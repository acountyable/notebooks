{
"Deno.internal": "Symbol(Deno.internal)",
"Deno.Process": "class Process {\n  constructor(res) {\n    this.rid = res.rid;\n    this.pid = res.pid;\n\n    if (res.stdinRid && res.stdinRid > 0) {\n      this.stdin = new FsFile(res.stdinRid, SymbolFor(\"Deno.internal.FsFile\"));\n    }\n\n    if (res.stdoutRid && res.stdoutRid > 0) {\n      this.stdout = new FsFile(\n        res.stdoutRid,\n        SymbolFor(\"Deno.internal.FsFile\"),\n      );\n    }\n\n    if (res.stderrRid && res.stderrRid > 0) {\n      this.stderr = new FsFile(\n        res.stderrRid,\n        SymbolFor(\"Deno.internal.FsFile\"),\n      );\n    }\n  }\n\n  status() {\n    return runStatus(this.rid);\n  }\n\n  async output() {\n    if (!this.stdout) {\n      throw new TypeError(\"Cannot collect output: 'stdout' is not piped\");\n    }\n    try {\n      return await readAll(this.stdout);\n    } finally {\n      this.stdout.close();\n    }\n  }\n\n  async stderrOutput() {\n    if (!this.stderr) {\n      throw new TypeError(\"Cannot collect output: 'stderr' is not piped\");\n    }\n    try {\n      return await readAll(this.stderr);\n    } finally {\n      this.stderr.close();\n    }\n  }\n\n  close() {\n    core.close(this.rid);\n  }\n\n  kill(signo = \"SIGTERM\") {\n    opKill(this.pid, signo, \"Deno.Process.kill()\");\n  }\n}",
"Deno.run": "function run({\n  cmd,\n  cwd = undefined,\n  env = { __proto__: null },\n  stdout = \"inherit\",\n  stderr = \"inherit\",\n  stdin = \"inherit\",\n}) {\n  if (cmd[0] != null) {\n    cmd = [\n      pathFromURL(cmd[0]),\n      ...new SafeArrayIterator(ArrayPrototypeSlice(cmd, 1)),\n    ];\n  }\n  const res = opRun({\n    cmd: ArrayPrototypeMap(cmd, String),\n    cwd,\n    env: ObjectEntries(env),\n    stdin,\n    stdout,\n    stderr,\n  });\n  return new Process(res);\n}",
"Deno.isatty": "function isatty(rid) {\n  return isTerminal(rid);\n}",
"Deno.writeFileSync": "function writeFileSync(\n  path,\n  data,\n  options = { __proto__: null },\n) {\n  options.signal?.throwIfAborted();\n  op_fs_write_file_sync(\n    pathFromURL(path),\n    options.mode,\n    options.append ?? false,\n    options.create ?? true,\n    options.createNew ?? false,\n    data,\n  );\n}",
"Deno.writeFile": "async function writeFile(\n  path,\n  data,\n  options = { __proto__: null },\n) {\n  let cancelRid;\n  let abortHandler;\n  if (options.signal) {\n    options.signal.throwIfAborted();\n    cancelRid = createCancelHandle();\n    abortHandler = () => core.tryClose(cancelRid);\n    options.signal[abortSignal.add](abortHandler);\n  }\n  try {\n    if (ObjectPrototypeIsPrototypeOf(ReadableStreamPrototype, data)) {\n      const file = await open(path, {\n        mode: options.mode,\n        append: options.append ?? false,\n        create: options.create ?? true,\n        createNew: options.createNew ?? false,\n        truncate: !(options.append ?? false),\n        write: true,\n      });\n      await data.pipeTo(file.writable, {\n        signal: options.signal,\n      });\n    } else {\n      await op_fs_write_file_async(\n        pathFromURL(path),\n        options.mode,\n        options.append ?? false,\n        options.create ?? true,\n        options.createNew ?? false,\n        data,\n        cancelRid,\n      );\n    }\n  } finally {\n    if (options.signal) {\n      options.signal[abortSignal.remove](abortHandler);\n\n      // always throw the abort error when aborted\n      options.signal.throwIfAborted();\n    }\n  }\n}",
"Deno.writeTextFileSync": "function writeTextFileSync(\n  path,\n  data,\n  options = { __proto__: null },\n) {\n  const encoder = new TextEncoder();\n  return writeFileSync(path, encoder.encode(data), options);\n}",
"Deno.writeTextFile": "function writeTextFile(\n  path,\n  data,\n  options = { __proto__: null },\n) {\n  if (ObjectPrototypeIsPrototypeOf(ReadableStreamPrototype, data)) {\n    return writeFile(\n      path,\n      data.pipeThrough(new TextEncoderStream()),\n      options,\n    );\n  } else {\n    const encoder = new TextEncoder();\n    return writeFile(path, encoder.encode(data), options);\n  }\n}",
"Deno.readTextFile": "async function readTextFile(path, options) {\n  let cancelRid;\n  let abortHandler;\n  if (options?.signal) {\n    options.signal.throwIfAborted();\n    cancelRid = createCancelHandle();\n    abortHandler = () => core.tryClose(cancelRid);\n    options.signal[abortSignal.add](abortHandler);\n  }\n\n  try {\n    const read = await op_fs_read_file_text_async(\n      pathFromURL(path),\n      cancelRid,\n    );\n    return read;\n  } finally {\n    if (options?.signal) {\n      options.signal[abortSignal.remove](abortHandler);\n\n      // always throw the abort error when aborted\n      options.signal.throwIfAborted();\n    }\n  }\n}",
"Deno.readTextFileSync": "function readTextFileSync(path) {\n  return op_fs_read_file_text_sync(pathFromURL(path));\n}",
"Deno.readFile": "async function readFile(path, options) {\n  let cancelRid;\n  let abortHandler;\n  if (options?.signal) {\n    options.signal.throwIfAborted();\n    cancelRid = createCancelHandle();\n    abortHandler = () => core.tryClose(cancelRid);\n    options.signal[abortSignal.add](abortHandler);\n  }\n\n  try {\n    const read = await op_fs_read_file_async(\n      pathFromURL(path),\n      cancelRid,\n    );\n    return read;\n  } finally {\n    if (options?.signal) {\n      options.signal[abortSignal.remove](abortHandler);\n\n      // always throw the abort error when aborted\n      options.signal.throwIfAborted();\n    }\n  }\n}",
"Deno.readFileSync": "function readFileSync(path) {\n  return op_fs_read_file_sync(pathFromURL(path));\n}",
"Deno.watchFs": "function watchFs(\n  paths,\n  options = { __proto__: null, recursive: true },\n) {\n  return new FsWatcher(ArrayIsArray(paths) ? paths : [paths], options);\n}",
"Deno.chmodSync": "function chmodSync(path, mode) {\n  op_fs_chmod_sync(pathFromURL(path), mode);\n}",
"Deno.chmod": "async function chmod(path, mode) {\n  await op_fs_chmod_async(pathFromURL(path), mode);\n}",
"Deno.chown": "async function chown(\n  path,\n  uid,\n  gid,\n) {\n  await op_fs_chown_async(\n    pathFromURL(path),\n    uid,\n    gid,\n  );\n}",
"Deno.chownSync": "function chownSync(\n  path,\n  uid,\n  gid,\n) {\n  op_fs_chown_sync(pathFromURL(path), uid, gid);\n}",
"Deno.copyFileSync": "function copyFileSync(\n  fromPath,\n  toPath,\n) {\n  op_fs_copy_file_sync(\n    pathFromURL(fromPath),\n    pathFromURL(toPath),\n  );\n}",
"Deno.cwd": "function cwd() {\n  return op_fs_cwd();\n}",
"Deno.makeTempDirSync": "function makeTempDirSync(options = { __proto__: null }) {\n  return op_fs_make_temp_dir_sync(\n    options.dir,\n    options.prefix,\n    options.suffix,\n  );\n}",
"Deno.makeTempDir": "function makeTempDir(options = { __proto__: null }) {\n  return op_fs_make_temp_dir_async(\n    options.dir,\n    options.prefix,\n    options.suffix,\n  );\n}",
"Deno.makeTempFileSync": "function makeTempFileSync(options = { __proto__: null }) {\n  return op_fs_make_temp_file_sync(\n    options.dir,\n    options.prefix,\n    options.suffix,\n  );\n}",
"Deno.makeTempFile": "function makeTempFile(options = { __proto__: null }) {\n  return op_fs_make_temp_file_async(\n    options.dir,\n    options.prefix,\n    options.suffix,\n  );\n}",
"Deno.memoryUsage": "() => op_runtime_memory_usage()",
"Deno.mkdirSync": "function mkdirSync(path, options) {\n  op_fs_mkdir_sync(\n    pathFromURL(path),\n    options?.recursive ?? false,\n    options?.mode,\n  );\n}",
"Deno.mkdir": "async function mkdir(path, options) {\n  await op_fs_mkdir_async(\n    pathFromURL(path),\n    options?.recursive ?? false,\n    options?.mode,\n  );\n}",
"Deno.chdir": "function chdir(directory) {\n  op_fs_chdir(pathFromURL(directory));\n}",
"Deno.copyFile": "async function copyFile(\n  fromPath,\n  toPath,\n) {\n  await op_fs_copy_file_async(\n    pathFromURL(fromPath),\n    pathFromURL(toPath),\n  );\n}",
"Deno.readDirSync": "function readDirSync(path) {\n  return op_fs_read_dir_sync(pathFromURL(path))[\n    SymbolIterator\n  ]();\n}",
"Deno.readDir": "function readDir(path) {\n  const array = op_fs_read_dir_async(\n    pathFromURL(path),\n  );\n  return {\n    async *[SymbolAsyncIterator]() {\n      const dir = await array;\n      for (let i = 0; i < dir.length; ++i) {\n        yield dir[i];\n      }\n    },\n  };\n}",
"Deno.readLinkSync": "function readLinkSync(path) {\n  return op_fs_read_link_sync(pathFromURL(path));\n}",
"Deno.readLink": "function readLink(path) {\n  return op_fs_read_link_async(pathFromURL(path));\n}",
"Deno.realPathSync": "function realPathSync(path) {\n  return op_fs_realpath_sync(pathFromURL(path));\n}",
"Deno.realPath": "function realPath(path) {\n  return op_fs_realpath_async(pathFromURL(path));\n}",
"Deno.removeSync": "function removeSync(\n  path,\n  options = { __proto__: null },\n) {\n  op_fs_remove_sync(\n    pathFromURL(path),\n    !!options.recursive,\n  );\n}",
"Deno.remove": "async function remove(\n  path,\n  options = { __proto__: null },\n) {\n  await op_fs_remove_async(\n    pathFromURL(path),\n    !!options.recursive,\n  );\n}",
"Deno.renameSync": "function renameSync(oldpath, newpath) {\n  op_fs_rename_sync(\n    pathFromURL(oldpath),\n    pathFromURL(newpath),\n  );\n}",
"Deno.rename": "async function rename(oldpath, newpath) {\n  await op_fs_rename_async(\n    pathFromURL(oldpath),\n    pathFromURL(newpath),\n  );\n}",
"Deno.version": {
	"deno": "2.0.0-rc.10",
	"v8": "12.9.202.13-rusty",
	"typescript": "5.6.2"
},
"Deno.build": {
	"target": "aarch64-apple-darwin",
	"arch": "aarch64",
	"os": "darwin",
	"vendor": "apple",
	"env": "undefined"
},
"Deno.statSync": "function statSync(path) {\n  op_fs_stat_sync(pathFromURL(path), statBuf);\n  return statStruct(statBuf);\n}",
"Deno.lstatSync": "function lstatSync(path) {\n  op_fs_lstat_sync(pathFromURL(path), statBuf);\n  return statStruct(statBuf);\n}",
"Deno.stat": "async function stat(path) {\n  const res = await op_fs_stat_async(pathFromURL(path));\n  return parseFileInfo(res);\n}",
"Deno.lstat": "async function lstat(path) {\n  const res = await op_fs_lstat_async(pathFromURL(path));\n  return parseFileInfo(res);\n}",
"Deno.truncateSync": "function truncateSync(path, len) {\n  op_fs_truncate_sync(path, coerceLen(len));\n}",
"Deno.truncate": "async function truncate(path, len) {\n  await op_fs_truncate_async(path, coerceLen(len));\n}",
"Deno.errors": {
	"NotFound": "class NotFound extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"NotFound\";\n  }\n}",
	"PermissionDenied": "class PermissionDenied extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"PermissionDenied\";\n  }\n}",
	"ConnectionRefused": "class ConnectionRefused extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"ConnectionRefused\";\n  }\n}",
	"ConnectionReset": "class ConnectionReset extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"ConnectionReset\";\n  }\n}",
	"ConnectionAborted": "class ConnectionAborted extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"ConnectionAborted\";\n  }\n}",
	"NotConnected": "class NotConnected extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"NotConnected\";\n  }\n}",
	"AddrInUse": "class AddrInUse extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"AddrInUse\";\n  }\n}",
	"AddrNotAvailable": "class AddrNotAvailable extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"AddrNotAvailable\";\n  }\n}",
	"BrokenPipe": "class BrokenPipe extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"BrokenPipe\";\n  }\n}",
	"AlreadyExists": "class AlreadyExists extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"AlreadyExists\";\n  }\n}",
	"InvalidData": "class InvalidData extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"InvalidData\";\n  }\n}",
	"TimedOut": "class TimedOut extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"TimedOut\";\n  }\n}",
	"Interrupted": "class Interrupted extends Error {\n    constructor(msg) {\n      super(msg);\n      this.name = \"Interrupted\";\n    }\n  }",
	"WriteZero": "class WriteZero extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"WriteZero\";\n  }\n}",
	"WouldBlock": "class WouldBlock extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"WouldBlock\";\n  }\n}",
	"UnexpectedEof": "class UnexpectedEof extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"UnexpectedEof\";\n  }\n}",
	"BadResource": "class BadResource extends Error {\n    constructor(msg) {\n      super(msg);\n      this.name = \"BadResource\";\n    }\n  }",
	"Http": "class Http extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"Http\";\n  }\n}",
	"Busy": "class Busy extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"Busy\";\n  }\n}",
	"NotSupported": "class NotSupported extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"NotSupported\";\n  }\n}",
	"FilesystemLoop": "class FilesystemLoop extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"FilesystemLoop\";\n  }\n}",
	"IsADirectory": "class IsADirectory extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"IsADirectory\";\n  }\n}",
	"NetworkUnreachable": "class NetworkUnreachable extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"NetworkUnreachable\";\n  }\n}",
	"NotADirectory": "class NotADirectory extends Error {\n  constructor(msg) {\n    super(msg);\n    this.name = \"NotADirectory\";\n  }\n}",
	"NotCapable": "class NotCapable extends Error {\n    constructor(msg) {\n      super(msg);\n      this.name = \"NotCapable\";\n    }\n  }"
},
"Deno.inspect": "function inspect(\n  value,\n  inspectOptions = { __proto__: null },\n) {\n  // Default options\n  const ctx = {\n    ...getDefaultInspectOptions(),\n    ...inspectOptions,\n  };\n  if (inspectOptions.iterableLimit !== undefined) {\n    ctx.maxArrayLength = inspectOptions.iterableLimit;\n  }\n  if (inspectOptions.strAbbreviateSize !== undefined) {\n    ctx.maxStringLength = inspectOptions.strAbbreviateSize;\n  }\n\n  if (ctx.colors) ctx.stylize = createStylizeWithColor(styles, colors);\n  if (ctx.maxArrayLength === null) ctx.maxArrayLength = Infinity;\n  if (ctx.maxStringLength === null) ctx.maxStringLength = Infinity;\n  return formatValue(ctx, value, 0);\n}",
"Deno.env": {
	"get": "function getEnv(key) {\n  return op_get_env(key) ?? undefined;\n}",
	"toObject": "toObject() {\n    return op_env();\n  }",
	"set": "function setEnv(key, value) {\n  op_set_env(key, value);\n}",
	"has": "has(key) {\n    return getEnv(key) !== undefined;\n  }",
	"delete": "function deleteEnv(key) {\n  op_delete_env(key);\n}"
},
"Deno.exit": "function exit(code) {\n  // Set exit code first so unload event listeners can override it.\n  if (typeof code === \"number\") {\n    op_set_exit_code(code);\n  } else {\n    code = op_get_exit_code();\n  }\n\n  // Dispatches `unload` only when it's not dispatched yet.\n  if (!globalThis[SymbolFor(\"Deno.isUnloadDispatched\")]) {\n    // Invokes the `unload` hooks before exiting\n    // ref: https://github.com/denoland/deno/issues/3603\n    windowDispatchEvent(new Event(\"unload\"));\n  }\n\n  if (exitHandler) {\n    exitHandler(code);\n    return;\n  }\n\n  op_exit();\n  throw new Error(\"Code not reachable\");\n}",
"Deno.execPath": "function execPath() {\n  return op_exec_path();\n}",
"Deno.SeekMode": {
	"0": "Start",
	"1": "Current",
	"2": "End",
	"Start": "0",
	"Current": "1",
	"End": "2"
},
"Deno.FsFile": "class FsFile {\n  #rid = 0;\n\n  #readable;\n  #writable;\n\n  constructor(rid, symbol) {\n    ObjectDefineProperty(this, internalRidSymbol, {\n      __proto__: null,\n      enumerable: false,\n      value: rid,\n    });\n    this.#rid = rid;\n    if (!symbol || symbol !== SymbolFor(\"Deno.internal.FsFile\")) {\n      throw new TypeError(\n        \"`Deno.FsFile` cannot be constructed, use `Deno.open()` or `Deno.openSync()` instead.\",\n      );\n    }\n  }\n\n  write(p) {\n    return write(this.#rid, p);\n  }\n\n  writeSync(p) {\n    return writeSync(this.#rid, p);\n  }\n\n  truncate(len) {\n    return op_fs_file_truncate_async(this.#rid, coerceLen(len));\n  }\n\n  truncateSync(len) {\n    return op_fs_ftruncate_sync(this.#rid, coerceLen(len));\n  }\n\n  read(p) {\n    return read(this.#rid, p);\n  }\n\n  readSync(p) {\n    return readSync(this.#rid, p);\n  }\n\n  seek(offset, whence) {\n    return op_fs_seek_async(this.#rid, offset, whence);\n  }\n\n  seekSync(offset, whence) {\n    return op_fs_seek_sync(this.#rid, offset, whence);\n  }\n\n  async stat() {\n    return parseFileInfo(await op_fs_file_stat_async(this.#rid));\n  }\n\n  statSync() {\n    op_fs_file_stat_sync(this.#rid, statBuf);\n    return statStruct(statBuf);\n  }\n\n  async syncData() {\n    await op_fs_file_sync_data_async(this.#rid);\n  }\n\n  syncDataSync() {\n    op_fs_file_sync_data_sync(this.#rid);\n  }\n\n  close() {\n    core.close(this.#rid);\n  }\n\n  get readable() {\n    if (this.#readable === undefined) {\n      this.#readable = readableStreamForRid(this.#rid);\n    }\n    return this.#readable;\n  }\n\n  get writable() {\n    if (this.#writable === undefined) {\n      this.#writable = writableStreamForRid(this.#rid);\n    }\n    return this.#writable;\n  }\n\n  async sync() {\n    await op_fs_file_sync_async(this.#rid);\n  }\n\n  syncSync() {\n    op_fs_file_sync_sync(this.#rid);\n  }\n\n  async utime(atime, mtime) {\n    const { 0: atimeSec, 1: atimeNsec } = toUnixTimeFromEpoch(atime);\n    const { 0: mtimeSec, 1: mtimeNsec } = toUnixTimeFromEpoch(mtime);\n    await op_fs_futime_async(\n      this.#rid,\n      atimeSec,\n      atimeNsec,\n      mtimeSec,\n      mtimeNsec,\n    );\n  }\n\n  utimeSync(atime, mtime) {\n    const { 0: atimeSec, 1: atimeNsec } = toUnixTimeFromEpoch(atime);\n    const { 0: mtimeSec, 1: mtimeNsec } = toUnixTimeFromEpoch(mtime);\n    op_fs_futime_sync(this.#rid, atimeSec, atimeNsec, mtimeSec, mtimeNsec);\n  }\n\n  isTerminal() {\n    return core.isTerminal(this.#rid);\n  }\n\n  setRaw(mode, options = { __proto__: null }) {\n    const cbreak = !!(options.cbreak ?? false);\n    op_set_raw(this.#rid, mode, cbreak);\n  }\n\n  lockSync(exclusive = false) {\n    op_fs_flock_sync(this.#rid, exclusive);\n  }\n\n  async lock(exclusive = false) {\n    await op_fs_flock_async(this.#rid, exclusive);\n  }\n\n  unlockSync() {\n    op_fs_funlock_sync(this.#rid);\n  }\n\n  async unlock() {\n    await op_fs_funlock_async(this.#rid);\n  }\n\n  [SymbolDispose]() {\n    core.tryClose(this.#rid);\n  }\n}",
"Deno.open": "async function open(\n  path,\n  options,\n) {\n  if (options) checkOpenOptions(options);\n  const rid = await op_fs_open_async(\n    pathFromURL(path),\n    options,\n  );\n\n  return new FsFile(rid, SymbolFor(\"Deno.internal.FsFile\"));\n}",
"Deno.openSync": "function openSync(\n  path,\n  options,\n) {\n  if (options) checkOpenOptions(options);\n  const rid = op_fs_open_sync(\n    pathFromURL(path),\n    options,\n  );\n\n  return new FsFile(rid, SymbolFor(\"Deno.internal.FsFile\"));\n}",
"Deno.create": "function create(path) {\n  return open(path, {\n    read: true,\n    write: true,\n    truncate: true,\n    create: true,\n  });\n}",
"Deno.createSync": "function createSync(path) {\n  return openSync(path, {\n    read: true,\n    write: true,\n    truncate: true,\n    create: true,\n  });\n}",
"Deno.stdin": {},
"Deno.stdout": {},
"Deno.stderr": {},
"Deno.connect": "async function connect(args) {\n  switch (args.transport ?? \"tcp\") {\n    case \"tcp\": {\n      const port = validatePort(args.port);\n      const { 0: rid, 1: localAddr, 2: remoteAddr } = await op_net_connect_tcp(\n        {\n          hostname: args.hostname ?? \"127.0.0.1\",\n          port,\n        },\n      );\n      localAddr.transport = \"tcp\";\n      remoteAddr.transport = \"tcp\";\n      return new TcpConn(rid, remoteAddr, localAddr);\n    }\n    case \"unix\": {\n      const { 0: rid, 1: localAddr, 2: remoteAddr } = await op_net_connect_unix(\n        args.path,\n      );\n      return new UnixConn(\n        rid,\n        { transport: \"unix\", path: remoteAddr },\n        { transport: \"unix\", path: localAddr },\n      );\n    }\n    default:\n      throw new TypeError(`Unsupported transport: '${transport}'`);\n  }\n}",
"Deno.listen": "function listen(args) {\n  switch (args.transport ?? \"tcp\") {\n    case \"tcp\": {\n      const port = validatePort(args.port);\n      const { 0: rid, 1: addr } = op_net_listen_tcp(\n        {\n          hostname: args.hostname ?? \"0.0.0.0\",\n          port,\n        },\n        args.reusePort,\n        args.loadBalanced ?? false,\n      );\n      addr.transport = \"tcp\";\n      return new Listener(rid, addr);\n    }\n    case \"unix\": {\n      const { 0: rid, 1: path } = op_net_listen_unix(\n        args.path,\n        args[listenOptionApiName] ?? \"Deno.listen\",\n      );\n      const addr = {\n        transport: \"unix\",\n        path,\n      };\n      return new Listener(rid, addr);\n    }\n    default:\n      throw new TypeError(`Unsupported transport: '${transport}'`);\n  }\n}",
"Deno.loadavg": "function loadavg() {\n  return op_loadavg();\n}",
"Deno.connectTls": "async function connectTls({\n  port,\n  hostname = \"127.0.0.1\",\n  transport = \"tcp\",\n  caCerts = [],\n  alpnProtocols = undefined,\n  keyFormat = undefined,\n  cert = undefined,\n  key = undefined,\n}) {\n  if (transport !== \"tcp\") {\n    throw new TypeError(`Unsupported transport: '${transport}'`);\n  }\n\n  const keyPair = loadTlsKeyPair(\"Deno.connectTls\", {\n    keyFormat,\n    cert,\n    key,\n  });\n  // TODO(mmastrac): We only expose this feature via symbol for now. This should actually be a feature\n  // in Deno.connectTls, however.\n  const serverName = arguments[0][serverNameSymbol] ?? null;\n  const { 0: rid, 1: localAddr, 2: remoteAddr } = await op_net_connect_tls(\n    { hostname, port },\n    { caCerts, alpnProtocols, serverName },\n    keyPair,\n  );\n  localAddr.transport = \"tcp\";\n  remoteAddr.transport = \"tcp\";\n  return new TlsConn(rid, remoteAddr, localAddr);\n}",
"Deno.listenTls": "function listenTls({\n  port,\n  hostname = \"0.0.0.0\",\n  transport = \"tcp\",\n  alpnProtocols = undefined,\n  reusePort = false,\n}) {\n  if (transport !== \"tcp\") {\n    throw new TypeError(`Unsupported transport: '${transport}'`);\n  }\n  port = validatePort(port);\n\n  if (!hasTlsKeyPairOptions(arguments[0])) {\n    throw new TypeError(\n      \"A key and certificate are required for `Deno.listenTls`\",\n    );\n  }\n  const keyPair = loadTlsKeyPair(\"Deno.listenTls\", arguments[0]);\n  const { 0: rid, 1: localAddr } = op_net_listen_tls(\n    { hostname, port },\n    { alpnProtocols, reusePort },\n    keyPair,\n  );\n  return new TlsListener(rid, localAddr);\n}",
"Deno.startTls": "async function startTls(\n  conn,\n  {\n    hostname = \"127.0.0.1\",\n    caCerts = [],\n    alpnProtocols = undefined,\n  } = { __proto__: null },\n) {\n  const { 0: rid, 1: localAddr, 2: remoteAddr } = op_tls_start({\n    rid: conn[internalRidSymbol],\n    hostname,\n    caCerts,\n    alpnProtocols,\n  });\n  return new TlsConn(rid, remoteAddr, localAddr);\n}",
"Deno.symlink": "async function symlink(\n  oldpath,\n  newpath,\n  options,\n) {\n  await op_fs_symlink_async(\n    pathFromURL(oldpath),\n    pathFromURL(newpath),\n    options?.type,\n  );\n}",
"Deno.symlinkSync": "function symlinkSync(\n  oldpath,\n  newpath,\n  options,\n) {\n  op_fs_symlink_sync(\n    pathFromURL(oldpath),\n    pathFromURL(newpath),\n    options?.type,\n  );\n}",
"Deno.link": "async function link(oldpath, newpath) {\n  await op_fs_link_async(oldpath, newpath);\n}",
"Deno.linkSync": "function linkSync(oldpath, newpath) {\n  op_fs_link_sync(oldpath, newpath);\n}",
"Deno.permissions": {},
"Deno.Permissions": "class Permissions {\n  constructor(key = null) {\n    if (key != illegalConstructorKey) {\n      throw new TypeError(\"Illegal constructor\");\n    }\n  }\n\n  query(desc) {\n    try {\n      return PromiseResolve(this.querySync(desc));\n    } catch (error) {\n      return PromiseReject(error);\n    }\n  }\n\n  querySync(desc) {\n    if (!isValidDescriptor(desc)) {\n      throw new TypeError(\n        `The provided value \"${desc?.name}\" is not a valid permission name`,\n      );\n    }\n\n    formDescriptor(desc);\n\n    const status = opQuery(desc);\n    return cache(desc, status);\n  }\n\n  revoke(desc) {\n    try {\n      return PromiseResolve(this.revokeSync(desc));\n    } catch (error) {\n      return PromiseReject(error);\n    }\n  }\n\n  revokeSync(desc) {\n    if (!isValidDescriptor(desc)) {\n      throw new TypeError(\n        `The provided value \"${desc?.name}\" is not a valid permission name`,\n      );\n    }\n\n    formDescriptor(desc);\n\n    const status = opRevoke(desc);\n    return cache(desc, status);\n  }\n\n  request(desc) {\n    try {\n      return PromiseResolve(this.requestSync(desc));\n    } catch (error) {\n      return PromiseReject(error);\n    }\n  }\n\n  requestSync(desc) {\n    if (!isValidDescriptor(desc)) {\n      throw new TypeError(\n        `The provided value \"${desc?.name}\" is not a valid permission name.`,\n      );\n    }\n\n    formDescriptor(desc);\n\n    const status = opRequest(desc);\n    return cache(desc, status);\n  }\n}",
"Deno.PermissionStatus": "class PermissionStatus extends EventTarget {\n  /** @type {{ state: Deno.PermissionState, partial: boolean }} */\n  #status;\n\n  /** @type {((this: PermissionStatus, event: Event) => any) | null} */\n  onchange = null;\n\n  /** @returns {Deno.PermissionState} */\n  get state() {\n    return this.#status.state;\n  }\n\n  /** @returns {boolean} */\n  get partial() {\n    return this.#status.partial;\n  }\n\n  /**\n   * @param {{ state: Deno.PermissionState, partial: boolean }} status\n   * @param {unknown} key\n   */\n  constructor(status = null, key = null) {\n    if (key != illegalConstructorKey) {\n      throw new TypeError(\"Illegal constructor\");\n    }\n    super();\n    this.#status = status;\n  }\n\n  /**\n   * @param {Event} event\n   * @returns {boolean}\n   */\n  dispatchEvent(event) {\n    let dispatched = super.dispatchEvent(event);\n    if (dispatched && this.onchange) {\n      FunctionPrototypeCall(this.onchange, this, event);\n      dispatched = !event.defaultPrevented;\n    }\n    return dispatched;\n  }\n\n  [SymbolFor(\"Deno.privateCustomInspect\")](inspect, inspectOptions) {\n    const object = { state: this.state, onchange: this.onchange };\n    if (this.partial) object.partial = this.partial;\n    return `${this.constructor.name} ${inspect(object, inspectOptions)}`;\n  }\n}",
"Deno.serveHttp": "function serveHttp(conn) {\n  const rid = op_http_start(conn[internalRidSymbol]);\n  return new HttpConn(rid, conn.remoteAddr, conn.localAddr);\n}",
"Deno.serve": "function serve(arg1, arg2) {\n  let options;\n  let handler;\n  if (typeof arg1 === \"function\") {\n    handler = arg1;\n  } else if (typeof arg2 === \"function\") {\n    handler = arg2;\n    options = arg1;\n  } else {\n    options = arg1;\n  }\n  if (handler === undefined) {\n    if (options === undefined) {\n      throw new TypeError(\"Cannot serve HTTP requests: either a `handler` or `options` must be specified\");\n    }\n    handler = options.handler;\n  }\n  if (typeof handler !== \"function\") {\n    throw new TypeError(`Cannot serve HTTP requests: handler must be a function, received ${typeof handler}`);\n  }\n  if (options === undefined) {\n    options = {\n      __proto__: null\n    };\n  }\n  const wantsHttps = hasTlsKeyPairOptions(options);\n  const wantsUnix = ObjectHasOwn(options, \"path\");\n  const signal = options.signal;\n  const onError = options.onError ?? function(error) {\n    // deno-lint-ignore no-console\n    console.error(error);\n    return internalServerError();\n  };\n  if (wantsUnix) {\n    const listener = listen({\n      transport: \"unix\",\n      path: options.path,\n      [listenOptionApiName]: \"Deno.serve\"\n    });\n    const path = listener.addr.path;\n    return serveHttpOnListener(listener, signal, handler, onError, ()=>{\n      if (options.onListen) {\n        options.onListen(listener.addr);\n      } else {\n        // deno-lint-ignore no-console\n        console.error(`Listening on ${path}`);\n      }\n    });\n  }\n  const listenOpts = {\n    hostname: options.hostname ?? \"0.0.0.0\",\n    port: options.port ?? 8000,\n    reusePort: options.reusePort ?? false,\n    loadBalanced: options[kLoadBalanced] ?? false\n  };\n  if (options.certFile || options.keyFile) {\n    throw new TypeError(\"Unsupported 'certFile' / 'keyFile' options provided: use 'cert' / 'key' instead.\");\n  }\n  if (options.alpnProtocols) {\n    throw new TypeError(\"Unsupported 'alpnProtocols' option provided. 'h2' and 'http/1.1' are automatically supported.\");\n  }\n  let listener;\n  if (wantsHttps) {\n    if (!options.cert || !options.key) {\n      throw new TypeError(\"Both 'cert' and 'key' must be provided to enable HTTPS\");\n    }\n    listenOpts.cert = options.cert;\n    listenOpts.key = options.key;\n    listenOpts.alpnProtocols = [\n      \"h2\",\n      \"http/1.1\"\n    ];\n    listener = listenTls(listenOpts);\n    listenOpts.port = listener.addr.port;\n  } else {\n    listener = listen(listenOpts);\n    listenOpts.port = listener.addr.port;\n  }\n  const addr = listener.addr;\n  const onListen = (scheme)=>{\n    if (options.onListen) {\n      options.onListen(addr);\n    } else {\n      const host = formatHostName(addr.hostname);\n      // deno-lint-ignore no-console\n      console.error(`Listening on ${scheme}${host}:${addr.port}/`);\n    }\n  };\n  return serveHttpOnListener(listener, signal, handler, onError, onListen);\n}",
"Deno.resolveDns": "async function resolveDns(query, recordType, options) {\n  let cancelRid;\n  let abortHandler;\n  if (options?.signal) {\n    options.signal.throwIfAborted();\n    cancelRid = createCancelHandle();\n    abortHandler = () => core.tryClose(cancelRid);\n    options.signal[abortSignal.add](abortHandler);\n  }\n\n  try {\n    return await op_dns_resolve({\n      cancelRid,\n      query,\n      recordType,\n      options,\n    });\n  } finally {\n    if (options?.signal) {\n      options.signal[abortSignal.remove](abortHandler);\n\n      // always throw the abort error when aborted\n      options.signal.throwIfAborted();\n    }\n  }\n}",
"Deno.upgradeWebSocket": "function upgradeWebSocket(request, options = {\n  __proto__: null\n}) {\n  const inner = toInnerRequest(request);\n  const upgrade = request.headers.get(\"upgrade\");\n  const upgradeHasWebSocketOption = upgrade !== null && websocketCvf(upgrade);\n  if (!upgradeHasWebSocketOption) {\n    throw new TypeError(\"Invalid Header: 'upgrade' header must contain 'websocket'\");\n  }\n  const connection = request.headers.get(\"connection\");\n  const connectionHasUpgradeOption = connection !== null && upgradeCvf(connection);\n  if (!connectionHasUpgradeOption) {\n    throw new TypeError(\"Invalid Header: 'connection' header must contain 'Upgrade'\");\n  }\n  const websocketKey = request.headers.get(\"sec-websocket-key\");\n  if (websocketKey === null) {\n    throw new TypeError(\"Invalid Header: 'sec-websocket-key' header must be set\");\n  }\n  const accept = op_http_websocket_accept_header(websocketKey);\n  const r = newInnerResponse(101);\n  r.headerList = [\n    [\n      \"upgrade\",\n      \"websocket\"\n    ],\n    [\n      \"connection\",\n      \"Upgrade\"\n    ],\n    [\n      \"sec-websocket-accept\",\n      accept\n    ]\n  ];\n  const protocolsStr = request.headers.get(\"sec-websocket-protocol\") || \"\";\n  const protocols = StringPrototypeSplit(protocolsStr, \", \");\n  if (protocols && options.protocol) {\n    if (ArrayPrototypeIncludes(protocols, options.protocol)) {\n      ArrayPrototypePush(r.headerList, [\n        \"sec-websocket-protocol\",\n        options.protocol\n      ]);\n    } else {\n      throw new TypeError(`Protocol '${options.protocol}' not in the request's protocol list (non negotiable)`);\n    }\n  }\n  const socket = createWebSocketBranded(WebSocket);\n  setEventTargetData(socket);\n  socket[_server] = true;\n  // Nginx timeout is 60s, so default to a lower number: https://github.com/denoland/deno/pull/23985\n  socket[_idleTimeoutDuration] = options.idleTimeout ?? 30;\n  socket[_idleTimeoutTimeout] = null;\n  if (inner._wantsUpgrade) {\n    return inner._wantsUpgrade(\"upgradeWebSocket\", r, socket);\n  }\n  const response = fromInnerResponse(r, \"immutable\");\n  response[_ws] = socket;\n  return {\n    response,\n    socket\n  };\n}",
"Deno.utime": "async function utime(\n  path,\n  atime,\n  mtime,\n) {\n  const { 0: atimeSec, 1: atimeNsec } = toUnixTimeFromEpoch(atime);\n  const { 0: mtimeSec, 1: mtimeNsec } = toUnixTimeFromEpoch(mtime);\n  await op_fs_utime_async(\n    pathFromURL(path),\n    atimeSec,\n    atimeNsec,\n    mtimeSec,\n    mtimeNsec,\n  );\n}",
"Deno.utimeSync": "function utimeSync(\n  path,\n  atime,\n  mtime,\n) {\n  const { 0: atimeSec, 1: atimeNsec } = toUnixTimeFromEpoch(atime);\n  const { 0: mtimeSec, 1: mtimeNsec } = toUnixTimeFromEpoch(mtime);\n  op_fs_utime_sync(\n    pathFromURL(path),\n    atimeSec,\n    atimeNsec,\n    mtimeSec,\n    mtimeNsec,\n  );\n}",
"Deno.kill": "function kill(pid, signo = \"SIGTERM\") {\n  opKill(pid, signo, \"Deno.kill()\");\n}",
"Deno.addSignalListener": "function addSignalListener(signo, listener) {\n  checkSignalListenerType(listener);\n\n  const sigData = getSignalData(signo);\n  SetPrototypeAdd(sigData.listeners, listener);\n\n  if (!sigData.rid) {\n    // If signal resource doesn't exist, create it.\n    // The program starts listening to the signal\n    sigData.rid = bindSignal(signo);\n    loop(sigData);\n  }\n}",
"Deno.removeSignalListener": "function removeSignalListener(signo, listener) {\n  checkSignalListenerType(listener);\n\n  const sigData = getSignalData(signo);\n  SetPrototypeDelete(sigData.listeners, listener);\n\n  if (sigData.listeners.size === 0 && sigData.rid) {\n    unbindSignal(sigData.rid);\n    sigData.rid = undefined;\n  }\n}",
"Deno.refTimer": "function refTimer(id) {\n  core.refTimer(id);\n}",
"Deno.unrefTimer": "function unrefTimer(id) {\n  core.unrefTimer(id);\n}",
"Deno.osRelease": "function osRelease() {\n  return op_os_release();\n}",
"Deno.osUptime": "function osUptime() {\n  return op_os_uptime();\n}",
"Deno.hostname": "function hostname() {\n  return op_hostname();\n}",
"Deno.systemMemoryInfo": "function systemMemoryInfo() {\n  return op_system_memory_info();\n}",
"Deno.networkInterfaces": "function networkInterfaces() {\n  return op_network_interfaces();\n}",
"Deno.consoleSize": "function consoleSize() {\n  op_console_size(size);\n  return { columns: size[0], rows: size[1] };\n}",
"Deno.gid": "function gid() {\n  return op_gid();\n}",
"Deno.uid": "function uid() {\n  return op_uid();\n}",
"Deno.Command": "class Command {\n  #command;\n  #options;\n\n  constructor(command, options) {\n    this.#command = command;\n    this.#options = options;\n  }\n\n  output() {\n    if (this.#options?.stdin === \"piped\") {\n      throw new TypeError(\n        \"Piped stdin is not supported for this function, use 'Deno.Command.spawn()' instead\",\n      );\n    }\n    return spawn(this.#command, this.#options);\n  }\n\n  outputSync() {\n    if (this.#options?.stdin === \"piped\") {\n      throw new TypeError(\n        \"Piped stdin is not supported for this function, use 'Deno.Command.spawn()' instead\",\n      );\n    }\n    return spawnSync(this.#command, this.#options);\n  }\n\n  spawn() {\n    const options = {\n      __proto__: null,\n      ...(this.#options ?? {}),\n      stdout: this.#options?.stdout ?? \"inherit\",\n      stderr: this.#options?.stderr ?? \"inherit\",\n      stdin: this.#options?.stdin ?? \"inherit\",\n    };\n    return spawnChild(this.#command, options);\n  }\n}",
"Deno.ChildProcess": "class ChildProcess {\n  #rid;\n  #waitPromise;\n  #waitComplete = false;\n\n  [_ipcPipeRid];\n  [_extraPipeRids];\n\n  #pid;\n  get pid() {\n    return this.#pid;\n  }\n\n  #stdin = null;\n  get stdin() {\n    if (this.#stdin == null) {\n      throw new TypeError(\"Cannot get 'stdin': 'stdin' is not piped\");\n    }\n    return this.#stdin;\n  }\n\n  #stdout = null;\n  get stdout() {\n    if (this.#stdout == null) {\n      throw new TypeError(\"Cannot get 'stdout': 'stdout' is not piped\");\n    }\n    return this.#stdout;\n  }\n\n  #stderr = null;\n  get stderr() {\n    if (this.#stderr == null) {\n      throw new TypeError(\"Cannot get 'stderr': 'stderr' is not piped\");\n    }\n    return this.#stderr;\n  }\n\n  constructor(key = null, {\n    signal,\n    rid,\n    pid,\n    stdinRid,\n    stdoutRid,\n    stderrRid,\n    ipcPipeRid, // internal\n    extraPipeRids,\n  } = null) {\n    if (key !== illegalConstructorKey) {\n      throw new TypeError(\"Illegal constructor\");\n    }\n\n    this.#rid = rid;\n    this.#pid = pid;\n    this[_ipcPipeRid] = ipcPipeRid;\n    this[_extraPipeRids] = extraPipeRids;\n\n    if (stdinRid !== null) {\n      this.#stdin = writableStreamForRid(stdinRid);\n    }\n\n    if (stdoutRid !== null) {\n      this.#stdout = readableStreamForRidUnrefable(stdoutRid);\n    }\n\n    if (stderrRid !== null) {\n      this.#stderr = readableStreamForRidUnrefable(stderrRid);\n    }\n\n    const onAbort = () => this.kill(\"SIGTERM\");\n    signal?.[abortSignal.add](onAbort);\n\n    const waitPromise = op_spawn_wait(this.#rid);\n    this.#waitPromise = waitPromise;\n    this.#status = PromisePrototypeThen(waitPromise, (res) => {\n      signal?.[abortSignal.remove](onAbort);\n      this.#waitComplete = true;\n      return res;\n    });\n  }\n\n  #status;\n  get status() {\n    return this.#status;\n  }\n\n  async output() {\n    if (this.#stdout?.locked) {\n      throw new TypeError(\n        \"Cannot collect output: 'stdout' is locked\",\n      );\n    }\n    if (this.#stderr?.locked) {\n      throw new TypeError(\n        \"Cannot collect output: 'stderr' is locked\",\n      );\n    }\n\n    const { 0: status, 1: stdout, 2: stderr } = await SafePromiseAll([\n      this.#status,\n      collectOutput(this.#stdout),\n      collectOutput(this.#stderr),\n    ]);\n\n    return {\n      success: status.success,\n      code: status.code,\n      signal: status.signal,\n      get stdout() {\n        if (stdout == null) {\n          throw new TypeError(\"Cannot get 'stdout': 'stdout' is not piped\");\n        }\n        return stdout;\n      },\n      get stderr() {\n        if (stderr == null) {\n          throw new TypeError(\"Cannot get 'stderr': 'stderr' is not piped\");\n        }\n        return stderr;\n      },\n    };\n  }\n\n  kill(signo = \"SIGTERM\") {\n    if (this.#waitComplete) {\n      throw new TypeError(\"Child process has already terminated\");\n    }\n    op_spawn_kill(this.#rid, signo);\n  }\n\n  async [SymbolAsyncDispose]() {\n    try {\n      op_spawn_kill(this.#rid, \"SIGTERM\");\n    } catch {\n      // ignore errors from killing the process (such as ESRCH or BadResource)\n    }\n    await this.#status;\n  }\n\n  ref() {\n    core.refOpPromise(this.#waitPromise);\n    if (this.#stdout) readableStreamForRidUnrefableRef(this.#stdout);\n    if (this.#stderr) readableStreamForRidUnrefableRef(this.#stderr);\n  }\n\n  unref() {\n    core.unrefOpPromise(this.#waitPromise);\n    if (this.#stdout) readableStreamForRidUnrefableUnref(this.#stdout);\n    if (this.#stderr) readableStreamForRidUnrefableUnref(this.#stderr);\n  }\n}",
"Deno.dlopen": "function dlopen(path, symbols) {\n  return new DynamicLibrary(pathFromURL(path), symbols);\n}",
"Deno.UnsafeCallback": "class UnsafeCallback {\n  #refcount;\n  // Internal promise only meant to keep Deno from exiting\n  #refpromise;\n  #rid;\n  definition;\n  callback;\n  pointer;\n\n  constructor(definition, callback) {\n    if (definition.nonblocking) {\n      throw new TypeError(\n        \"Cannot construct UnsafeCallback: cannot be nonblocking\",\n      );\n    }\n    const { 0: rid, 1: pointer } = op_ffi_unsafe_callback_create(\n      definition,\n      callback,\n    );\n    this.#refcount = 0;\n    this.#rid = rid;\n    this.pointer = pointer;\n    this.definition = definition;\n    this.callback = callback;\n  }\n\n  static threadSafe(definition, callback) {\n    const unsafeCallback = new UnsafeCallback(definition, callback);\n    unsafeCallback.ref();\n    return unsafeCallback;\n  }\n\n  ref() {\n    if (this.#refcount++ === 0) {\n      if (this.#refpromise) {\n        // Re-refing\n        core.refOpPromise(this.#refpromise);\n      } else {\n        this.#refpromise = op_ffi_unsafe_callback_ref(\n          this.#rid,\n        );\n      }\n    }\n    return this.#refcount;\n  }\n\n  unref() {\n    // Only decrement refcount if it is positive, and only\n    // unref the callback if refcount reaches zero.\n    if (this.#refcount > 0 && --this.#refcount === 0) {\n      core.unrefOpPromise(this.#refpromise);\n    }\n    return this.#refcount;\n  }\n\n  close() {\n    this.#refcount = 0;\n    op_ffi_unsafe_callback_close(this.#rid);\n  }\n}",
"Deno.UnsafePointer": "class UnsafePointer {\n  static create(value) {\n    return op_ffi_ptr_create(value);\n  }\n\n  static equals(a, b) {\n    if (a === null || b === null) {\n      return a === b;\n    }\n    return op_ffi_ptr_equals(a, b);\n  }\n\n  static of(value) {\n    if (ObjectPrototypeIsPrototypeOf(UnsafeCallbackPrototype, value)) {\n      return value.pointer;\n    }\n    let pointer;\n    if (ArrayBufferIsView(value)) {\n      if (value.length === 0) {\n        pointer = op_ffi_ptr_of_exact(value);\n      } else {\n        pointer = op_ffi_ptr_of(value);\n      }\n    } else if (isArrayBuffer(value)) {\n      if (value.length === 0) {\n        pointer = op_ffi_ptr_of_exact(new Uint8Array(value));\n      } else {\n        pointer = op_ffi_ptr_of(new Uint8Array(value));\n      }\n    } else {\n      throw new TypeError(\n        `Cannot access pointer: expected 'ArrayBuffer', 'ArrayBufferView' or 'UnsafeCallbackPrototype', received ${typeof value}`,\n      );\n    }\n    if (pointer) {\n      POINTER_TO_BUFFER_WEAK_MAP.set(pointer, value);\n    }\n    return pointer;\n  }\n\n  static offset(value, offset) {\n    return op_ffi_ptr_offset(value, offset);\n  }\n\n  static value(value) {\n    if (ObjectPrototypeIsPrototypeOf(UnsafeCallbackPrototype, value)) {\n      value = value.pointer;\n    }\n    return op_ffi_ptr_value(value);\n  }\n}",
"Deno.UnsafePointerView": "class UnsafePointerView {\n  pointer;\n\n  constructor(pointer) {\n    this.pointer = pointer;\n  }\n\n  getBool(offset = 0) {\n    return op_ffi_read_bool(\n      this.pointer,\n      offset,\n    );\n  }\n\n  getUint8(offset = 0) {\n    return op_ffi_read_u8(\n      this.pointer,\n      offset,\n    );\n  }\n\n  getInt8(offset = 0) {\n    return op_ffi_read_i8(\n      this.pointer,\n      offset,\n    );\n  }\n\n  getUint16(offset = 0) {\n    return op_ffi_read_u16(\n      this.pointer,\n      offset,\n    );\n  }\n\n  getInt16(offset = 0) {\n    return op_ffi_read_i16(\n      this.pointer,\n      offset,\n    );\n  }\n\n  getUint32(offset = 0) {\n    return op_ffi_read_u32(\n      this.pointer,\n      offset,\n    );\n  }\n\n  getInt32(offset = 0) {\n    return op_ffi_read_i32(\n      this.pointer,\n      offset,\n    );\n  }\n\n  getBigUint64(offset = 0) {\n    return op_ffi_read_u64(\n      this.pointer,\n      // We return a BigInt, so the turbocall\n      // is forced to use BigInts everywhere.\n      BigInt(offset),\n    );\n  }\n\n  getBigInt64(offset = 0) {\n    return op_ffi_read_i64(\n      this.pointer,\n      // We return a BigInt, so the turbocall\n      // is forced to use BigInts everywhere.\n      BigInt(offset),\n    );\n  }\n\n  getFloat32(offset = 0) {\n    return op_ffi_read_f32(\n      this.pointer,\n      offset,\n    );\n  }\n\n  getFloat64(offset = 0) {\n    return op_ffi_read_f64(\n      this.pointer,\n      offset,\n    );\n  }\n\n  getPointer(offset = 0) {\n    return op_ffi_read_ptr(\n      this.pointer,\n      offset,\n    );\n  }\n\n  getCString(offset = 0) {\n    return op_ffi_cstr_read(\n      this.pointer,\n      offset,\n    );\n  }\n\n  static getCString(pointer, offset = 0) {\n    return op_ffi_cstr_read(\n      pointer,\n      offset,\n    );\n  }\n\n  getArrayBuffer(byteLength, offset = 0) {\n    return op_ffi_get_buf(\n      this.pointer,\n      offset,\n      byteLength,\n    );\n  }\n\n  static getArrayBuffer(pointer, byteLength, offset = 0) {\n    return op_ffi_get_buf(\n      pointer,\n      offset,\n      byteLength,\n    );\n  }\n\n  copyInto(destination, offset = 0) {\n    op_ffi_buf_copy_into(\n      this.pointer,\n      offset,\n      destination,\n      getBufferSourceByteLength(destination),\n    );\n  }\n\n  static copyInto(pointer, destination, offset = 0) {\n    op_ffi_buf_copy_into(\n      pointer,\n      offset,\n      destination,\n      getBufferSourceByteLength(destination),\n    );\n  }\n}",
"Deno.UnsafeFnPointer": "class UnsafeFnPointer {\n  pointer;\n  definition;\n  #structSize;\n\n  constructor(pointer, definition) {\n    this.pointer = pointer;\n    this.definition = definition;\n    this.#structSize = isStruct(definition.result)\n      ? getTypeSizeAndAlignment(definition.result)[0]\n      : null;\n  }\n\n  call(...parameters) {\n    if (this.definition.nonblocking) {\n      if (this.#structSize === null) {\n        return op_ffi_call_ptr_nonblocking(\n          this.pointer,\n          this.definition,\n          parameters,\n        );\n      } else {\n        const buffer = new Uint8Array(this.#structSize);\n        return PromisePrototypeThen(\n          op_ffi_call_ptr_nonblocking(\n            this.pointer,\n            this.definition,\n            parameters,\n            buffer,\n          ),\n          () => buffer,\n        );\n      }\n    } else {\n      if (this.#structSize === null) {\n        return op_ffi_call_ptr(\n          this.pointer,\n          this.definition,\n          parameters,\n        );\n      } else {\n        const buffer = new Uint8Array(this.#structSize);\n        op_ffi_call_ptr(\n          this.pointer,\n          this.definition,\n          parameters,\n          buffer,\n        );\n        return buffer;\n      }\n    }\n  }\n}",
"Deno.umask": "function umask(mask) {\n  return op_fs_umask(mask);\n}",
"Deno.HttpClient": "class HttpClient {\n  #rid;\n\n  /**\n   * @param {number} rid\n   */\n  constructor(rid) {\n    ObjectDefineProperty(this, internalRidSymbol, {\n      __proto__: null,\n      enumerable: false,\n      value: rid,\n    });\n    this.#rid = rid;\n  }\n\n  close() {\n    core.close(this.#rid);\n  }\n\n  [SymbolDispose]() {\n    core.tryClose(this.#rid);\n  }\n}",
"Deno.createHttpClient": "function createHttpClient(options) {\n  options.caCerts ??= [];\n  const keyPair = loadTlsKeyPair(\"Deno.createHttpClient\", options);\n  return new HttpClient(\n    op_fetch_custom_client(\n      options,\n      keyPair,\n    ),\n  );\n}",
"Deno.test": "function test(\n  nameOrFnOrOptions,\n  optionsOrFn,\n  maybeFn,\n) {\n  return testInner(nameOrFnOrOptions, optionsOrFn, maybeFn);\n}",
"Deno.bench": "function bench(\n  nameOrFnOrOptions,\n  optionsOrFn,\n  maybeFn,\n) {\n  // No-op if we're not running in `deno bench` subcommand.\n  if (typeof op_register_bench !== \"function\") {\n    return;\n  }\n\n  if (!registeredWarmupBench) {\n    registeredWarmupBench = true;\n    const warmupBenchDesc = {\n      name: \"<warmup>\",\n      fn: function warmup() {},\n      async: false,\n      ignore: false,\n      baseline: false,\n      only: false,\n      sanitizeExit: true,\n      permissions: null,\n      warmup: true,\n    };\n    if (cachedOrigin == undefined) {\n      cachedOrigin = op_bench_get_origin();\n    }\n    warmupBenchDesc.fn = wrapBenchmark(warmupBenchDesc);\n    op_register_bench(\n      warmupBenchDesc.fn,\n      warmupBenchDesc.name,\n      warmupBenchDesc.baseline,\n      warmupBenchDesc.group,\n      warmupBenchDesc.ignore,\n      warmupBenchDesc.only,\n      warmupBenchDesc.warmup,\n      registerBenchIdRetBufU8,\n    );\n    warmupBenchDesc.id = registerBenchIdRetBufU8[0];\n    warmupBenchDesc.origin = cachedOrigin;\n  }\n\n  let benchDesc;\n  const defaults = {\n    ignore: false,\n    baseline: false,\n    only: false,\n    sanitizeExit: true,\n    permissions: null,\n  };\n\n  if (typeof nameOrFnOrOptions === \"string\") {\n    if (!nameOrFnOrOptions) {\n      throw new TypeError(\"The bench name can't be empty\");\n    }\n    if (typeof optionsOrFn === \"function\") {\n      benchDesc = { fn: optionsOrFn, name: nameOrFnOrOptions, ...defaults };\n    } else {\n      if (!maybeFn || typeof maybeFn !== \"function\") {\n        throw new TypeError(\"Missing bench function\");\n      }\n      if (optionsOrFn.fn != undefined) {\n        throw new TypeError(\n          \"Unexpected 'fn' field in options, bench function is already provided as the third argument\",\n        );\n      }\n      if (optionsOrFn.name != undefined) {\n        throw new TypeError(\n          \"Unexpected 'name' field in options, bench name is already provided as the first argument\",\n        );\n      }\n      benchDesc = {\n        ...defaults,\n        ...optionsOrFn,\n        fn: maybeFn,\n        name: nameOrFnOrOptions,\n      };\n    }\n  } else if (typeof nameOrFnOrOptions === \"function\") {\n    if (!nameOrFnOrOptions.name) {\n      throw new TypeError(\"The bench function must have a name\");\n    }\n    if (optionsOrFn != undefined) {\n      throw new TypeError(\"Unexpected second argument to Deno.bench()\");\n    }\n    if (maybeFn != undefined) {\n      throw new TypeError(\"Unexpected third argument to Deno.bench()\");\n    }\n    benchDesc = {\n      ...defaults,\n      fn: nameOrFnOrOptions,\n      name: nameOrFnOrOptions.name,\n    };\n  } else {\n    let fn;\n    let name;\n    if (typeof optionsOrFn === \"function\") {\n      fn = optionsOrFn;\n      if (nameOrFnOrOptions.fn != undefined) {\n        throw new TypeError(\n          \"Unexpected 'fn' field in options, bench function is already provided as the second argument\",\n        );\n      }\n      name = nameOrFnOrOptions.name ?? fn.name;\n    } else {\n      if (\n        !nameOrFnOrOptions.fn || typeof nameOrFnOrOptions.fn !== \"function\"\n      ) {\n        throw new TypeError(\n          \"Expected 'fn' field in the first argument to be a bench function\",\n        );\n      }\n      fn = nameOrFnOrOptions.fn;\n      name = nameOrFnOrOptions.name ?? fn.name;\n    }\n    if (!name) {\n      throw new TypeError(\"The bench name can't be empty\");\n    }\n    benchDesc = { ...defaults, ...nameOrFnOrOptions, fn, name };\n  }\n\n  const AsyncFunction = (async () => {}).constructor;\n  benchDesc.async = AsyncFunction === benchDesc.fn.constructor;\n  benchDesc.fn = wrapBenchmark(benchDesc);\n  benchDesc.warmup = false;\n  benchDesc.name = escapeName(benchDesc.name);\n  if (cachedOrigin == undefined) {\n    cachedOrigin = op_bench_get_origin();\n  }\n  op_register_bench(\n    benchDesc.fn,\n    benchDesc.name,\n    benchDesc.baseline,\n    benchDesc.group,\n    benchDesc.ignore,\n    benchDesc.only,\n    false,\n    registerBenchIdRetBufU8,\n  );\n  benchDesc.id = registerBenchIdRetBufU8[0];\n  benchDesc.origin = cachedOrigin;\n}",
"Deno.pid": "49634",
"Deno.ppid": "49616",
"Deno.noColor": "false",
"Deno.args": {},
"Deno.mainModule": "file:///Users/zhorton/testing/notebooks/$deno$jupyter.ts",
"jsr:@std/archive": {
	"Tar": "class Tar {\n  /** Tar data. */ #data;\n  /** Constructs a new instance. */ constructor(){\n    this.#data = [];\n  }\n  /**\n   * Append a file or reader of arbitrary content to this tar archive. Directories\n   * appended to the archive append only the directory itself to the archive, not\n   * its contents.  To add a directory and its contents, recursively append the\n   * directory's contents.  Directories and subdirectories will be created automatically\n   * in the archive as required.\n   *\n   * @param filenameInArchive File name of the content in the archive. E.g.\n   * `test.txt`. Use slash for directory separators.\n   * @param source Details of the source of the content including the\n   * reference to the content itself and potentially any related metadata.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { Tar } from \"@std/archive/tar\";\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { copy } from \"@std/io/copy\";\n   *\n   * const tar = new Tar();\n   *\n   * // Now that we've created our tar, let's add some files to it:\n   *\n   * const content = new TextEncoder().encode(\"Some arbitrary content\");\n   * await tar.append(\"deno.txt\", {\n   *   reader: new Buffer(content),\n   *   contentSize: content.byteLength,\n   * });\n   *\n   * // This file is sourced from the filesystem (and renamed in the archive)\n   * await tar.append(\"filename_in_archive.txt\", {\n   *   filePath: \"./filename_on_filesystem.txt\",\n   * });\n   *\n   * // Now let's write the tar (with its two files) to the filesystem\n   * // use tar.getReader() to read the contents.\n   *\n   * const writer = await Deno.open(\"./out.tar\", { write: true, create: true });\n   * await copy(tar.getReader(), writer);\n   * writer.close();\n   * ```\n   */ async append(filenameInArchive, source) {\n    if (typeof filenameInArchive !== \"string\") {\n      throw new Error(\"Cannot append data: File name is not a string\");\n    }\n    let fileName = filenameInArchive;\n    /**\n     * Ustar format has a limitation of file name length. Specifically:\n     * 1. File names can contain at most 255 bytes.\n     * 2. File names longer than 100 bytes must be split at a directory separator in two parts,\n     * the first being at most 155 bytes long. So, in most cases file names must be a bit shorter\n     * than 255 bytes.\n     */ // separate file name into two parts if needed\n    let fileNamePrefix;\n    if (fileName.length > 100) {\n      let i = fileName.length;\n      while(i >= 0){\n        i = fileName.lastIndexOf(\"/\", i);\n        if (i <= 155) {\n          fileNamePrefix = fileName.slice(0, i);\n          fileName = fileName.slice(i + 1);\n          break;\n        }\n        i--;\n      }\n      const errMsg = \"Cannot append data: The 'ustar' format does not allow a long file name (length of [file name\" + \"prefix] + / + [file name] must be shorter than 256 bytes)\";\n      if (i < 0 || fileName.length > 100) {\n        throw new Error(errMsg);\n      } else {\n        if (fileNamePrefix === undefined) {\n          throw new TypeError(\"File name prefix is undefined\");\n        }\n        if (fileNamePrefix.length > 155) {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    source = source ?? {};\n    // set meta data\n    let info;\n    if (source.filePath) {\n      info = await Deno.stat(source.filePath);\n      if (info.isDirectory) {\n        info.size = 0;\n        source.reader = new Buffer();\n      }\n    }\n    const mode = source.fileMode || info && info.mode || parseInt(\"777\", 8) & 0xfff /* 511 */ ;\n    const mtime = Math.floor(source.mtime ?? (info?.mtime ?? new Date()).valueOf() / 1000);\n    const uid = source.uid ?? 0;\n    const gid = source.gid ?? 0;\n    if (typeof source.owner === \"string\" && source.owner.length >= 32) {\n      throw new Error(\"Cannot append data: The 'ustar' format does not allow owner name length >= 32 bytes\");\n    }\n    if (typeof source.group === \"string\" && source.group.length >= 32) {\n      throw new Error(\"Cannot append data: The 'ustar' format does not allow group name length >= 32 bytes\");\n    }\n    const fileSize = info?.size ?? source.contentSize;\n    if (fileSize === undefined) {\n      throw new TypeError(\"Cannot append data: The file size is not defined\");\n    }\n    const type = source.type ? FileTypes[source.type] : info?.isDirectory ? FileTypes.directory : FileTypes.file;\n    const tarData = {\n      fileName,\n      fileMode: pad(mode, 7),\n      uid: pad(uid, 7),\n      gid: pad(gid, 7),\n      fileSize: pad(fileSize, 11),\n      mtime: pad(mtime, 11),\n      checksum: \"        \",\n      type: type.toString(),\n      ustar: USTAR_MAGIC_HEADER,\n      owner: source.owner ?? \"\",\n      group: source.group ?? \"\"\n    };\n    if (fileNamePrefix !== undefined) {\n      tarData.fileNamePrefix = fileNamePrefix;\n    }\n    if (source.filePath !== undefined) {\n      tarData.filePath = source.filePath;\n    }\n    if (source.reader !== undefined) {\n      tarData.reader = source.reader;\n    }\n    // calculate the checksum\n    let checksum = 0;\n    const encoder = new TextEncoder();\n    Object.keys(tarData).filter((key)=>[\n        \"filePath\",\n        \"reader\"\n      ].indexOf(key) < 0).forEach(function(key) {\n      checksum += encoder.encode(tarData[key]).reduce((p, c)=>p + c, 0);\n    });\n    tarData.checksum = pad(checksum, 6) + \"\\u0000 \";\n    this.#data.push(tarData);\n  }\n  /**\n   * Get a {@linkcode Reader} instance for this tar archive.\n   *\n   * @returns A reader instance for the tar archive.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { Tar } from \"@std/archive/tar\";\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { copy } from \"@std/io/copy\";\n   *\n   * const tar = new Tar();\n   *\n   * // Now that we've created our tar, let's add some files to it:\n   *\n   * const content = new TextEncoder().encode(\"Some arbitrary content\");\n   * await tar.append(\"deno.txt\", {\n   *   reader: new Buffer(content),\n   *   contentSize: content.byteLength,\n   * });\n   *\n   * // This file is sourced from the filesystem (and renamed in the archive)\n   * await tar.append(\"filename_in_archive.txt\", {\n   *   filePath: \"./filename_on_filesystem.txt\",\n   * });\n   *\n   * // Now let's write the tar (with its two files) to the filesystem\n   * // use tar.getReader() to read the contents.\n   *\n   * const writer = await Deno.open(\"./out.tar\", { write: true, create: true });\n   * await copy(tar.getReader(), writer);\n   * writer.close();\n   * ```\n   */ getReader() {\n    const readers = [];\n    this.#data.forEach((tarData)=>{\n      let { reader } = tarData;\n      const { filePath } = tarData;\n      const headerArr = formatHeader(tarData);\n      readers.push(new Buffer(headerArr));\n      if (!reader) {\n        if (filePath === undefined) {\n          throw new TypeError(\"Cannot get the reader for the tar archive: FilePath is not defined\");\n        }\n        reader = new FileReader(filePath);\n      }\n      readers.push(reader);\n      // to the nearest multiple of recordSize\n      if (tarData.fileSize === undefined) {\n        throw new TypeError(\"Cannot get the reader for the tar archive: FileSize is not defined\");\n      }\n      readers.push(new Buffer(new Uint8Array(HEADER_LENGTH - (parseInt(tarData.fileSize, 8) % HEADER_LENGTH || HEADER_LENGTH))));\n    });\n    // append 2 empty records\n    readers.push(new Buffer(new Uint8Array(HEADER_LENGTH * 2)));\n    return new MultiReader(readers);\n  }\n}",
	"TarEntry": "class TarEntry {\n  #reader;\n  #size;\n  #read = 0;\n  #consumed = false;\n  #entrySize;\n  /**\n   * Constructs a new instance.\n   *\n   * @param meta The metadata of the entry.\n   * @param reader The reader to read the entry from.\n   */ constructor(meta, reader){\n    Object.assign(this, meta);\n    this.#reader = reader;\n    // File Size\n    this.#size = this.fileSize ?? 0;\n    // Entry Size\n    const blocks = Math.ceil(this.#size / HEADER_LENGTH);\n    this.#entrySize = blocks * HEADER_LENGTH;\n  }\n  /**\n   * Returns whether the entry has already been consumed.\n   *\n   * @returns Whether the entry has already been consumed.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { TarEntry } from \"@std/archive/untar\";\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const content = new TextEncoder().encode(\"hello tar world!\");\n   * const reader = new Buffer(content);\n   * const tarMeta = {\n   *   fileName: \"archive/\",\n   *   fileSize: 0,\n   *   fileMode: 509,\n   *   mtime: 1591800767,\n   *   uid: 1001,\n   *   gid: 1001,\n   *   owner: \"deno\",\n   *   group: \"deno\",\n   *   type: \"directory\",\n   * };\n   * const tarEntry: TarEntry = new TarEntry(tarMeta, reader);\n   *\n   * assertEquals(tarEntry.consumed, false);\n   * ```\n   */ get consumed() {\n    return this.#consumed;\n  }\n  /**\n   * Reads up to `p.byteLength` bytes of the tar entry into `p`. It resolves to\n   * the number of bytes read (`0 < n <= p.byteLength`) and rejects if any\n   * error encountered. Even if read() resolves to n < p.byteLength, it may use\n   * all of `p` as scratch space during the call. If some data is available but\n   * not `p.byteLength bytes`, read() conventionally resolves to what is available\n   * instead of waiting for more.\n   *\n   * @param p The buffer to read the entry into.\n   * @returns The number of bytes read (`0 < n <= p.byteLength`) or `null` if\n   * there are no more bytes to read.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { Tar, Untar } from \"@std/archive\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   * import { Buffer } from \"@std/io/buffer\";\n   *\n   * const content = new TextEncoder().encode(\"hello tar world!\");\n   *\n   * const tar = new Tar();\n   * tar.append(\"test.txt\", {\n   *   reader: new Buffer(content),\n   *   contentSize: content.byteLength,\n   * });\n   *\n   * const untar = new Untar(tar.getReader());\n   * const entry = await untar.extract();\n   * const buffer = new Uint8Array(1024);\n   * const n = await entry!.read(buffer);\n   *\n   * assertEquals(buffer.subarray(0, n!), content);\n   * ```\n   */ async read(p) {\n    // Bytes left for entry\n    const entryBytesLeft = this.#entrySize - this.#read;\n    const bufSize = Math.min(// bufSize can't be greater than p.length nor bytes left in the entry\n    p.length, entryBytesLeft);\n    if (entryBytesLeft <= 0) {\n      this.#consumed = true;\n      return null;\n    }\n    const block = new Uint8Array(bufSize);\n    const n = await readBlock(this.#reader, block);\n    const bytesLeft = this.#size - this.#read;\n    this.#read += n ?? 0;\n    if (n === null || bytesLeft <= 0) {\n      if (n === null) this.#consumed = true;\n      return null;\n    }\n    // Remove zero filled\n    const offset = bytesLeft < n ? bytesLeft : n;\n    p.set(block.subarray(0, offset), 0);\n    return offset < 0 ? n - Math.abs(offset) : offset;\n  }\n  /**\n   * Discords the current entry.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { TarEntry } from \"@std/archive/untar\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const text = \"Hello, world!\";\n   *\n   * const reader = new Buffer(new TextEncoder().encode(text));\n   * const tarMeta = {\n   *   fileName: \"text\",\n   *   fileSize: 0,\n   *   fileMode: 509,\n   *   mtime: 1591800767,\n   *   uid: 1001,\n   *   gid: 1001,\n   *   owner: \"deno\",\n   *   group: \"deno\",\n   *   type: \"file\",\n   * };\n   *\n   * const tarEntry: TarEntry = new TarEntry(tarMeta, reader);\n   * await tarEntry.discard();\n   *\n   * assertEquals(tarEntry.consumed, true);\n   * ```\n   */ async discard() {\n    // Discard current entry\n    if (this.#consumed) return;\n    this.#consumed = true;\n    if (typeof this.#reader.seek === \"function\") {\n      await this.#reader.seek(this.#entrySize - this.#read, Deno.SeekMode.Current);\n      this.#read = this.#entrySize;\n    } else {\n      await readAll(this);\n    }\n  }\n}",
	"Untar": "class Untar {\n  /** Internal reader. */ #reader;\n  /** Internal block. */ #block;\n  #entry;\n  /**\n   * Constructs a new instance.\n   *\n   * @param reader The reader to extract from.\n   */ constructor(reader){\n    this.#reader = reader;\n    this.#block = new Uint8Array(HEADER_LENGTH);\n  }\n  #checksum(header) {\n    let sum = initialChecksum;\n    for(let i = 0; i < HEADER_LENGTH; i++){\n      if (i >= 148 && i < 156) {\n        continue;\n      }\n      sum += header[i];\n    }\n    return sum;\n  }\n  async #getAndValidateHeader() {\n    await readBlock(this.#reader, this.#block);\n    const header = parseHeader(this.#block);\n    // calculate the checksum\n    const decoder = new TextDecoder();\n    const checksum = this.#checksum(this.#block);\n    if (parseInt(decoder.decode(header.checksum), 8) !== checksum) {\n      if (checksum === initialChecksum) {\n        // EOF\n        return null;\n      }\n      throw new Error(\"Cannot validate checksum\");\n    }\n    const magic = decoder.decode(header.ustar);\n    if (magic.indexOf(\"ustar\")) {\n      throw new Error(`Cannot validate the header as it has unsupported archive format: ${magic}`);\n    }\n    return header;\n  }\n  #getMetadata(header) {\n    const decoder = new TextDecoder();\n    // get meta data\n    const meta = {\n      fileName: decoder.decode(trim(header.fileName))\n    };\n    const fileNamePrefix = trim(header.fileNamePrefix);\n    if (fileNamePrefix.byteLength > 0) {\n      meta.fileName = decoder.decode(fileNamePrefix) + \"/\" + meta.fileName;\n    }\n    [\n      \"fileMode\",\n      \"mtime\",\n      \"uid\",\n      \"gid\"\n    ].forEach((key)=>{\n      const arr = trim(header[key]);\n      if (arr.byteLength > 0) {\n        meta[key] = parseInt(decoder.decode(arr), 8);\n      }\n    });\n    [\n      \"owner\",\n      \"group\",\n      \"type\"\n    ].forEach((key)=>{\n      const arr = trim(header[key]);\n      if (arr.byteLength > 0) {\n        meta[key] = decoder.decode(arr);\n      }\n    });\n    meta.fileSize = parseInt(decoder.decode(header.fileSize), 8);\n    if (meta.type !== undefined) {\n      meta.type = FileTypes[parseInt(meta.type)] ?? meta.type;\n    }\n    // Only create the `linkName` property for symbolic links to minimize\n    // the effect on existing code that only deals with non-links.\n    if (meta.type === \"symlink\") {\n      meta.linkName = decoder.decode(trim(header.linkName));\n    }\n    return meta;\n  }\n  /**\n   * Extract the next entry of the tar archive.\n   *\n   * @returns A TarEntry with header metadata and a reader to the entry's body,\n   * or null if there are no more entries to extract.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { Tar, Untar } from \"@std/archive\";\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { readAll } from \"@std/io/read-all\";\n   * import { assertEquals, assertNotEquals } from \"@std/assert\";\n   *\n   * const content = new TextEncoder().encode(\"hello tar world!\");\n   *\n   * // Create a tar archive\n   * const tar = new Tar();\n   * await tar.append(\"output.txt\", {\n   *   reader: new Buffer(content),\n   *   contentSize: content.byteLength,\n   * });\n   *\n   * // Read data from a tar archive\n   * const untar = new Untar(tar.getReader());\n   * const result = await untar.extract();\n   *\n   * assertNotEquals(result, null);\n   * assertEquals(result!.fileName, \"output.txt\");\n   * assertEquals(result!.fileSize, content.byteLength);\n   * assertEquals(result!.type, \"file\");\n   * assertEquals(await readAll(result!), content);\n   * ```\n   */ async extract() {\n    if (this.#entry && !this.#entry.consumed) {\n      // If entry body was not read, discard the body\n      // so we can read the next entry.\n      await this.#entry.discard();\n    }\n    const header = await this.#getAndValidateHeader();\n    if (header === null) return null;\n    const meta = this.#getMetadata(header);\n    this.#entry = new TarEntry(meta, this.#reader);\n    return this.#entry;\n  }\n  /**\n   * Iterate over all entries of the tar archive.\n   *\n   * @yields A TarEntry with tar header metadata and a reader to the entry's body.\n   * @returns An async iterator.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { Untar } from \"@std/archive/untar\";\n   * import { ensureFile } from \"@std/fs/ensure-file\";\n   * import { ensureDir } from \"@std/fs/ensure-dir\";\n   * import { copy } from \"@std/io/copy\";\n   *\n   * using reader = await Deno.open(\"./out.tar\", { read: true });\n   * const untar = new Untar(reader);\n   *\n   * for await (const entry of untar) {\n   *   console.log(entry); // metadata\n   *\n   *   if (entry.type === \"directory\") {\n   *     await ensureDir(entry.fileName);\n   *     continue;\n   *   }\n   *\n   *   await ensureFile(entry.fileName);\n   *   using file = await Deno.open(entry.fileName, { write: true });\n   *   // <entry> is a reader.\n   *   await copy(entry, file);\n   * }\n   * ```\n   */ async *[_computedKey]() {\n    while(true){\n      const entry = await this.extract();\n      if (entry === null) return;\n      yield entry;\n    }\n  }\n}"
},
"jsr:@std/yaml": {
	"parse": "function parse(content, options = {}) {\n  content = sanitizeInput(content);\n  const state = new LoaderState(content, {\n    ...options,\n    schema: SCHEMA_MAP.get(options.schema)\n  });\n  const documentGenerator = state.readDocuments();\n  const document = documentGenerator.next().value;\n  if (!documentGenerator.next().done) {\n    throw new SyntaxError(\"Found more than 1 document in the stream: expected a single document\");\n  }\n  return document ?? null;\n}",
	"parseAll": "function parseAll(content, options = {}) {\n  content = sanitizeInput(content);\n  const state = new LoaderState(content, {\n    ...options,\n    schema: SCHEMA_MAP.get(options.schema)\n  });\n  return [\n    ...state.readDocuments()\n  ];\n}",
	"stringify": "function stringify(data, options = {}) {\n  const state = new DumperState({\n    ...options,\n    schema: SCHEMA_MAP.get(options.schema)\n  });\n  return state.stringify(data);\n}"
},
"jsr:@std/webgpu": {
	"BYTES_PER_PIXEL": "4",
	"COPY_BYTES_PER_ROW_ALIGNMENT": "256",
	"createCapture": "function createCapture(device, width, height) {\n  const { padded } = getRowPadding(width);\n  const outputBuffer = device.createBuffer({\n    label: \"Capture\",\n    size: padded * height,\n    usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST\n  });\n  const texture = device.createTexture({\n    label: \"Capture\",\n    size: {\n      width,\n      height\n    },\n    format: \"rgba8unorm-srgb\",\n    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.COPY_SRC\n  });\n  return {\n    texture,\n    outputBuffer\n  };\n}",
	"createTextureWithData": "function createTextureWithData(device, descriptor, data) {\n  descriptor.usage |= GPUTextureUsage.COPY_DST;\n  const texture = device.createTexture(descriptor);\n  const layerIterations = textureDimensionArrayLayerCount(descriptor);\n  const formatInfo = describeTextureFormat(descriptor.format);\n  let binaryOffset = 0;\n  for(let layer = 0; layer < layerIterations; layer++){\n    for(let mip = 0; mip < (descriptor.mipLevelCount ?? 1); mip++){\n      const mipSize = textureMipLevelSize(descriptor, mip);\n      if (descriptor.dimension !== \"3d\") {\n        mipSize.depthOrArrayLayers = 1;\n      }\n      const mipPhysical = extent3DPhysicalSize(mipSize, descriptor.format);\n      const widthBlocks = Math.floor(mipPhysical.width / formatInfo.blockDimensions[0]);\n      const heightBlocks = Math.floor(mipPhysical.height / formatInfo.blockDimensions[1]);\n      const bytesPerRow = widthBlocks * formatInfo.blockSize;\n      const dataSize = bytesPerRow * heightBlocks * mipSize.depthOrArrayLayers;\n      const endOffset = binaryOffset + dataSize;\n      device.queue.writeTexture({\n        texture,\n        mipLevel: mip,\n        origin: {\n          x: 0,\n          y: 0,\n          z: layer\n        }\n      }, data.subarray(binaryOffset, endOffset), {\n        bytesPerRow,\n        rowsPerImage: heightBlocks\n      }, mipPhysical);\n      binaryOffset = endOffset;\n    }\n  }\n  return texture;\n}",
	"describeTextureFormat": "function describeTextureFormat(format) {\n  let info;\n  switch(format){\n    case \"r8unorm\":\n      info = [\n        undefined,\n        \"float\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        1,\n        1\n      ];\n      break;\n    case \"r8snorm\":\n      info = [\n        undefined,\n        \"float\",\n        basic,\n        [\n          1,\n          1\n        ],\n        1,\n        1\n      ];\n      break;\n    case \"r8uint\":\n      info = [\n        undefined,\n        \"uint\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        1,\n        1\n      ];\n      break;\n    case \"r8sint\":\n      info = [\n        undefined,\n        \"sint\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        1,\n        1\n      ];\n      break;\n    case \"r16uint\":\n      info = [\n        undefined,\n        \"uint\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        2,\n        1\n      ];\n      break;\n    case \"r16sint\":\n      info = [\n        undefined,\n        \"sint\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        2,\n        1\n      ];\n      break;\n    case \"r16float\":\n      info = [\n        undefined,\n        \"float\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        2,\n        1\n      ];\n      break;\n    case \"rg8unorm\":\n      info = [\n        undefined,\n        \"float\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        2,\n        2\n      ];\n      break;\n    case \"rg8snorm\":\n      info = [\n        undefined,\n        \"float\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        2,\n        2\n      ];\n      break;\n    case \"rg8uint\":\n      info = [\n        undefined,\n        \"uint\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        2,\n        2\n      ];\n      break;\n    case \"rg8sint\":\n      info = [\n        undefined,\n        \"sint\",\n        basic,\n        [\n          1,\n          1\n        ],\n        2,\n        2\n      ];\n      break;\n    case \"r32uint\":\n      info = [\n        undefined,\n        \"uint\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        4,\n        1\n      ];\n      break;\n    case \"r32sint\":\n      info = [\n        undefined,\n        \"sint\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        4,\n        1\n      ];\n      break;\n    case \"r32float\":\n      info = [\n        undefined,\n        \"unfilterable-float\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        4,\n        1\n      ];\n      break;\n    case \"rg16uint\":\n      info = [\n        undefined,\n        \"uint\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        4,\n        2\n      ];\n      break;\n    case \"rg16sint\":\n      info = [\n        undefined,\n        \"sint\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        4,\n        2\n      ];\n      break;\n    case \"rg16float\":\n      info = [\n        undefined,\n        \"float\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        4,\n        2\n      ];\n      break;\n    case \"rgba8unorm\":\n      info = [\n        undefined,\n        \"float\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        4,\n        4\n      ];\n      break;\n    case \"rgba8unorm-srgb\":\n      info = [\n        undefined,\n        \"float\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        4,\n        4\n      ];\n      break;\n    case \"rgba8snorm\":\n      info = [\n        undefined,\n        \"float\",\n        storage,\n        [\n          1,\n          1\n        ],\n        4,\n        4\n      ];\n      break;\n    case \"rgba8uint\":\n      info = [\n        undefined,\n        \"uint\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        4,\n        4\n      ];\n      break;\n    case \"rgba8sint\":\n      info = [\n        undefined,\n        \"sint\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        4,\n        4\n      ];\n      break;\n    case \"bgra8unorm\":\n      info = [\n        undefined,\n        \"float\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        4,\n        4\n      ];\n      break;\n    case \"bgra8unorm-srgb\":\n      info = [\n        undefined,\n        \"float\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        4,\n        4\n      ];\n      break;\n    case \"rgb9e5ufloat\":\n      info = [\n        undefined,\n        \"float\",\n        basic,\n        [\n          1,\n          1\n        ],\n        4,\n        3\n      ];\n      break;\n    case \"rgb10a2unorm\":\n      info = [\n        undefined,\n        \"float\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        4,\n        4\n      ];\n      break;\n    case \"rg11b10ufloat\":\n      info = [\n        undefined,\n        \"float\",\n        basic,\n        [\n          1,\n          1\n        ],\n        4,\n        3\n      ];\n      break;\n    case \"rg32uint\":\n      info = [\n        undefined,\n        \"uint\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        8,\n        2\n      ];\n      break;\n    case \"rg32sint\":\n      info = [\n        undefined,\n        \"sint\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        8,\n        2\n      ];\n      break;\n    case \"rg32float\":\n      info = [\n        undefined,\n        \"unfilterable-float\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        8,\n        2\n      ];\n      break;\n    case \"rgba16uint\":\n      info = [\n        undefined,\n        \"uint\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        8,\n        4\n      ];\n      break;\n    case \"rgba16sint\":\n      info = [\n        undefined,\n        \"sint\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        8,\n        4\n      ];\n      break;\n    case \"rgba16float\":\n      info = [\n        undefined,\n        \"float\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        8,\n        4\n      ];\n      break;\n    case \"rgba32uint\":\n      info = [\n        undefined,\n        \"uint\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"rgba32sint\":\n      info = [\n        undefined,\n        \"sint\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"rgba32float\":\n      info = [\n        undefined,\n        \"float\",\n        allFlags,\n        [\n          1,\n          1\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"stencil8\":\n      info = [\n        undefined,\n        \"uint\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        1,\n        1\n      ];\n      break;\n    case \"depth16unorm\":\n      info = [\n        undefined,\n        \"depth\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        2,\n        1\n      ];\n      break;\n    case \"depth24plus\":\n      info = [\n        undefined,\n        \"depth\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        4,\n        1\n      ];\n      break;\n    case \"depth24plus-stencil8\":\n      info = [\n        undefined,\n        \"depth\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        4,\n        2\n      ];\n      break;\n    case \"depth32float\":\n      info = [\n        undefined,\n        \"depth\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        4,\n        1\n      ];\n      break;\n    case \"depth32float-stencil8\":\n      info = [\n        \"depth32float-stencil8\",\n        \"depth\",\n        attachment,\n        [\n          1,\n          1\n        ],\n        4,\n        2\n      ];\n      break;\n    case \"bc1-rgba-unorm\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        8,\n        4\n      ];\n      break;\n    case \"bc1-rgba-unorm-srgb\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        8,\n        4\n      ];\n      break;\n    case \"bc2-rgba-unorm\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"bc2-rgba-unorm-srgb\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"bc3-rgba-unorm\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"bc3-rgba-unorm-srgb\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"bc4-r-unorm\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        8,\n        1\n      ];\n      break;\n    case \"bc4-r-snorm\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        8,\n        1\n      ];\n      break;\n    case \"bc5-rg-unorm\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        2\n      ];\n      break;\n    case \"bc5-rg-snorm\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        2\n      ];\n      break;\n    case \"bc6h-rgb-ufloat\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        3\n      ];\n      break;\n    case \"bc6h-rgb-float\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        3\n      ];\n      break;\n    case \"bc7-rgba-unorm\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"bc7-rgba-unorm-srgb\":\n      info = [\n        \"texture-compression-bc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"etc2-rgb8unorm\":\n      info = [\n        \"texture-compression-etc2\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        8,\n        3\n      ];\n      break;\n    case \"etc2-rgb8unorm-srgb\":\n      info = [\n        \"texture-compression-etc2\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        8,\n        3\n      ];\n      break;\n    case \"etc2-rgb8a1unorm\":\n      info = [\n        \"texture-compression-etc2\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        8,\n        4\n      ];\n      break;\n    case \"etc2-rgb8a1unorm-srgb\":\n      info = [\n        \"texture-compression-etc2\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        8,\n        4\n      ];\n      break;\n    case \"etc2-rgba8unorm\":\n      info = [\n        \"texture-compression-etc2\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"etc2-rgba8unorm-srgb\":\n      info = [\n        \"texture-compression-etc2\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"eac-r11unorm\":\n      info = [\n        \"texture-compression-etc2\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        8,\n        1\n      ];\n      break;\n    case \"eac-r11snorm\":\n      info = [\n        \"texture-compression-etc2\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        8,\n        1\n      ];\n      break;\n    case \"eac-rg11unorm\":\n      info = [\n        \"texture-compression-etc2\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        2\n      ];\n      break;\n    case \"eac-rg11snorm\":\n      info = [\n        \"texture-compression-etc2\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        2\n      ];\n      break;\n    case \"astc-4x4-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-4x4-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          4,\n          4\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-5x4-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          5,\n          4\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-5x4-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          5,\n          4\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-5x5-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          5,\n          5\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-5x5-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          5,\n          5\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-6x5-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          6,\n          5\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-6x5-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          6,\n          5\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-6x6-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          6,\n          6\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-6x6-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          6,\n          6\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-8x5-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          8,\n          5\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-8x5-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          8,\n          5\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-8x6-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          8,\n          6\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-8x6-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          8,\n          6\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-8x8-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          8,\n          8\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-8x8-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          8,\n          8\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-10x5-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          10,\n          5\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-10x5-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          10,\n          5\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-10x6-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          10,\n          6\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-10x6-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          10,\n          6\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-10x8-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          10,\n          8\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-10x8-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          10,\n          8\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-10x10-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          10,\n          10\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-10x10-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          10,\n          10\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-12x10-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          12,\n          10\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-12x10-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          12,\n          10\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-12x12-unorm\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          12,\n          12\n        ],\n        16,\n        4\n      ];\n      break;\n    case \"astc-12x12-unorm-srgb\":\n      info = [\n        \"texture-compression-astc\",\n        \"float\",\n        basic,\n        [\n          12,\n          12\n        ],\n        16,\n        4\n      ];\n      break;\n    default:\n      throw new TypeError(`Unsupported GPUTextureFormat '${format}'`);\n  }\n  const ret = {\n    sampleType: info[1],\n    allowedUsages: info[2],\n    blockDimensions: info[3],\n    blockSize: info[4],\n    components: info[5]\n  };\n  if (info[0] !== undefined) {\n    ret.requiredFeature = info[0];\n  }\n  return ret;\n}",
	"getRowPadding": "function getRowPadding(width) {\n  // It is a WebGPU requirement that\n  // GPUImageCopyBuffer.layout.bytesPerRow % COPY_BYTES_PER_ROW_ALIGNMENT == 0\n  // So we calculate paddedBytesPerRow by rounding unpaddedBytesPerRow\n  // up to the next multiple of COPY_BYTES_PER_ROW_ALIGNMENT.\n  const unpaddedBytesPerRow = width * BYTES_PER_PIXEL;\n  const paddedBytesPerRowPadding = (COPY_BYTES_PER_ROW_ALIGNMENT - unpaddedBytesPerRow % COPY_BYTES_PER_ROW_ALIGNMENT) % COPY_BYTES_PER_ROW_ALIGNMENT;\n  const paddedBytesPerRow = unpaddedBytesPerRow + paddedBytesPerRowPadding;\n  return {\n    unpadded: unpaddedBytesPerRow,\n    padded: paddedBytesPerRow\n  };\n}",
	"resliceBufferWithPadding": "function resliceBufferWithPadding(buffer, width, height) {\n  const { padded, unpadded } = getRowPadding(width);\n  const outputBuffer = new Uint8Array(unpadded * height);\n  for(let i = 0; i < height; i++){\n    const slice = buffer.slice(i * padded, (i + 1) * padded).slice(0, unpadded);\n    outputBuffer.set(slice, i * unpadded);\n  }\n  return outputBuffer;\n}"
},
"jsr:@std/uuid": {
	"NAMESPACE_DNS": "6ba7b810-9dad-11d1-80b4-00c04fd430c8",
	"NAMESPACE_OID": "6ba7b812-9dad-11d1-80b4-00c04fd430c8",
	"NAMESPACE_URL": "6ba7b811-9dad-11d1-80b4-00c04fd430c8",
	"NAMESPACE_X500": "6ba7b814-9dad-11d1-80b4-00c04fd430c8",
	"NIL_UUID": "00000000-0000-0000-0000-000000000000",
	"isNil": "function isNil(id) {\n  return id === NIL_UUID;\n}",
	"v1": {
	"generate": "function generate(options = {}) {\n  let i = 0;\n  const b = [];\n  let { node = _nodeId, clockseq = _clockseq } = options;\n  if (node === undefined || clockseq === undefined) {\n    // deno-lint-ignore no-explicit-any\n    const seedBytes = options.random ?? options.rng ?? crypto.getRandomValues(new Uint8Array(16));\n    if (node === undefined) {\n      node = _nodeId = [\n        seedBytes[0] | 0x01,\n        seedBytes[1],\n        seedBytes[2],\n        seedBytes[3],\n        seedBytes[4],\n        seedBytes[5]\n      ];\n    }\n    if (clockseq === undefined) {\n      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n    }\n  }\n  let { msecs = new Date().getTime(), nsecs = _lastNSecs + 1 } = options;\n  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000;\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  }\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  }\n  if (nsecs > 10000) {\n    throw new Error(\"Can't create more than 10M uuids/sec\");\n  }\n  if (node.length !== 6) {\n    throw new Error(\"Cannot create UUID: the node option must be an array of 6 bytes\");\n  }\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq;\n  // We have to add this value because \"msecs\" here is the number of\n  // milliseconds since January 1, 1970, not since October 15, 1582.\n  // This is also the milliseconds from October 15, 1582 to January 1, 1970.\n  msecs += 12219292800000;\n  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff;\n  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff;\n  b[i++] = tmh >>> 24 & 0xf | 0x10;\n  b[i++] = tmh >>> 16 & 0xff;\n  b[i++] = clockseq >>> 8 | 0x80;\n  b[i++] = clockseq & 0xff;\n  for(let n = 0; n < 6; ++n){\n    b[i + n] = node[n];\n  }\n  return bytesToUuid(b);\n}",
	"validate": "function validate(id) {\n  return UUID_RE.test(id);\n}"
	},
	"v3": {
	"generate": "async function generate(namespace, data) {\n  if (!validateCommon(namespace)) {\n    throw new TypeError(`Cannot generate UUID: invalid namespace ${namespace}`);\n  }\n  const namespaceBytes = uuidToBytes(namespace);\n  const toHash = concat([\n    namespaceBytes,\n    data\n  ]);\n  const buffer = await crypto.subtle.digest(\"MD5\", toHash);\n  const bytes = new Uint8Array(buffer);\n  bytes[6] = bytes[6] & 0x0f | 0x30;\n  bytes[8] = bytes[8] & 0x3f | 0x80;\n  return bytesToUuid(bytes);\n}",
	"validate": "function validate(id) {\n  return UUID_RE.test(id);\n}"
	},
	"v4": {
	"validate": "function validate(id) {\n  return UUID_RE.test(id);\n}"
	},
	"v5": {
	"generate": "async function generate(namespace, data) {\n  if (!validateCommon(namespace)) {\n    throw new TypeError(`Cannot generate UUID: invalid namespace ${namespace}`);\n  }\n  const namespaceBytes = uuidToBytes(namespace);\n  const toHash = concat([\n    namespaceBytes,\n    data\n  ]);\n  const buffer = await crypto.subtle.digest(\"sha-1\", toHash);\n  const bytes = new Uint8Array(buffer);\n  bytes[6] = bytes[6] & 0x0f | 0x50;\n  bytes[8] = bytes[8] & 0x3f | 0x80;\n  return bytesToUuid(bytes);\n}",
	"validate": "function validate(id) {\n  return UUID_RE.test(id);\n}"
	},
	"validate": "function validate(uuid) {\n  return /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i.test(uuid);\n}",
	"version": "function version(uuid) {\n  if (!validate(uuid)) {\n    throw new TypeError(`Cannot detect UUID version: received ${uuid}`);\n  }\n  return parseInt(uuid[14], 16);\n}"
},
"jsr:@std/ulid": {
	"decodeTime": "function decodeTime(ulid) {\n  if (ulid.length !== ULID_LEN) {\n    throw new Error(`ULID must be exactly ${ULID_LEN} characters long`);\n  }\n  const time = ulid.substring(0, TIME_LEN).split(\"\").reverse().reduce((carry, char, index)=>{\n    const encodingIndex = ENCODING.indexOf(char);\n    if (encodingIndex === -1) {\n      throw new Error(`Invalid ULID character found: ${char}`);\n    }\n    return carry += encodingIndex * Math.pow(ENCODING_LEN, index);\n  }, 0);\n  if (time > TIME_MAX) {\n    throw new RangeError(`ULID timestamp component exceeds maximum value of ${TIME_MAX}`);\n  }\n  return time;\n}",
	"monotonicUlid": "function monotonicUlid(seedTime = Date.now()) {\n  return defaultMonotonicUlid(seedTime);\n}",
	"ulid": "function ulid(seedTime = Date.now()) {\n  return encodeTime(seedTime) + encodeRandom();\n}"
},
"jsr:@std/toml": {
	"parse": "function parse(tomlString) {\n  return parserFactory(toml)(tomlString);\n}",
	"stringify": "function stringify(obj, options) {\n  return new Dumper(obj).dump(options).join(\"\\n\");\n}"
},
"jsr:@std/text": {
	"closestString": "function closestString(givenWord, possibleWords, options) {\n  if (possibleWords.length === 0) {\n    throw new TypeError(\"When using closestString(), the possibleWords array must contain at least one word\");\n  }\n  const { caseSensitive, compareFn = levenshteinDistance } = {\n    ...options\n  };\n  if (!caseSensitive) {\n    givenWord = givenWord.toLowerCase();\n  }\n  let nearestWord = possibleWords[0];\n  let closestStringDistance = Infinity;\n  for (const each of possibleWords){\n    const distance = caseSensitive ? compareFn(givenWord, each) : compareFn(givenWord, each.toLowerCase());\n    if (distance < closestStringDistance) {\n      nearestWord = each;\n      closestStringDistance = distance;\n    }\n  }\n  return nearestWord;\n}",
	"compareSimilarity": "function compareSimilarity(givenWord, options) {\n  const { compareFn = levenshteinDistance } = {\n    ...options\n  };\n  if (options?.caseSensitive) {\n    return (a, b)=>compareFn(givenWord, a) - compareFn(givenWord, b);\n  }\n  givenWord = givenWord.toLowerCase();\n  return (a, b)=>compareFn(givenWord, a.toLowerCase()) - compareFn(givenWord, b.toLowerCase());\n}",
	"levenshteinDistance": "function levenshteinDistance(str1, str2) {\n  let t = [\n    ...str1\n  ];\n  let p = [\n    ...str2\n  ];\n  if (t.length < p.length) {\n    [p, t] = [\n      t,\n      p\n    ];\n  }\n  if (p.length === 0) {\n    return t.length;\n  }\n  return p.length <= 32 ? myers32(t, p) : myersX(t, p);\n}",
	"toCamelCase": "function toCamelCase(input) {\n  input = input.trim();\n  const [first = \"\", ...rest] = splitToWords(input);\n  return [\n    first.toLocaleLowerCase(),\n    ...rest.map(capitalizeWord)\n  ].join(\"\");\n}",
	"toKebabCase": "function toKebabCase(input) {\n  input = input.trim();\n  return splitToWords(input).join(\"-\").toLocaleLowerCase();\n}",
	"toPascalCase": "function toPascalCase(input) {\n  input = input.trim();\n  return splitToWords(input).map(capitalizeWord).join(\"\");\n}",
	"toSnakeCase": "function toSnakeCase(input) {\n  input = input.trim();\n  return splitToWords(input).join(\"_\").toLocaleLowerCase();\n}",
	"wordSimilaritySort": "function wordSimilaritySort(givenWord, possibleWords, options) {\n  // This distance metric could be swapped/improved in the future\n  return possibleWords.toSorted(compareSimilarity(givenWord, options));\n}"
},
"jsr:@std/streams": {
	"Buffer": "class Buffer {\n  #buf;\n  #off = 0;\n  #readable = new ReadableStream({\n    type: \"bytes\",\n    pull: (controller)=>{\n      const view = new Uint8Array(controller.byobRequest.view.buffer);\n      if (this.empty()) {\n        // Buffer is empty, reset to recover space.\n        this.reset();\n        controller.close();\n        controller.byobRequest.respond(0);\n        return;\n      }\n      const nread = copy(this.#buf.subarray(this.#off), view);\n      this.#off += nread;\n      controller.byobRequest.respond(nread);\n    },\n    autoAllocateChunkSize: DEFAULT_CHUNK_SIZE\n  });\n  /**\n   * Getter returning the instance's {@linkcode ReadableStream}.\n   *\n   * @returns A `ReadableStream` of the buffer.\n   *\n   * @example Read the content out of the buffer to stdout\n   * ```ts ignore\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const buf = new Buffer();\n   * await buf.readable.pipeTo(Deno.stdout.writable);\n   * ```\n   */ get readable() {\n    return this.#readable;\n  }\n  #writable = new WritableStream({\n    write: (chunk)=>{\n      const m = this.#grow(chunk.byteLength);\n      copy(chunk, this.#buf, m);\n    }\n  });\n  /**\n   * Getter returning the instance's {@linkcode WritableStream}.\n   *\n   * @returns A `WritableStream` of the buffer.\n   *\n   * @example Write the data from stdin to the buffer\n   * ```ts ignore\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const buf = new Buffer();\n   * await Deno.stdin.readable.pipeTo(buf.writable);\n   * ```\n   */ get writable() {\n    return this.#writable;\n  }\n  /**\n   * Constructs a new instance.\n   *\n   * @param ab An optional buffer to use as the initial buffer.\n   */ constructor(ab){\n    this.#buf = ab === undefined ? new Uint8Array(0) : new Uint8Array(ab);\n  }\n  /**\n   * Returns a slice holding the unread portion of the buffer.\n   *\n   * The slice is valid for use only until the next buffer modification (that\n   * is, only until the next call to a method that mutates or consumes the\n   * buffer, like reading data out via `readable`, `reset()`, or `truncate()`).\n   *\n   * If `options.copy` is false the slice aliases the buffer content at least\n   * until the next buffer modification, so immediate changes to the slice will\n   * affect the result of future reads. If `options` is not provided,\n   * `options.copy` defaults to `true`.\n   *\n   * @param options Options for the bytes method.\n   * @returns A copy or a slice of the buffer.\n   *\n   * @example Copy the buffer\n   * ```ts\n   * import { assertEquals } from \"@std/assert\";\n   * import { assertNotEquals } from \"@std/assert\";\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const array = new Uint8Array([0, 1, 2]);\n   * const buf = new Buffer(array.buffer);\n   * const copied = buf.bytes();\n   * assertEquals(copied.length, array.length);\n   *\n   * // Modify an element in the original array\n   * array[1] = 99;\n   * assertEquals(copied[0], array[0]);\n   * // The copied buffer is not affected by the modification\n   * assertNotEquals(copied[1], array[1]);\n   * assertEquals(copied[2], array[2]);\n   * ```\n   *\n   * @example Get a slice to the buffer\n   * ```ts\n   * import { assertEquals } from \"@std/assert\";\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const array = new Uint8Array([0, 1, 2]);\n   * const buf = new Buffer(array.buffer);\n   * const slice = buf.bytes({ copy: false });\n   * assertEquals(slice.length, array.length);\n   *\n   * // Modify an element in the original array\n   * array[1] = 99;\n   * assertEquals(slice[0], array[0]);\n   * // The slice _is_ affected by the modification\n   * assertEquals(slice[1], array[1]);\n   * assertEquals(slice[2], array[2]);\n   * ```\n   */ bytes(options = {\n    copy: true\n  }) {\n    if (options.copy === false) return this.#buf.subarray(this.#off);\n    return this.#buf.slice(this.#off);\n  }\n  /**\n   * Returns whether the unread portion of the buffer is empty.\n   *\n   * @returns Whether the buffer is empty.\n   *\n   * @example Empty buffer\n   * ```ts\n   * import { assert } from \"@std/assert\";\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const buf = new Buffer();\n   * assert(buf.empty());\n   * ```\n   *\n   * @example Non-empty buffer\n   * ```ts\n   * import { assert } from \"@std/assert\";\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const array = new Uint8Array([42]);\n   * const buf = new Buffer(array.buffer);\n   * assert(!buf.empty());\n   * ```\n   *\n   * @example Non-empty, but the content was already read\n   * ```ts ignore\n   * import { assert } from \"@std/assert\";\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const array = new Uint8Array([42]);\n   * const buf = new Buffer(array.buffer);\n   * assert(!buf.empty());\n   * // Read the content out of the buffer\n   * await buf.readable.pipeTo(Deno.stdout.writable);\n   * // The buffer is now empty\n   * assert(buf.empty());\n   * ```\n   */ empty() {\n    return this.#buf.byteLength <= this.#off;\n  }\n  /**\n   * A read only number of bytes of the unread portion of the buffer.\n   *\n   * @returns The number of bytes in the unread portion of the buffer.\n   *\n   * @example Basic usage\n   * ```ts\n   * import { assertEquals } from \"@std/assert\";\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const array = new Uint8Array([0, 1, 2]);\n   * const buf = new Buffer(array.buffer);\n   * assertEquals(buf.length, 3);\n   * ```\n   *\n   * @example Length becomes 0 after the content is read\n   * ```ts ignore\n   * import { assertEquals } from \"@std/assert\";\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const array = new Uint8Array([42]);\n   * const buf = new Buffer(array.buffer);\n   * assertEquals(buf.length, 1);\n   * // Read the content out of the buffer\n   * await buf.readable.pipeTo(Deno.stdout.writable);\n   * // The length is now 0\n   * assertEquals(buf.length, 0);\n   * ```\n   */ get length() {\n    return this.#buf.byteLength - this.#off;\n  }\n  /**\n   * The read only capacity of the buffer's underlying byte slice, that is,\n   * the total space allocated for the buffer's data.\n   *\n   * @returns The number of allocated bytes for the buffer.\n   *\n   * @example Basic usage\n   * ```ts\n   * import { assertEquals } from \"@std/assert\";\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const arrayBuffer = new ArrayBuffer(256);\n   * const buf = new Buffer(arrayBuffer);\n   * assertEquals(buf.capacity, 256);\n   * ```\n   */ get capacity() {\n    return this.#buf.buffer.byteLength;\n  }\n  /**\n   * Discards all but the first `n` unread bytes from the buffer but\n   * continues to use the same allocated storage. It throws if `n` is\n   * negative or greater than the length of the buffer.\n   *\n   * @param n The number of bytes to keep.\n   *\n   * @example Basic usage\n   * ```ts\n   * import { assertEquals } from \"@std/assert\";\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const array = new Uint8Array([0, 1, 2]);\n   * const buf = new Buffer(array.buffer);\n   * assertEquals(buf.bytes(), array);\n   *\n   * // Discard all but the first 2 bytes\n   * buf.truncate(2);\n   * assertEquals(buf.bytes(), array.slice(0, 2));\n   * ```\n   */ truncate(n) {\n    if (n === 0) {\n      this.reset();\n      return;\n    }\n    if (n < 0 || n > this.length) {\n      throw new Error(`Buffer truncation value \"${n}\" is not between 0 and ${this.length}`);\n    }\n    this.#reslice(this.#off + n);\n  }\n  /**\n   * Resets to an empty buffer.\n   *\n   * @example Basic usage\n   * ```ts\n   * import { assert } from \"@std/assert\";\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const array = new Uint8Array([0, 1, 2]);\n   * const buf = new Buffer(array.buffer);\n   * assert(!buf.empty());\n   *\n   * // Reset\n   * buf.reset();\n   * assert(buf.empty());\n   * ```\n   */ reset() {\n    this.#reslice(0);\n    this.#off = 0;\n  }\n  #tryGrowByReslice(n) {\n    const l = this.#buf.byteLength;\n    if (n <= this.capacity - l) {\n      this.#reslice(l + n);\n      return l;\n    }\n    return -1;\n  }\n  #reslice(len) {\n    this.#buf = new Uint8Array(this.#buf.buffer, 0, len);\n  }\n  #grow(n) {\n    const m = this.length;\n    // If buffer is empty, reset to recover space.\n    if (m === 0 && this.#off !== 0) {\n      this.reset();\n    }\n    // Fast: Try to grow by means of a reslice.\n    const i = this.#tryGrowByReslice(n);\n    if (i >= 0) {\n      return i;\n    }\n    const c = this.capacity;\n    if (n <= Math.floor(c / 2) - m) {\n      // We can slide things down instead of allocating a new\n      // ArrayBuffer. We only need m+n <= c to slide, but\n      // we instead let capacity get twice as large so we\n      // don't spend all our time copying.\n      copy(this.#buf.subarray(this.#off), this.#buf);\n    } else if (c + n > MAX_SIZE) {\n      throw new Error(`The buffer cannot grow beyond the maximum size of ${MAX_SIZE}`);\n    } else {\n      // Not enough space anywhere, we need to allocate.\n      const buf = new Uint8Array(Math.min(2 * c + n, MAX_SIZE));\n      copy(this.#buf.subarray(this.#off), buf);\n      this.#buf = buf;\n    }\n    // Restore this.#off and len(this.#buf).\n    this.#off = 0;\n    this.#reslice(Math.min(m + n, MAX_SIZE));\n    return m;\n  }\n  /**\n   * Grows the buffer's capacity, if necessary, to guarantee space for\n   * another `n` bytes. After `.grow(n)`, at least `n` bytes can be written to\n   * the buffer without another allocation. If `n` is negative, `.grow()` will\n   * throw. If the buffer can't grow it will throw an error.\n   *\n   * @param n The number of bytes to grow the buffer by.\n   *\n   * Based on Go Lang's\n   * {@link https://golang.org/pkg/bytes/#Buffer.Grow | Buffer.Grow}.\n   *\n   * @example Basic usage\n   * ```ts\n   * import { assert } from \"@std/assert\";\n   * import { assertEquals } from \"@std/assert\";\n   * import { Buffer } from \"@std/streams/buffer\";\n   *\n   * const buf = new Buffer();\n   * assertEquals(buf.capacity, 0);\n   *\n   * buf.grow(200);\n   * assert(buf.capacity >= 200);\n   * ```\n   */ grow(n) {\n    if (n < 0) {\n      throw new Error(`Cannot grow buffer as growth must be positive: received ${n}`);\n    }\n    const m = this.#grow(n);\n    this.#reslice(m);\n  }\n}",
	"ByteSliceStream": "class ByteSliceStream extends TransformStream {\n  #offsetStart = 0;\n  #offsetEnd = 0;\n  /**\n   * Constructs a new instance.\n   *\n   * @param start The zero-indexed byte index to start reading from.\n   * @param end The zero-indexed byte index to stop reading at. Inclusive.\n   */ constructor(start = 0, end = Infinity){\n    super({\n      start: ()=>{\n        if (start < 0) {\n          throw new RangeError(`Cannot construct ByteSliceStream as start must be >= 0: received ${start}`);\n        }\n        end += 1;\n      },\n      transform: (chunk, controller)=>{\n        this.#offsetStart = this.#offsetEnd;\n        this.#offsetEnd += chunk.byteLength;\n        if (this.#offsetEnd > start) {\n          if (this.#offsetStart < start) {\n            chunk = chunk.slice(start - this.#offsetStart);\n          }\n          if (this.#offsetEnd >= end) {\n            chunk = chunk.slice(0, chunk.byteLength - this.#offsetEnd + end);\n            controller.enqueue(chunk);\n            controller.terminate();\n          } else {\n            controller.enqueue(chunk);\n          }\n        }\n      }\n    });\n  }\n}",
	"DelimiterStream": "class DelimiterStream extends TransformStream {\n  #bufs = [];\n  #delimiter;\n  #matchIndex = 0;\n  #delimLPS;\n  #disp;\n  /**\n   * Constructs a new instance.\n   *\n   * @param delimiter A delimiter to split the stream by.\n   * @param options Options for the delimiter stream.\n   */ constructor(delimiter, options = {}){\n    super({\n      transform: (chunk, controller)=>delimiter.length === 1 ? this.#handleChar(chunk, controller) : this.#handle(chunk, controller),\n      flush: (controller)=>this.#flush(controller)\n    });\n    this.#delimiter = delimiter;\n    this.#delimLPS = delimiter.length > 1 ? createLPS(delimiter) : null;\n    this.#disp = options.disposition ?? \"discard\";\n  }\n  #handle(chunk, controller) {\n    const bufs = this.#bufs;\n    const length = chunk.byteLength;\n    const disposition = this.#disp;\n    const delimiter = this.#delimiter;\n    const delimLen = delimiter.length;\n    const lps = this.#delimLPS;\n    let chunkStart = 0;\n    let matchIndex = this.#matchIndex;\n    let inspectIndex = 0;\n    while(inspectIndex < length){\n      if (chunk[inspectIndex] === delimiter[matchIndex]) {\n        // Next byte matched our next delimiter byte\n        inspectIndex++;\n        matchIndex++;\n        if (matchIndex === delimLen) {\n          // Full match\n          matchIndex = 0;\n          const delimiterStartIndex = inspectIndex - delimLen;\n          const delimitedChunkEnd = disposition === \"suffix\" ? inspectIndex : delimiterStartIndex;\n          if (delimitedChunkEnd <= 0 && bufs.length === 0) {\n            // Our chunk started with a delimiter and no previous chunks exist:\n            // Enqueue an empty chunk.\n            controller.enqueue(new Uint8Array());\n            chunkStart = disposition === \"prefix\" ? 0 : inspectIndex;\n          } else if (delimitedChunkEnd > 0 && bufs.length === 0) {\n            // No previous chunks, slice from current chunk.\n            controller.enqueue(chunk.subarray(chunkStart, delimitedChunkEnd));\n            // Our chunk may have more than one delimiter; we must remember where\n            // the next delimited chunk begins.\n            chunkStart = disposition === \"prefix\" ? delimiterStartIndex : inspectIndex;\n          } else if (delimitedChunkEnd === 0 && bufs.length > 0) {\n            // Our chunk started with a delimiter, previous chunks are passed as\n            // they are (with concatenation).\n            if (bufs.length === 1) {\n              // Concat not needed when a single buffer is passed.\n              controller.enqueue(bufs[0]);\n            } else {\n              controller.enqueue(concat(bufs));\n            }\n            // Drop all previous chunks.\n            bufs.length = 0;\n            if (disposition !== \"prefix\") {\n              // suffix or discard: The next chunk starts where our inspection finished.\n              // We should only ever end up here with a discard disposition as\n              // for a suffix disposition this branch would mean that the previous\n              // chunk ended with a full match but was not enqueued.\n              chunkStart = inspectIndex;\n            } else {\n              chunkStart = 0;\n            }\n          } else if (delimitedChunkEnd < 0 && bufs.length > 0) {\n            // Our chunk started by finishing a partial delimiter match.\n            const lastIndex = bufs.length - 1;\n            const last = bufs[lastIndex];\n            const lastSliceIndex = last.byteLength + delimitedChunkEnd;\n            const lastSliced = last.subarray(0, lastSliceIndex);\n            if (lastIndex === 0) {\n              controller.enqueue(lastSliced);\n            } else {\n              bufs[lastIndex] = lastSliced;\n              controller.enqueue(concat(bufs));\n            }\n            bufs.length = 0;\n            if (disposition === \"prefix\") {\n              // Must keep last bytes of last chunk.\n              bufs.push(last.subarray(lastSliceIndex));\n              chunkStart = 0;\n            } else {\n              chunkStart = inspectIndex;\n            }\n          } else if (delimitedChunkEnd > 0 && bufs.length > 0) {\n            // Previous chunks and current chunk together form a delimited chunk.\n            const chunkSliced = chunk.subarray(chunkStart, delimitedChunkEnd);\n            const result = concat([\n              ...bufs,\n              chunkSliced\n            ]);\n            bufs.length = 0;\n            controller.enqueue(result);\n            chunkStart = disposition === \"prefix\" ? delimitedChunkEnd : inspectIndex;\n          } else {\n            throw new Error(\"This should be unreachable, please file a bug report against Deno at https://github.com/denoland/std/issues\");\n          }\n        }\n      } else if (matchIndex === 0) {\n        // No match ongoing, keep going through the buffer.\n        inspectIndex++;\n      } else {\n        // Ongoing match: Degrade to the previous possible match.\n        // eg. If we're looking for 'AAB' and had matched 'AA' previously\n        // but now got a new 'A', then we'll drop down to having matched\n        // just 'A'. The while loop will turn around again and we'll rematch\n        // to 'AA' and proceed onwards to try and match on 'B' again.\n        matchIndex = lps[matchIndex - 1];\n      }\n    }\n    // Save match index.\n    this.#matchIndex = matchIndex;\n    if (chunkStart === 0) {\n      bufs.push(chunk);\n    } else if (chunkStart < length) {\n      // If we matched partially somewhere in the middle of our chunk\n      // then the remnants should be pushed into buffers.\n      bufs.push(chunk.subarray(chunkStart));\n    }\n  }\n  /**\n   * Optimized handler for a char delimited stream:\n   *\n   * For char delimited streams we do not need to keep track of\n   * the match index, removing the need for a fair bit of work.\n   */ #handleChar(chunk, controller) {\n    const bufs = this.#bufs;\n    const length = chunk.byteLength;\n    const disposition = this.#disp;\n    const delimiter = this.#delimiter[0];\n    let chunkStart = 0;\n    let inspectIndex = 0;\n    while(inspectIndex < length){\n      if (chunk[inspectIndex] === delimiter) {\n        // Next byte matched our next delimiter\n        inspectIndex++;\n        /**\n         * Always non-negative\n         */ const delimitedChunkEnd = disposition === \"suffix\" ? inspectIndex : inspectIndex - 1;\n        if (delimitedChunkEnd === 0 && bufs.length === 0) {\n          // Our chunk started with a delimiter and no previous chunks exist:\n          // Enqueue an empty chunk.\n          controller.enqueue(new Uint8Array());\n          chunkStart = disposition === \"prefix\" ? 0 : 1;\n        } else if (delimitedChunkEnd > 0 && bufs.length === 0) {\n          // No previous chunks, slice from current chunk.\n          controller.enqueue(chunk.subarray(chunkStart, delimitedChunkEnd));\n          // Our chunk may have more than one delimiter; we must remember where\n          // the next delimited chunk begins.\n          chunkStart = disposition === \"prefix\" ? inspectIndex - 1 : inspectIndex;\n        } else if (delimitedChunkEnd === 0 && bufs.length > 0) {\n          // Our chunk started with a delimiter, previous chunks are passed as\n          // they are (with concatenation).\n          if (bufs.length === 1) {\n            // Concat not needed when a single buffer is passed.\n            controller.enqueue(bufs[0]);\n          } else {\n            controller.enqueue(concat(bufs));\n          }\n          // Drop all previous chunks.\n          bufs.length = 0;\n          if (disposition !== \"prefix\") {\n            // suffix or discard: The next chunk starts where our inspection finished.\n            // We should only ever end up here with a discard disposition as\n            // for a suffix disposition this branch would mean that the previous\n            // chunk ended with a full match but was not enqueued.\n            chunkStart = inspectIndex;\n          }\n        } else if (delimitedChunkEnd > 0 && bufs.length > 0) {\n          // Previous chunks and current chunk together form a delimited chunk.\n          const chunkSliced = chunk.subarray(chunkStart, delimitedChunkEnd);\n          const result = concat([\n            ...bufs,\n            chunkSliced\n          ]);\n          bufs.length = 0;\n          chunkStart = disposition === \"prefix\" ? delimitedChunkEnd : inspectIndex;\n          controller.enqueue(result);\n        } else {\n          throw new Error(\"This should be unreachable, please file a bug report against Deno at https://github.com/denoland/std/issues\");\n        }\n      } else {\n        inspectIndex++;\n      }\n    }\n    if (chunkStart === 0) {\n      bufs.push(chunk);\n    } else if (chunkStart < length) {\n      // If we matched partially somewhere in the middle of our chunk\n      // then the remnants should be pushed into buffers.\n      bufs.push(chunk.subarray(chunkStart));\n    }\n  }\n  #flush(controller) {\n    const bufs = this.#bufs;\n    const length = bufs.length;\n    if (length === 0) {\n      controller.enqueue(new Uint8Array());\n    } else if (length === 1) {\n      controller.enqueue(bufs[0]);\n    } else {\n      controller.enqueue(concat(bufs));\n    }\n  }\n}",
	"LimitedBytesTransformStream": "class LimitedBytesTransformStream extends TransformStream {\n  #read = 0;\n  /**\n   * Constructs a new instance.\n   *\n   * @param size A size limit in bytes.\n   * @param options Options for the stream.\n   */ constructor(size, options = {\n    error: false\n  }){\n    super({\n      transform: (chunk, controller)=>{\n        if (this.#read + chunk.byteLength > size) {\n          if (options.error) {\n            throw new RangeError(`Exceeded byte size limit of '${size}'`);\n          } else {\n            controller.terminate();\n          }\n        } else {\n          this.#read += chunk.byteLength;\n          controller.enqueue(chunk);\n        }\n      }\n    });\n  }\n}",
	"LimitedTransformStream": "class LimitedTransformStream extends TransformStream {\n  #read = 0;\n  /**\n   * Constructs a new instance.\n   *\n   * @param size The maximum number of chunks to read.\n   * @param options Options for the stream.\n   */ constructor(size, options = {\n    error: false\n  }){\n    super({\n      transform: (chunk, controller)=>{\n        if (this.#read + 1 > size) {\n          if (options.error) {\n            throw new RangeError(`Exceeded chunk limit of '${size}'`);\n          } else {\n            controller.terminate();\n          }\n        } else {\n          this.#read++;\n          controller.enqueue(chunk);\n        }\n      }\n    });\n  }\n}",
	"TextDelimiterStream": "class TextDelimiterStream extends TransformStream {\n  #buf = \"\";\n  #delimiter;\n  #inspectIndex = 0;\n  #matchIndex = 0;\n  #delimLPS;\n  #disp;\n  /**\n   * Constructs a new instance.\n   *\n   * @param delimiter A delimiter to split the stream by.\n   * @param options Options for the stream.\n   */ constructor(delimiter, options){\n    super({\n      transform: (chunk, controller)=>{\n        this.#handle(chunk, controller);\n      },\n      flush: (controller)=>{\n        controller.enqueue(this.#buf);\n      }\n    });\n    this.#delimiter = delimiter;\n    this.#delimLPS = createLPS(new TextEncoder().encode(delimiter));\n    this.#disp = options?.disposition ?? \"discard\";\n  }\n  #handle(chunk, controller) {\n    this.#buf += chunk;\n    let localIndex = 0;\n    while(this.#inspectIndex < this.#buf.length){\n      if (chunk[localIndex] === this.#delimiter[this.#matchIndex]) {\n        this.#inspectIndex++;\n        localIndex++;\n        this.#matchIndex++;\n        if (this.#matchIndex === this.#delimiter.length) {\n          // Full match\n          const start = this.#inspectIndex - this.#delimiter.length;\n          const end = this.#disp === \"suffix\" ? this.#inspectIndex : start;\n          const copy = this.#buf.slice(0, end);\n          controller.enqueue(copy);\n          const shift = this.#disp === \"prefix\" ? start : this.#inspectIndex;\n          this.#buf = this.#buf.slice(shift);\n          this.#inspectIndex = this.#disp === \"prefix\" ? this.#delimiter.length : 0;\n          this.#matchIndex = 0;\n        }\n      } else {\n        if (this.#matchIndex === 0) {\n          this.#inspectIndex++;\n          localIndex++;\n        } else {\n          this.#matchIndex = this.#delimLPS[this.#matchIndex - 1];\n        }\n      }\n    }\n  }\n}",
	"TextLineStream": "class TextLineStream extends TransformStream {\n  #currentLine = \"\";\n  /**\n   * Constructs a new instance.\n   *\n   * @param options Options for the stream.\n   */ constructor(options = {\n    allowCR: false\n  }){\n    super({\n      transform: (chars, controller)=>{\n        chars = this.#currentLine + chars;\n        while(true){\n          const lfIndex = chars.indexOf(\"\\n\");\n          const crIndex = options.allowCR ? chars.indexOf(\"\\r\") : -1;\n          if (crIndex !== -1 && crIndex !== chars.length - 1 && (lfIndex === -1 || lfIndex - 1 > crIndex)) {\n            controller.enqueue(chars.slice(0, crIndex));\n            chars = chars.slice(crIndex + 1);\n            continue;\n          }\n          if (lfIndex === -1) break;\n          const endIndex = chars[lfIndex - 1] === \"\\r\" ? lfIndex - 1 : lfIndex;\n          controller.enqueue(chars.slice(0, endIndex));\n          chars = chars.slice(lfIndex + 1);\n        }\n        this.#currentLine = chars;\n      },\n      flush: (controller)=>{\n        if (this.#currentLine === \"\") return;\n        const currentLine = options.allowCR && this.#currentLine.endsWith(\"\\r\") ? this.#currentLine.slice(0, -1) : this.#currentLine;\n        controller.enqueue(currentLine);\n      }\n    });\n  }\n}",
	"concatReadableStreams": "function concatReadableStreams(...streams) {\n  let i = 0;\n  return new ReadableStream({\n    async pull (controller) {\n      const reader = streams[i].getReader();\n      const { done, value } = await reader.read();\n      if (done) {\n        if (streams.length === ++i) {\n          return controller.close();\n        }\n        return await this.pull(controller);\n      }\n      controller.enqueue(value);\n      reader.releaseLock();\n    },\n    async cancel (reason) {\n      const promises = streams.map((stream)=>stream.cancel(reason));\n      await Promise.allSettled(promises);\n    }\n  });\n}",
	"earlyZipReadableStreams": "function earlyZipReadableStreams(...streams) {\n  const readers = streams.map((stream)=>stream.getReader());\n  return new ReadableStream({\n    async pull (controller) {\n      for(let i = 0; i < readers.length; ++i){\n        const { done, value } = await readers[i].read();\n        if (done) {\n          await Promise.all(readers.map((reader)=>reader.cancel(`Stream at index ${i} ended`)));\n          controller.close();\n          return;\n        }\n        controller.enqueue(value);\n      }\n    },\n    async cancel (reason) {\n      await Promise.all(readers.map((reader)=>reader.cancel(reason)));\n    }\n  });\n}",
	"mergeReadableStreams": "function mergeReadableStreams(...streams) {\n  const resolvePromises = streams.map(()=>Promise.withResolvers());\n  return new ReadableStream({\n    start (controller) {\n      let mustClose = false;\n      Promise.all(resolvePromises.map(({ promise })=>promise)).then(()=>{\n        controller.close();\n      }).catch((error)=>{\n        mustClose = true;\n        controller.error(error);\n      });\n      for (const [index, stream] of streams.entries()){\n        (async ()=>{\n          try {\n            for await (const data of stream){\n              if (mustClose) {\n                break;\n              }\n              controller.enqueue(data);\n            }\n            resolvePromises[index].resolve();\n          } catch (error) {\n            resolvePromises[index].reject(error);\n          }\n        })();\n      }\n    }\n  });\n}",
	"toArrayBuffer": "async function toArrayBuffer(readableStream) {\n  const reader = readableStream.getReader();\n  const chunks = [];\n  while(true){\n    const { done, value } = await reader.read();\n    if (done) {\n      break;\n    }\n    chunks.push(value);\n  }\n  return concat(chunks).buffer;\n}",
	"toBlob": "async function toBlob(stream) {\n  return await new Response(stream).blob();\n}",
	"toJson": "function toJson(stream) {\n  return toText(stream).then(JSON.parse);\n}",
	"toText": "async function toText(stream) {\n  const textDecoder = new TextDecoder();\n  const reader = stream.getReader();\n  let result = \"\";\n  while(true){\n    const { done, value } = await reader.read();\n    if (done) {\n      break;\n    }\n    result += typeof value === \"string\" ? value : textDecoder.decode(value, {\n      stream: true\n    });\n  }\n  result += textDecoder.decode();\n  return result;\n}",
	"toTransformStream": "function toTransformStream(transformer, writableStrategy, readableStrategy) {\n  const { writable, readable } = new TransformStream(undefined, writableStrategy);\n  const iterable = transformer(readable);\n  const iterator = iterable[Symbol.asyncIterator]?.() ?? iterable[Symbol.iterator]?.();\n  return {\n    writable,\n    readable: new ReadableStream({\n      async pull (controller) {\n        let result;\n        try {\n          result = await iterator.next();\n        } catch (error) {\n          // Propagate error to stream from iterator\n          // If the stream status is \"errored\", it will be thrown, but ignore.\n          await readable.cancel(error).catch(()=>{});\n          controller.error(error);\n          return;\n        }\n        if (result.done) {\n          controller.close();\n          return;\n        }\n        controller.enqueue(result.value);\n      },\n      async cancel (reason) {\n        // Propagate cancellation to readable and iterator\n        if (typeof iterator.throw === \"function\") {\n          try {\n            await iterator.throw(reason);\n          } catch  {\n          /* `iterator.throw()` always throws on site. We catch it. */ }\n        }\n        await readable.cancel(reason);\n      }\n    }, readableStrategy)\n  };\n}",
	"zipReadableStreams": "function zipReadableStreams(...streams) {\n  const readers = new Set(streams.map((s)=>s.getReader()));\n  return new ReadableStream({\n    async start (controller) {\n      try {\n        let resolved = 0;\n        while(resolved !== streams.length){\n          for (const reader of readers){\n            const { value, done } = await reader.read();\n            if (!done) {\n              controller.enqueue(value);\n            } else {\n              resolved++;\n              readers.delete(reader);\n            }\n          }\n        }\n        controller.close();\n      } catch (e) {\n        controller.error(e);\n      }\n    }\n  });\n}"
},
"jsr:@std/semver": {
	"canParse": "function canParse(value) {\n  try {\n    parse(value);\n    return true;\n  } catch  {\n    return false;\n  }\n}",
	"compare": "function compare(version1, version2) {\n  if (version1 === version2) return 0;\n  return compareNumber(version1.major, version2.major) || compareNumber(version1.minor, version2.minor) || compareNumber(version1.patch, version2.patch) || checkIdentifier(version1.prerelease, version2.prerelease) || compareIdentifier(version1.prerelease, version2.prerelease);\n}",
	"difference": "function difference(version1, version2) {\n  const hasPrerelease = version1.prerelease?.length || version2.prerelease?.length;\n  if (version1.major !== version2.major) {\n    return hasPrerelease ? \"premajor\" : \"major\";\n  }\n  if (version1.minor !== version2.minor) {\n    return hasPrerelease ? \"preminor\" : \"minor\";\n  }\n  if (version1.patch !== version2.patch) {\n    return hasPrerelease ? \"prepatch\" : \"patch\";\n  }\n  if (compareIdentifier(version1.prerelease, version2.prerelease) !== 0) {\n    return \"prerelease\";\n  }\n}",
	"equals": "function equals(version1, version2) {\n  return compare(version1, version2) === 0;\n}",
	"format": "function format(version) {\n  const major = formatNumber(version.major);\n  const minor = formatNumber(version.minor);\n  const patch = formatNumber(version.patch);\n  const pre = version.prerelease?.join(\".\") ?? \"\";\n  const build = version.build?.join(\".\") ?? \"\";\n  const primary = `${major}.${minor}.${patch}`;\n  const release = [\n    primary,\n    pre\n  ].filter((v)=>v).join(\"-\");\n  return [\n    release,\n    build\n  ].filter((v)=>v).join(\"+\");\n}",
	"formatRange": "function formatRange(range) {\n  return range.map((c)=>c.map((c)=>formatComparator(c)).join(\" \")).join(\"||\");\n}",
	"greaterOrEqual": "function greaterOrEqual(version1, version2) {\n  return compare(version1, version2) >= 0;\n}",
	"greaterThan": "function greaterThan(version1, version2) {\n  return compare(version1, version2) > 0;\n}",
	"greaterThanRange": "function greaterThanRange(version, range) {\n  return range.every((comparatorSet)=>greaterThanComparatorSet(version, comparatorSet));\n}",
	"increment": "function increment(version, release, options = {}) {\n  const build = options.build !== undefined ? parseBuild(options.build) : version.build ?? [];\n  switch(release){\n    case \"premajor\":\n      return {\n        major: version.major + 1,\n        minor: 0,\n        patch: 0,\n        prerelease: bumpPrerelease(version.prerelease, options.prerelease),\n        build\n      };\n    case \"preminor\":\n      return {\n        major: version.major,\n        minor: version.minor + 1,\n        patch: 0,\n        prerelease: bumpPrerelease(version.prerelease, options.prerelease),\n        build\n      };\n    case \"prepatch\":\n      return {\n        major: version.major,\n        minor: version.minor,\n        patch: version.patch + 1,\n        prerelease: bumpPrerelease(version.prerelease, options.prerelease),\n        build\n      };\n    case \"prerelease\":\n      {\n        // If the input is a non-prerelease version, this acts the same as prepatch.\n        const isPrerelease = (version.prerelease ?? []).length === 0;\n        const patch = isPrerelease ? version.patch + 1 : version.patch;\n        return {\n          major: version.major,\n          minor: version.minor,\n          patch,\n          prerelease: bumpPrerelease(version.prerelease, options.prerelease),\n          build\n        };\n      }\n    case \"major\":\n      {\n        // If this is a pre-major version, bump up to the same major version. Otherwise increment major.\n        // 1.0.0-5 bumps to 1.0.0\n        // 1.1.0 bumps to 2.0.0\n        const isPrerelease = (version.prerelease ?? []).length === 0;\n        const major = isPrerelease || version.minor !== 0 || version.patch !== 0 ? version.major + 1 : version.major;\n        return {\n          major,\n          minor: 0,\n          patch: 0,\n          prerelease: [],\n          build\n        };\n      }\n    case \"minor\":\n      {\n        // If this is a pre-minor version, bump up to the same minor version. Otherwise increment minor.\n        // 1.2.0-5 bumps to 1.2.0\n        // 1.2.1 bumps to 1.3.0\n        const isPrerelease = (version.prerelease ?? []).length === 0;\n        const minor = isPrerelease || version.patch !== 0 ? version.minor + 1 : version.minor;\n        return {\n          major: version.major,\n          minor,\n          patch: 0,\n          prerelease: [],\n          build\n        };\n      }\n    case \"patch\":\n      {\n        // If this is not a pre-release version, it will increment the patch.\n        // If it is a pre-release it will bump up to the same patch version.\n        // 1.2.0-5 patches to 1.2.0\n        // 1.2.0 patches to 1.2.1\n        const isPrerelease = (version.prerelease ?? []).length === 0;\n        const patch = isPrerelease ? version.patch + 1 : version.patch;\n        return {\n          major: version.major,\n          minor: version.minor,\n          patch,\n          prerelease: [],\n          build\n        };\n      }\n    case \"pre\":\n      {\n        // 1.0.0 \"pre\" would become 1.0.0-0\n        // 1.0.0-0 would become 1.0.0-1\n        // 1.0.0-beta.0 would be come 1.0.0-beta.1\n        // switching the pre identifier resets the number to 0\n        return {\n          major: version.major,\n          minor: version.minor,\n          patch: version.patch,\n          prerelease: bumpPrerelease(version.prerelease, options.prerelease),\n          build\n        };\n      }\n    default:\n      throw new TypeError(`Cannot increment version: invalid argument ${release}`);\n  }\n}",
	"isRange": "function isRange(value) {\n  return Array.isArray(value) && value.every((r)=>Array.isArray(r) && r.every((c)=>isComparator(c)));\n}",
	"isSemVer": "function isSemVer(value) {\n  if (value === null || value === undefined) return false;\n  if (Array.isArray(value)) return false;\n  if (typeof value !== \"object\") return false;\n  if (value === ANY) return true;\n  const { major, minor, patch, build = [], prerelease = [] } = value;\n  return isValidNumber(major) && isValidNumber(minor) && isValidNumber(patch) && Array.isArray(prerelease) && prerelease.every((v)=>isValidString(v) || isValidNumber(v)) && Array.isArray(build) && build.every(isValidString);\n}",
	"lessOrEqual": "function lessOrEqual(version1, version2) {\n  return compare(version1, version2) <= 0;\n}",
	"lessThan": "function lessThan(version1, version2) {\n  return compare(version1, version2) < 0;\n}",
	"lessThanRange": "function lessThanRange(version, range) {\n  return range.every((comparatorSet)=>lessThanComparatorSet(version, comparatorSet));\n}",
	"maxSatisfying": "function maxSatisfying(versions, range) {\n  let max;\n  for (const version of versions){\n    if (!satisfies(version, range)) continue;\n    max = max && greaterThan(max, version) ? max : version;\n  }\n  return max;\n}",
	"minSatisfying": "function minSatisfying(versions, range) {\n  let min;\n  for (const version of versions){\n    if (!satisfies(version, range)) continue;\n    min = min && lessThan(min, version) ? min : version;\n  }\n  return min;\n}",
	"notEquals": "function notEquals(version1, version2) {\n  return compare(version1, version2) !== 0;\n}",
	"parse": "function parse(value) {\n  if (typeof value !== \"string\") {\n    throw new TypeError(`Cannot parse version as version must be a string: received ${typeof value}`);\n  }\n  if (value.length > MAX_LENGTH) {\n    throw new TypeError(`Cannot parse version as version length is too long: length is ${value.length}, max length is ${MAX_LENGTH}`);\n  }\n  value = value.trim();\n  const groups = value.match(FULL_REGEXP)?.groups;\n  if (!groups) throw new TypeError(`Cannot parse version: ${value}`);\n  const major = parseNumber(groups.major, `Cannot parse version ${value}: invalid major version`);\n  const minor = parseNumber(groups.minor, `Cannot parse version ${value}: invalid minor version`);\n  const patch = parseNumber(groups.patch, `Cannot parse version ${value}: invalid patch version`);\n  const prerelease = groups.prerelease ? parsePrerelease(groups.prerelease) : [];\n  const build = groups.buildmetadata ? parseBuild(groups.buildmetadata) : [];\n  return {\n    major,\n    minor,\n    patch,\n    prerelease,\n    build\n  };\n}",
	"parseRange": "function parseRange(value) {\n  const result = value// remove spaces between operators and versions\n  .replaceAll(/(?<=<|>|=|~|\\^)(\\s+)/g, \"\").split(/\\s*\\|\\|\\s*/).map((string)=>parseHyphenRange(string) || parseOperatorRanges(string));\n  if (result.some((r)=>r.includes(null))) {\n    throw new TypeError(`Cannot parse version range: range \"${value}\" is invalid`);\n  }\n  return result;\n}",
	"rangeIntersects": "function rangeIntersects(range1, range2) {\n  return rangesSatisfiable([\n    range1,\n    range2\n  ]) && range1.some((range10)=>{\n    return range2.some((r11)=>{\n      return range10.every((comparator1)=>{\n        return r11.every((comparator2)=>comparatorIntersects(comparator1, comparator2));\n      });\n    });\n  });\n}",
	"satisfies": "function satisfies(version, range) {\n  return range.some((set)=>testComparatorSet(version, set));\n}",
	"tryParse": "function tryParse(value) {\n  try {\n    return parse(value);\n  } catch  {\n    return undefined;\n  }\n}",
	"tryParseRange": "function tryParseRange(value) {\n  try {\n    // Return '*' instead of '' so that truthiness works.\n    // This will throw if it's invalid anyway\n    return parseRange(value);\n  } catch  {\n    return undefined;\n  }\n}"
},
"jsr:@std/regexp": {
	"escape": "function escape(str) {\n  return str.replaceAll(RX_REGEXP_ESCAPE, (m)=>RESERVED_CHARS[m]);\n}"
},
"jsr:@std/random": {
	"randomBetween": "function randomBetween(min, max, options) {\n  if (!Number.isFinite(min)) {\n    throw new RangeError(`Cannot generate a random number: min cannot be ${min}`);\n  }\n  if (!Number.isFinite(max)) {\n    throw new RangeError(`Cannot generate a random number: max cannot be ${max}`);\n  }\n  if (max < min) {\n    throw new RangeError(`Cannot generate a random number as max must be greater than or equal to min: max=${max}, min=${min}`);\n  }\n  const x = (options?.prng ?? Math.random)();\n  const y = min * (1 - x) + max * x;\n  return y >= min && y < max ? y : min;\n}",
	"randomIntegerBetween": "function randomIntegerBetween(min, max, options) {\n  return Math.floor(randomBetween(Math.ceil(min), Math.floor(max) + 1, options));\n}",
	"randomSeeded": "function randomSeeded(seed) {\n  const pcg = fromSeed(seedFromU64(seed, 16));\n  return ()=>uint32ToFloat64(nextU32(pcg));\n}",
	"sample": "function sample(array, options) {\n  const { weights } = {\n    ...options\n  };\n  if (weights) {\n    if (weights.length !== array.length) {\n      throw new RangeError(\"Cannot sample an item: The length of the weights array must match the length of the input array\");\n    }\n    if (!array.length) return undefined;\n    const total = Object.values(weights).reduce((sum, n)=>sum + n, 0);\n    if (total <= 0) {\n      throw new RangeError(\"Cannot sample an item: Total weight must be greater than 0\");\n    }\n    const rand = (options?.prng ?? Math.random)() * total;\n    let current = 0;\n    for(let i = 0; i < array.length; ++i){\n      current += weights[i];\n      if (rand < current) {\n        return array[i];\n      }\n    }\n    // this line should never be hit, but in case of rounding errors etc.\n    return array[0];\n  }\n  const length = array.length;\n  return length ? array[randomIntegerBetween(0, length - 1, options)] : undefined;\n}",
	"shuffle": "function shuffle(items, options) {\n  const result = [\n    ...items\n  ];\n  // https://en.wikipedia.org/wiki/FisherYates_shuffle#The_modern_algorithm\n  // -- To shuffle an array a of n elements (indices 0..n-1):\n  // for i from n1 down to 1 do\n  for(let i = result.length - 1; i >= 1; --i){\n    // j  random integer such that 0  j  i\n    const j = randomIntegerBetween(0, i, options);\n    // exchange a[j] and a[i]\n    [result[i], result[j]] = [\n      result[j],\n      result[i]\n    ];\n  }\n  return result;\n}"
},
"jsr:@std/path": {
	"DELIMITER": ":",
	"SEPARATOR": "/",
	"SEPARATOR_PATTERN": {},
	"basename": "function basename(path, suffix = \"\") {\n  return isWindows ? windowsBasename(path, suffix) : posixBasename(path, suffix);\n}",
	"common": "function common(paths) {\n  return _common(paths, SEPARATOR);\n}",
	"dirname": "function dirname(path) {\n  return isWindows ? windowsDirname(path) : posixDirname(path);\n}",
	"extname": "function extname(path) {\n  return isWindows ? windowsExtname(path) : posixExtname(path);\n}",
	"format": "function format(pathObject) {\n  return isWindows ? windowsFormat(pathObject) : posixFormat(pathObject);\n}",
	"fromFileUrl": "function fromFileUrl(url) {\n  return isWindows ? windowsFromFileUrl(url) : posixFromFileUrl(url);\n}",
	"globToRegExp": "function globToRegExp(glob, options = {}) {\n  return isWindows ? windowsGlobToRegExp(glob, options) : posixGlobToRegExp(glob, options);\n}",
	"isAbsolute": "function isAbsolute(path) {\n  return isWindows ? windowsIsAbsolute(path) : posixIsAbsolute(path);\n}",
	"isGlob": "function isGlob(str) {\n  const chars = {\n    \"{\": \"}\",\n    \"(\": \")\",\n    \"[\": \"]\"\n  };\n  const regex = /\\\\(.)|(^!|\\*|\\?|[\\].+)]\\?|\\[[^\\\\\\]]+\\]|\\{[^\\\\}]+\\}|\\(\\?[:!=][^\\\\)]+\\)|\\([^|]+\\|[^\\\\)]+\\))/;\n  if (str === \"\") {\n    return false;\n  }\n  let match;\n  while(match = regex.exec(str)){\n    if (match[2]) return true;\n    let idx = match.index + match[0].length;\n    // if an open bracket/brace/paren is escaped,\n    // set the index to the next closing character\n    const open = match[1];\n    const close = open ? chars[open] : null;\n    if (open && close) {\n      const n = str.indexOf(close, idx);\n      if (n !== -1) {\n        idx = n + 1;\n      }\n    }\n    str = str.slice(idx);\n  }\n  return false;\n}",
	"join": "function join(...paths) {\n  return isWindows ? windowsJoin(...paths) : posixJoin(...paths);\n}",
	"joinGlobs": "function joinGlobs(globs, options = {}) {\n  return isWindows ? windowsJoinGlobs(globs, options) : posixJoinGlobs(globs, options);\n}",
	"normalize": "function normalize(path) {\n  return isWindows ? windowsNormalize(path) : posixNormalize(path);\n}",
	"normalizeGlob": "function normalizeGlob(glob, options = {}) {\n  return isWindows ? windowsNormalizeGlob(glob, options) : posixNormalizeGlob(glob, options);\n}",
	"parse": "function parse(path) {\n  return isWindows ? windowsParse(path) : posixParse(path);\n}",
	"relative": "function relative(from, to) {\n  return isWindows ? windowsRelative(from, to) : posixRelative(from, to);\n}",
	"resolve": "function resolve(...pathSegments) {\n  return isWindows ? windowsResolve(...pathSegments) : posixResolve(...pathSegments);\n}",
	"toFileUrl": "function toFileUrl(path) {\n  return isWindows ? windowsToFileUrl(path) : posixToFileUrl(path);\n}",
	"toNamespacedPath": "function toNamespacedPath(path) {\n  return isWindows ? windowsToNamespacedPath(path) : posixToNamespacedPath(path);\n}"
},
"jsr:@std/net": {
	"getAvailablePort": "function getAvailablePort(options) {\n  try {\n    var _usingCtx = _using_ctx();\n    if (options?.preferredPort) {\n      try {\n        try {\n          var _usingCtx1 = _using_ctx();\n          const listener = // Check if the preferred port is available\n          _usingCtx1.u(Deno.listen({\n            port: options.preferredPort\n          }));\n          return listener.addr.port;\n        } catch (_) {\n          _usingCtx1.e = _;\n        } finally{\n          _usingCtx1.d();\n        }\n      } catch (e) {\n        // If the preferred port is not available, fall through and find an available port\n        if (!(e instanceof Deno.errors.AddrInUse)) {\n          throw e;\n        }\n      }\n    }\n    const listener = _usingCtx.u(Deno.listen({\n      port: 0\n    }));\n    return listener.addr.port;\n  } catch (_) {\n    _usingCtx.e = _;\n  } finally{\n    _usingCtx.d();\n  }\n}"
},
"jsr:@std/msgpack": {
	"decode": "function decode(data) {\n  const pointer = {\n    consumed: 0\n  };\n  const dataView = new DataView(data.buffer, data.byteOffset, data.byteLength);\n  const value = decodeSlice(data, dataView, pointer);\n  if (pointer.consumed < data.length) {\n    throw new EvalError(\"Messagepack decode did not consume whole array\");\n  }\n  return value;\n}",
	"encode": "function encode(object) {\n  const byteParts = [];\n  encodeSlice(object, byteParts);\n  return concat(byteParts);\n}"
},
"jsr:@std/mediaTypes": {
	"allExtensions": "function allExtensions(type) {\n  try {\n    const [mediaType] = parseMediaType(type);\n    return extensions.get(mediaType);\n  } catch  {\n  // just swallow errors, returning undefined\n  }\n}",
	"contentType": "function contentType(extensionOrType) {\n  try {\n    const [mediaType, params = {}] = extensionOrType.includes(\"/\") ? parseMediaType(extensionOrType) : [\n      typeByExtension(extensionOrType),\n      undefined\n    ];\n    if (!mediaType) {\n      return undefined;\n    }\n    if (!(\"charset\" in params)) {\n      const charset = getCharset(mediaType);\n      if (charset) {\n        params.charset = charset;\n      }\n    }\n    return formatMediaType(mediaType, params);\n  } catch  {\n  // just swallow returning undefined\n  }\n  return undefined;\n}",
	"extension": "function extension(type) {\n  return allExtensions(type)?.[0];\n}",
	"formatMediaType": "function formatMediaType(type, param) {\n  let serializedMediaType = \"\";\n  const [major = \"\", sub] = type.split(\"/\");\n  if (!sub) {\n    if (!isToken(type)) {\n      return \"\";\n    }\n    serializedMediaType += type.toLowerCase();\n  } else {\n    if (!isToken(major) || !isToken(sub)) {\n      return \"\";\n    }\n    serializedMediaType += `${major.toLowerCase()}/${sub.toLowerCase()}`;\n  }\n  if (param) {\n    param = isIterator(param) ? Object.fromEntries(param) : param;\n    const attrs = Object.keys(param);\n    attrs.sort();\n    for (const attribute of attrs){\n      if (!isToken(attribute)) {\n        return \"\";\n      }\n      const value = param[attribute];\n      serializedMediaType += `; ${attribute.toLowerCase()}`;\n      const needEnc = needsEncoding(value);\n      if (needEnc) {\n        serializedMediaType += \"*\";\n      }\n      serializedMediaType += \"=\";\n      if (needEnc) {\n        serializedMediaType += `utf-8''${encodeURIComponent(value)}`;\n        continue;\n      }\n      if (isToken(value)) {\n        serializedMediaType += value;\n        continue;\n      }\n      serializedMediaType += `\"${value.replace(/[\"\\\\]/gi, (m)=>`\\\\${m}`)}\"`;\n    }\n  }\n  return serializedMediaType;\n}",
	"getCharset": "function getCharset(type) {\n  try {\n    const [mediaType, params] = parseMediaType(type);\n    if (params?.charset) {\n      return params.charset;\n    }\n    const entry = db[mediaType];\n    if (entry?.charset) {\n      return entry.charset;\n    }\n    if (mediaType.startsWith(\"text/\")) {\n      return \"UTF-8\";\n    }\n  } catch  {\n  // just swallow errors, returning undefined\n  }\n  return undefined;\n}",
	"parseMediaType": "function parseMediaType(type) {\n  const [base] = type.split(\";\");\n  const mediaType = base.toLowerCase().trim();\n  const params = {};\n  // Map of base parameter name -> parameter name -> value\n  // for parameters containing a '*' character.\n  const continuation = new Map();\n  type = type.slice(base.length);\n  while(type.length){\n    type = type.trimStart();\n    if (type.length === 0) {\n      break;\n    }\n    const [key, value, rest] = consumeMediaParam(type);\n    if (!key) {\n      if (SEMICOLON_REGEXP.test(rest)) {\n        break;\n      }\n      throw new TypeError(`Cannot parse media type: invalid parameter \"${type}\"`);\n    }\n    let pmap = params;\n    const [baseName, rest2] = key.split(\"*\");\n    if (baseName && rest2 !== undefined) {\n      if (!continuation.has(baseName)) {\n        continuation.set(baseName, {});\n      }\n      pmap = continuation.get(baseName);\n    }\n    if (key in pmap) {\n      throw new TypeError(\"Cannot parse media type: duplicate key\");\n    }\n    pmap[key] = value;\n    type = rest;\n  }\n  // Stitch together any continuations or things with stars\n  // (i.e. RFC 2231 things with stars: \"foo*0\" or \"foo*\")\n  let str = \"\";\n  for (const [key, pieceMap] of continuation){\n    const singlePartKey = `${key}*`;\n    const type = pieceMap[singlePartKey];\n    if (type) {\n      const decv = decode2331Encoding(type);\n      if (decv) {\n        params[key] = decv;\n      }\n      continue;\n    }\n    str = \"\";\n    let valid = false;\n    for(let n = 0;; n++){\n      const simplePart = `${key}*${n}`;\n      let type = pieceMap[simplePart];\n      if (type) {\n        valid = true;\n        str += type;\n        continue;\n      }\n      const encodedPart = `${simplePart}*`;\n      type = pieceMap[encodedPart];\n      if (!type) {\n        break;\n      }\n      valid = true;\n      if (n === 0) {\n        const decv = decode2331Encoding(type);\n        if (decv) {\n          str += decv;\n        }\n      } else {\n        const decv = decodeURI(type);\n        str += decv;\n      }\n    }\n    if (valid) {\n      params[key] = str;\n    }\n  }\n  return [\n    mediaType,\n    Object.keys(params).length ? params : undefined\n  ];\n}",
	"typeByExtension": "function typeByExtension(extension) {\n  extension = extension.startsWith(\".\") ? extension.slice(1) : extension;\n  // @ts-ignore Work around https://github.com/denoland/dnt/issues/148\n  return types.get(extension.toLowerCase());\n}"
},
"jsr:@std/log": {
	"BaseHandler": "class BaseHandler {\n  #levelName;\n  #level;\n  formatter;\n  constructor(levelName, options){\n    const { formatter = DEFAULT_FORMATTER } = options ?? {};\n    this.#levelName = levelName;\n    this.#level = getLevelByName(levelName);\n    this.formatter = formatter;\n  }\n  get level() {\n    return this.#level;\n  }\n  set level(level) {\n    this.#level = level;\n    this.#levelName = getLevelName(level);\n  }\n  get levelName() {\n    return this.#levelName;\n  }\n  set levelName(levelName) {\n    this.#levelName = levelName;\n    this.#level = getLevelByName(levelName);\n  }\n  handle(logRecord) {\n    if (this.level > logRecord.level) return;\n    const msg = this.format(logRecord);\n    this.log(msg);\n  }\n  format(logRecord) {\n    return this.formatter(logRecord);\n  }\n  setup() {}\n  destroy() {}\n  [_computedKey]() {\n    this.destroy();\n  }\n}",
	"ConsoleHandler": "class ConsoleHandler extends BaseHandler {\n  #useColors;\n  constructor(levelName, options = {}){\n    super(levelName, options);\n    this.#useColors = options.useColors ?? true;\n  }\n  format(logRecord) {\n    let msg = super.format(logRecord);\n    if (this.#useColors) {\n      msg = this.applyColors(msg, logRecord.level);\n    }\n    return msg;\n  }\n  applyColors(msg, level) {\n    switch(level){\n      case LogLevels.INFO:\n        msg = blue(msg);\n        break;\n      case LogLevels.WARN:\n        msg = yellow(msg);\n        break;\n      case LogLevels.ERROR:\n        msg = red(msg);\n        break;\n      case LogLevels.CRITICAL:\n        msg = bold(red(msg));\n        break;\n      default:\n        break;\n    }\n    return msg;\n  }\n  log(msg) {\n    // deno-lint-ignore no-console\n    console.log(msg);\n  }\n}",
	"FileHandler": "class FileHandler extends BaseHandler {\n  [fileSymbol];\n  [bufSymbol];\n  [pointerSymbol] = 0;\n  [filenameSymbol];\n  [modeSymbol];\n  [openOptionsSymbol];\n  [encoderSymbol] = new TextEncoder();\n  #unloadCallback = (()=>{\n    this.destroy();\n  }).bind(this);\n  constructor(levelName, options){\n    super(levelName, options);\n    this[filenameSymbol] = options.filename;\n    // default to append mode, write only\n    this[modeSymbol] = options.mode ?? \"a\";\n    this[openOptionsSymbol] = {\n      createNew: this[modeSymbol] === \"x\",\n      create: this[modeSymbol] !== \"x\",\n      append: this[modeSymbol] === \"a\",\n      truncate: this[modeSymbol] !== \"a\",\n      write: true\n    };\n    this[bufSymbol] = new Uint8Array(options.bufferSize ?? 4096);\n  }\n  setup() {\n    this[fileSymbol] = Deno.openSync(this[filenameSymbol], this[openOptionsSymbol]);\n    this.#resetBuffer();\n    addEventListener(\"unload\", this.#unloadCallback);\n  }\n  handle(logRecord) {\n    super.handle(logRecord);\n    // Immediately flush if log level is higher than ERROR\n    if (logRecord.level > LogLevels.ERROR) {\n      this.flush();\n    }\n  }\n  log(msg) {\n    const bytes = this[encoderSymbol].encode(msg + \"\\n\");\n    if (bytes.byteLength > this[bufSymbol].byteLength - this[pointerSymbol]) {\n      this.flush();\n    }\n    if (bytes.byteLength > this[bufSymbol].byteLength) {\n      writeAllSync(this[fileSymbol], bytes);\n    } else {\n      this[bufSymbol].set(bytes, this[pointerSymbol]);\n      this[pointerSymbol] += bytes.byteLength;\n    }\n  }\n  flush() {\n    if (this[pointerSymbol] > 0 && this[fileSymbol]) {\n      let written = 0;\n      while(written < this[pointerSymbol]){\n        written += this[fileSymbol].writeSync(this[bufSymbol].subarray(written, this[pointerSymbol]));\n      }\n      this.#resetBuffer();\n    }\n  }\n  #resetBuffer() {\n    this[pointerSymbol] = 0;\n  }\n  destroy() {\n    this.flush();\n    this[fileSymbol]?.close();\n    this[fileSymbol] = undefined;\n    removeEventListener(\"unload\", this.#unloadCallback);\n  }\n}",
	"LogLevelNames": {
        "0": "NOTSET",
        "1": "DEBUG",
        "2": "INFO",
        "3": "WARN",
        "4": "ERROR",
        "5": "CRITICAL"
	},
	"LogLevels": {
        "NOTSET": "0",
        "DEBUG": "10",
        "INFO": "20",
        "WARN": "30",
        "ERROR": "40",
		"CRITICAL": "50"
	},
	"LogRecord": "class LogRecord {\n  msg;\n  #args;\n  #datetime;\n  level;\n  levelName;\n  loggerName;\n  constructor(options){\n    this.msg = options.msg;\n    this.#args = [\n      ...options.args\n    ];\n    this.level = options.level;\n    this.loggerName = options.loggerName;\n    this.#datetime = new Date();\n    this.levelName = getLevelName(options.level);\n  }\n  get args() {\n    return [\n      ...this.#args\n    ];\n  }\n  get datetime() {\n    return new Date(this.#datetime.getTime());\n  }\n}",
	"Logger": "class Logger {\n  #level;\n  handlers;\n  #loggerName;\n  constructor(loggerName, levelName, options = {}){\n    this.#loggerName = loggerName;\n    this.#level = getLevelByName(levelName);\n    this.handlers = options.handlers ?? [];\n  }\n  /** Use this to retrieve the current numeric log level. */ get level() {\n    return this.#level;\n  }\n  /** Use this to set the numeric log level. */ set level(level) {\n    try {\n      this.#level = getLevelByName(getLevelName(level));\n    } catch (_) {\n      throw new TypeError(`Invalid log level: ${level}`);\n    }\n  }\n  get levelName() {\n    return getLevelName(this.#level);\n  }\n  set levelName(levelName) {\n    this.#level = getLevelByName(levelName);\n  }\n  get loggerName() {\n    return this.#loggerName;\n  }\n  /**\n   * If the level of the logger is greater than the level to log, then nothing\n   * is logged, otherwise a log record is passed to each log handler.  `msg` data\n   * passed in is returned.  If a function is passed in, it is only evaluated\n   * if the msg will be logged and the return value will be the result of the\n   * function, not the function itself, unless the function isn't called, in which\n   * case undefined is returned.  All types are coerced to strings for logging.\n   */ #log(level, msg, ...args) {\n    if (this.level > level) {\n      return msg instanceof Function ? undefined : msg;\n    }\n    let fnResult;\n    let logMessage;\n    if (msg instanceof Function) {\n      fnResult = msg();\n      logMessage = this.asString(fnResult);\n    } else {\n      logMessage = this.asString(msg);\n    }\n    const record = new LogRecord({\n      msg: logMessage,\n      args: args,\n      level: level,\n      loggerName: this.loggerName\n    });\n    this.handlers.forEach((handler)=>{\n      handler.handle(record);\n    });\n    return msg instanceof Function ? fnResult : msg;\n  }\n  asString(data, isProperty = false) {\n    if (typeof data === \"string\") {\n      if (isProperty) return `\"${data}\"`;\n      return data;\n    } else if (data === null || typeof data === \"number\" || typeof data === \"bigint\" || typeof data === \"boolean\" || typeof data === \"undefined\" || typeof data === \"symbol\") {\n      return String(data);\n    } else if (data instanceof Error) {\n      return data.stack;\n    } else if (typeof data === \"object\") {\n      return `{${Object.entries(data).map(([k, v])=>`\"${k}\":${this.asString(v, true)}`).join(\",\")}}`;\n    }\n    return \"undefined\";\n  }\n  debug(msg, ...args) {\n    return this.#log(LogLevels.DEBUG, msg, ...args);\n  }\n  info(msg, ...args) {\n    return this.#log(LogLevels.INFO, msg, ...args);\n  }\n  warn(msg, ...args) {\n    return this.#log(LogLevels.WARN, msg, ...args);\n  }\n  error(msg, ...args) {\n    return this.#log(LogLevels.ERROR, msg, ...args);\n  }\n  critical(msg, ...args) {\n    return this.#log(LogLevels.CRITICAL, msg, ...args);\n  }\n}",
	"LoggerConfig": "class LoggerConfig {\n  level;\n  handlers;\n}",
	"RotatingFileHandler": "class RotatingFileHandler extends FileHandler {\n  #maxBytes;\n  #maxBackupCount;\n  #currentFileSize = 0;\n  constructor(levelName, options){\n    super(levelName, options);\n    this.#maxBytes = options.maxBytes;\n    this.#maxBackupCount = options.maxBackupCount;\n  }\n  setup() {\n    if (this.#maxBytes < 1) {\n      this.destroy();\n      throw new Error(`\"maxBytes\" must be >= 1: received ${this.#maxBytes}`);\n    }\n    if (this.#maxBackupCount < 1) {\n      this.destroy();\n      throw new Error(`\"maxBackupCount\" must be >= 1: received ${this.#maxBackupCount}`);\n    }\n    super.setup();\n    if (this[modeSymbol] === \"w\") {\n      // Remove old backups too as it doesn't make sense to start with a clean\n      // log file, but old backups\n      for(let i = 1; i <= this.#maxBackupCount; i++){\n        try {\n          Deno.removeSync(this[filenameSymbol] + \".\" + i);\n        } catch (error) {\n          if (!(error instanceof Deno.errors.NotFound)) {\n            throw error;\n          }\n        }\n      }\n    } else if (this[modeSymbol] === \"x\") {\n      // Throw if any backups also exist\n      for(let i = 1; i <= this.#maxBackupCount; i++){\n        if (existsSync(this[filenameSymbol] + \".\" + i)) {\n          this.destroy();\n          throw new Deno.errors.AlreadyExists(\"Backup log file \" + this[filenameSymbol] + \".\" + i + \" already exists\");\n        }\n      }\n    } else {\n      this.#currentFileSize = Deno.statSync(this[filenameSymbol]).size;\n    }\n  }\n  log(msg) {\n    const msgByteLength = this[encoderSymbol].encode(msg).byteLength + 1;\n    if (this.#currentFileSize + msgByteLength > this.#maxBytes) {\n      this.rotateLogFiles();\n      this.#currentFileSize = 0;\n    }\n    super.log(msg);\n    this.#currentFileSize += msgByteLength;\n  }\n  rotateLogFiles() {\n    this.flush();\n    this[fileSymbol].close();\n    for(let i = this.#maxBackupCount - 1; i >= 0; i--){\n      const source = this[filenameSymbol] + (i === 0 ? \"\" : \".\" + i);\n      const dest = this[filenameSymbol] + \".\" + (i + 1);\n      if (existsSync(source)) {\n        Deno.renameSync(source, dest);\n      }\n    }\n    this[fileSymbol] = Deno.openSync(this[filenameSymbol], this[openOptionsSymbol]);\n  }\n}",
	"critical": "function critical(msg, ...args) {\n  // Assist TS compiler with pass-through generic type\n  if (msg instanceof Function) {\n    return getLogger(\"default\").critical(msg, ...args);\n  }\n  return getLogger(\"default\").critical(msg, ...args);\n}",
	"debug": "function debug(msg, ...args) {\n  // Assist TS compiler with pass-through generic type\n  if (msg instanceof Function) {\n    return getLogger(\"default\").debug(msg, ...args);\n  }\n  return getLogger(\"default\").debug(msg, ...args);\n}",
	"error": "function error(msg, ...args) {\n  // Assist TS compiler with pass-through generic type\n  if (msg instanceof Function) {\n    return getLogger(\"default\").error(msg, ...args);\n  }\n  return getLogger(\"default\").error(msg, ...args);\n}",
	"formatters": {
		"jsonFormatter": "function jsonFormatter(logRecord) {\n  return JSON.stringify({\n    level: logRecord.levelName,\n    datetime: logRecord.datetime.getTime(),\n    message: logRecord.msg,\n    args: flattenArgs(logRecord.args)\n  });\n}"
	},
	"getLevelByName": "function getLevelByName(name) {\n  const level = LogLevels[name];\n  if (level !== undefined) {\n    return level;\n  }\n  throw new Error(`Cannot get log level: no level named ${name}`);\n}",
	"getLevelName": "function getLevelName(level) {\n  const levelName = byLevel[level];\n  if (levelName) {\n    return levelName;\n  }\n  throw new Error(`Cannot get log level: no name for level: ${level}`);\n}",
	"getLogger": "function getLogger(name) {\n  if (!name) {\n    const d = state.loggers.get(\"default\");\n    if (d === undefined) {\n      throw new Error(`\"default\" logger must be set for getting logger without name`);\n    }\n    return d;\n  }\n  const result = state.loggers.get(name);\n  if (!result) {\n    const logger = new Logger(name, \"NOTSET\", {\n      handlers: []\n    });\n    state.loggers.set(name, logger);\n    return logger;\n  }\n  return result;\n}",
	"info": "function info(msg, ...args) {\n  // Assist TS compiler with pass-through generic type\n  if (msg instanceof Function) {\n    return getLogger(\"default\").info(msg, ...args);\n  }\n  return getLogger(\"default\").info(msg, ...args);\n}",
	"jsonFormatter": "function jsonFormatter(logRecord) {\n  return JSON.stringify({\n    level: logRecord.levelName,\n    datetime: logRecord.datetime.getTime(),\n    message: logRecord.msg,\n    args: flattenArgs(logRecord.args)\n  });\n}",
	"setup": "function setup(config) {\n  state.config = {\n    handlers: {\n      ...DEFAULT_CONFIG.handlers,\n      ...config.handlers\n    },\n    loggers: {\n      ...DEFAULT_CONFIG.loggers,\n      ...config.loggers\n    }\n  };\n  // tear down existing handlers\n  state.handlers.forEach((handler)=>{\n    handler.destroy();\n  });\n  state.handlers.clear();\n  // setup handlers\n  const handlers = state.config.handlers ?? {};\n  for (const [handlerName, handler] of Object.entries(handlers)){\n    handler.setup();\n    state.handlers.set(handlerName, handler);\n  }\n  // remove existing loggers\n  state.loggers.clear();\n  // setup loggers\n  const loggers = state.config.loggers ?? {};\n  for (const [loggerName, loggerConfig] of Object.entries(loggers)){\n    const handlerNames = loggerConfig.handlers ?? [];\n    const handlers = [];\n    handlerNames.forEach((handlerName)=>{\n      const handler = state.handlers.get(handlerName);\n      if (handler) {\n        handlers.push(handler);\n      }\n    });\n    const levelName = loggerConfig.level ?? DEFAULT_LEVEL;\n    const logger = new Logger(loggerName, levelName, {\n      handlers: handlers\n    });\n    state.loggers.set(loggerName, logger);\n  }\n}",
	"warn": "function warn(msg, ...args) {\n  // Assist TS compiler with pass-through generic type\n  if (msg instanceof Function) {\n    return getLogger(\"default\").warn(msg, ...args);\n  }\n  return getLogger(\"default\").warn(msg, ...args);\n}"
}
  },
  {
    "jsr:@std/jsonc": {
      "parse": "function parse(text) {\n  if (new.target) {\n    throw new TypeError(\"Cannot create an instance: parse is not a constructor\");\n  }\n  return new JSONCParser(text).parse();\n}"
    }
  },
  {
    "jsr:@std/json": {
      "ConcatenatedJsonParseStream": "class ConcatenatedJsonParseStream {\n  /**\n   * A writable stream of byte data.\n   *\n   * @example Usage\n   * ```ts\n   * import { ConcatenatedJsonParseStream } from \"@std/json/concatenated-json-parse-stream\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const stream = ReadableStream.from([\n   *   `{\"foo\":\"bar\"}`,\n   *   `{\"baz\":100}`,\n   * ]).pipeThrough(new ConcatenatedJsonParseStream());\n   *\n   * assertEquals(await Array.fromAsync(stream), [\n   *   { foo: \"bar\" },\n   *   { baz: 100 },\n   * ]);\n   * ```\n   */ writable;\n  /**\n   * A readable stream of byte data.\n   *\n   * @example Usage\n   * ```ts\n   * import { ConcatenatedJsonParseStream } from \"@std/json/concatenated-json-parse-stream\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const stream = ReadableStream.from([\n   *   `{\"foo\":\"bar\"}`,\n   *   `{\"baz\":100}`,\n   * ]).pipeThrough(new ConcatenatedJsonParseStream());\n   *\n   * assertEquals(await Array.fromAsync(stream), [\n   *   { foo: \"bar\" },\n   *   { baz: 100 },\n   * ]);\n   * ```\n   */ readable;\n  /**\n   * Constructs a new instance.\n   */ constructor(){\n    const { writable, readable } = toTransformStream(this.#concatenatedJSONIterator);\n    this.writable = writable;\n    this.readable = readable;\n  }\n  async *#concatenatedJSONIterator(src) {\n    // Counts the number of '{', '}', '[', ']', and when the nesting level reaches 0, concatenates and returns the string.\n    let targetString = \"\";\n    let hasValue = false;\n    let nestCount = 0;\n    let readingString = false;\n    let escapeNext = false;\n    let readingPrimitive = false;\n    let positionInPrimitive = 0;\n    for await (const string of src){\n      let sliceStart = 0;\n      for(let i = 0; i < string.length; i++){\n        const char = string[i];\n        // We're reading a primitive at the top level\n        if (readingPrimitive) {\n          if (char === readingPrimitive[positionInPrimitive]) {\n            positionInPrimitive++;\n            // Emit the primitive when done reading\n            if (positionInPrimitive === readingPrimitive.length) {\n              yield parse(targetString + string.slice(sliceStart, i + 1));\n              hasValue = false;\n              readingPrimitive = false;\n              positionInPrimitive = 0;\n              targetString = \"\";\n              sliceStart = i + 1;\n            }\n          } else {\n            // If the primitive is malformed, keep reading, maybe the next characters can be useful in the syntax error.\n            readingPrimitive = false;\n            positionInPrimitive = 0;\n          }\n          continue;\n        }\n        if (readingString) {\n          if (char === '\"' && !escapeNext) {\n            readingString = false;\n            // When the nesting level is 0, it returns a string when '\"' comes.\n            if (nestCount === 0 && hasValue) {\n              yield parse(targetString + string.slice(sliceStart, i + 1));\n              hasValue = false;\n              targetString = \"\";\n              sliceStart = i + 1;\n            }\n          }\n          escapeNext = !escapeNext && char === \"\\\\\";\n          continue;\n        }\n        // Parses number with a nesting level of 0.\n        // example: '0[\"foo\"]' => 0, [\"foo\"]\n        // example: '3.14{\"foo\": \"bar\"}' => 3.14, {foo: \"bar\"}\n        if (hasValue && nestCount === 0 && (char === \"{\" || char === \"[\" || char === '\"' || char === \" \" || char === \"n\" || char === \"t\" || char === \"f\")) {\n          yield parse(targetString + string.slice(sliceStart, i));\n          hasValue = false;\n          readingString = false;\n          targetString = \"\";\n          sliceStart = i;\n          i--;\n          continue;\n        }\n        switch(char){\n          case '\"':\n            readingString = true;\n            escapeNext = false;\n            break;\n          case \"{\":\n          case \"[\":\n            nestCount++;\n            break;\n          case \"}\":\n          case \"]\":\n            nestCount--;\n            break;\n        }\n        if (nestCount === 0 && primitives.has(char)) {\n          // The first letter of a primitive at top level was found\n          readingPrimitive = primitives.get(char);\n          positionInPrimitive = 1;\n        }\n        // parse object or array\n        if (hasValue && nestCount === 0 && (char === \"}\" || char === \"]\")) {\n          yield parse(targetString + string.slice(sliceStart, i + 1));\n          hasValue = false;\n          targetString = \"\";\n          sliceStart = i + 1;\n          continue;\n        }\n        if (!hasValue && !isBlankChar(char)) {\n          // We want to ignore the character string with only blank, so if there is a character other than blank, record it.\n          hasValue = true;\n        }\n      }\n      targetString += string.slice(sliceStart);\n    }\n    if (hasValue) {\n      yield parse(targetString);\n    }\n  }\n}",
      "JsonParseStream": "class JsonParseStream extends TransformStream {\n  /**\n   * Constructs new instance.\n   */ constructor(){\n    super({\n      transform (chunk, controller) {\n        if (!isBrankString(chunk)) {\n          controller.enqueue(parse(chunk));\n        }\n      }\n    });\n  }\n}",
      "JsonStringifyStream": "class JsonStringifyStream extends TransformStream {\n  /**\n   * Constructs new instance.\n   *\n   * @param options Options for the stream.\n   */ constructor(options){\n    const { prefix = \"\", suffix = \"\\n\" } = options ?? {};\n    super({\n      transform (chunk, controller) {\n        controller.enqueue(`${prefix}${JSON.stringify(chunk)}${suffix}`);\n      }\n    });\n  }\n}"
    }
  },
  {
    "jsr:@std/io": {
      "AbstractBufBase": "class AbstractBufBase {\n  /**\n   * The buffer\n   *\n   * @example Usage\n   * ```ts\n   * import { AbstractBufBase } from \"@std/io/buf-writer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * class MyBuffer extends AbstractBufBase {}\n   *\n   * const buf = new Uint8Array(1024);\n   * const mb = new MyBuffer(buf);\n   *\n   * assertEquals(mb.buf, buf);\n   * ```\n   */ buf;\n  /**\n   * The used buffer bytes\n   *\n   * @example Usage\n   * ```ts\n   * import { AbstractBufBase } from \"@std/io/buf-writer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * class MyBuffer extends AbstractBufBase {}\n   *\n   * const buf = new Uint8Array(1024);\n   * const mb = new MyBuffer(buf);\n   *\n   * assertEquals(mb.usedBufferBytes, 0);\n   * ```\n   */ usedBufferBytes = 0;\n  /**\n   * The error\n   *\n   * @example Usage\n   * ```ts\n   * import { AbstractBufBase } from \"@std/io/buf-writer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * class MyBuffer extends AbstractBufBase {}\n   *\n   * const buf = new Uint8Array(1024);\n   * const mb = new MyBuffer(buf);\n   *\n   * assertEquals(mb.err, null);\n   * ```\n   */ err = null;\n  /**\n   * Construct a {@linkcode AbstractBufBase} instance\n   *\n   * @param buf The buffer to use.\n   */ constructor(buf){\n    this.buf = buf;\n  }\n  /**\n   * Size returns the size of the underlying buffer in bytes.\n   *\n   * @example Usage\n   * ```ts\n   * import { AbstractBufBase } from \"@std/io/buf-writer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * class MyBuffer extends AbstractBufBase {}\n   *\n   * const buf = new Uint8Array(1024);\n   * const mb = new MyBuffer(buf);\n   *\n   * assertEquals(mb.size(), 1024);\n   * ```\n   *\n   * @return the size of the buffer in bytes.\n   */ size() {\n    return this.buf.byteLength;\n  }\n  /**\n   * Returns how many bytes are unused in the buffer.\n   *\n   * @example Usage\n   * ```ts\n   * import { AbstractBufBase } from \"@std/io/buf-writer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * class MyBuffer extends AbstractBufBase {}\n   *\n   * const buf = new Uint8Array(1024);\n   * const mb = new MyBuffer(buf);\n   *\n   * assertEquals(mb.available(), 1024);\n   * ```\n   *\n   * @return the number of bytes that are unused in the buffer.\n   */ available() {\n    return this.buf.byteLength - this.usedBufferBytes;\n  }\n  /**\n   * buffered returns the number of bytes that have been written into the\n   * current buffer.\n   *\n   * @example Usage\n   * ```ts\n   * import { AbstractBufBase } from \"@std/io/buf-writer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * class MyBuffer extends AbstractBufBase {}\n   *\n   * const buf = new Uint8Array(1024);\n   * const mb = new MyBuffer(buf);\n   *\n   * assertEquals(mb.buffered(), 0);\n   * ```\n   *\n   * @return the number of bytes that have been written into the current buffer.\n   */ buffered() {\n    return this.usedBufferBytes;\n  }\n}",
      "BufReader": "class BufReader {\n  #buf;\n  #rd;\n  #r = 0;\n  #w = 0;\n  #eof = false;\n  /**\n   * Returns a new {@linkcode BufReader} if `r` is not already one.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufReader, Buffer } from \"@std/io\";\n   * import { assert } from \"@std/assert/assert\";\n   *\n   * const reader = new Buffer(new TextEncoder().encode(\"hello world\"));\n   * const bufReader = BufReader.create(reader);\n   * assert(bufReader instanceof BufReader);\n   * ```\n   *\n   * @param r The reader to read from.\n   * @param size The size of the buffer.\n   * @returns A new {@linkcode BufReader} if `r` is not already one.\n   */ static create(r, size = DEFAULT_BUF_SIZE) {\n    return r instanceof BufReader ? r : new BufReader(r, size);\n  }\n  /**\n   * Constructs a new {@linkcode BufReader} for the given reader and buffer size.\n   *\n   * @param rd The reader to read from.\n   * @param size The size of the buffer.\n   */ constructor(rd, size = DEFAULT_BUF_SIZE){\n    if (size < MIN_BUF_SIZE) {\n      size = MIN_BUF_SIZE;\n    }\n    this.#reset(new Uint8Array(size), rd);\n  }\n  /**\n   * Returns the size of the underlying buffer in bytes.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufReader, Buffer } from \"@std/io\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const reader = new Buffer(new TextEncoder().encode(\"hello world\"));\n   * const bufReader = new BufReader(reader);\n   *\n   * assertEquals(bufReader.size(), 4096);\n   * ```\n   *\n   * @returns The size of the underlying buffer in bytes.\n   */ size() {\n    return this.#buf.byteLength;\n  }\n  /**\n   * Returns the number of bytes that can be read from the current buffer.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufReader, Buffer } from \"@std/io\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const reader = new Buffer(new TextEncoder().encode(\"hello world\"));\n   * const bufReader = new BufReader(reader);\n   * await bufReader.read(new Uint8Array(5));\n   * assertEquals(bufReader.buffered(), 6);\n   * ```\n   *\n   * @returns Number of bytes that can be read from the buffer\n   */ buffered() {\n    return this.#w - this.#r;\n  }\n  // Reads a new chunk into the buffer.\n  #fill = async ()=>{\n    // Slide existing data to beginning.\n    if (this.#r > 0) {\n      this.#buf.copyWithin(0, this.#r, this.#w);\n      this.#w -= this.#r;\n      this.#r = 0;\n    }\n    if (this.#w >= this.#buf.byteLength) {\n      throw new Error(\"Buffer full while filling\");\n    }\n    // Read new data: try a limited number of times.\n    for(let i = MAX_CONSECUTIVE_EMPTY_READS; i > 0; i--){\n      const rr = await this.#rd.read(this.#buf.subarray(this.#w));\n      if (rr === null) {\n        this.#eof = true;\n        return;\n      }\n      this.#w += rr;\n      if (rr > 0) {\n        return;\n      }\n    }\n    throw new Error(`No progress after ${MAX_CONSECUTIVE_EMPTY_READS} read() calls`);\n  };\n  /**\n   * Discards any buffered data, resets all state, and switches\n   * the buffered reader to read from `r`.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufReader, Buffer } from \"@std/io\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const reader = new Buffer(new TextEncoder().encode(\"hello world\"));\n   * const bufReader = new BufReader(reader);\n   * await bufReader.read(new Uint8Array(5));\n   * bufReader.reset(reader);\n   * assertEquals(bufReader.buffered(), 6);\n   * ```\n   *\n   * @param r The reader to read from.\n   */ reset(r) {\n    this.#reset(this.#buf, r);\n  }\n  #reset = (buf, rd)=>{\n    this.#buf = buf;\n    this.#rd = rd;\n    this.#eof = false;\n  // this.lastByte = -1;\n  // this.lastCharSize = -1;\n  };\n  /**\n   * Reads data into `p`.\n   *\n   * The bytes are taken from at most one `read()` on the underlying `Reader`,\n   * hence n may be less than `len(p)`.\n   * To read exactly `len(p)` bytes, use `io.ReadFull(b, p)`.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufReader, Buffer } from \"@std/io\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const reader = new Buffer(new TextEncoder().encode(\"hello world\"));\n   * const bufReader = new BufReader(reader);\n   * const buf = new Uint8Array(5);\n   * await bufReader.read(buf);\n   * assertEquals(new TextDecoder().decode(buf), \"hello\");\n   * ```\n   *\n   * @param p The buffer to read data into.\n   * @returns The number of bytes read into `p`.\n   */ async read(p) {\n    let rr = p.byteLength;\n    if (p.byteLength === 0) return rr;\n    if (this.#r === this.#w) {\n      if (p.byteLength >= this.#buf.byteLength) {\n        // Large read, empty buffer.\n        // Read directly into p to avoid copy.\n        const rr = await this.#rd.read(p);\n        // if (rr.nread > 0) {\n        //   this.lastByte = p[rr.nread - 1];\n        //   this.lastCharSize = -1;\n        // }\n        return rr;\n      }\n      // One read.\n      // Do not use this.fill, which will loop.\n      this.#r = 0;\n      this.#w = 0;\n      rr = await this.#rd.read(this.#buf);\n      if (rr === 0 || rr === null) return rr;\n      this.#w += rr;\n    }\n    // copy as much as we can\n    const copied = copy(this.#buf.subarray(this.#r, this.#w), p, 0);\n    this.#r += copied;\n    // this.lastByte = this.buf[this.r - 1];\n    // this.lastCharSize = -1;\n    return copied;\n  }\n  /**\n   * Reads exactly `p.length` bytes into `p`.\n   *\n   * If successful, `p` is returned.\n   *\n   * If the end of the underlying stream has been reached, and there are no more\n   * bytes available in the buffer, `readFull()` returns `null` instead.\n   *\n   * An error is thrown if some bytes could be read, but not enough to fill `p`\n   * entirely before the underlying stream reported an error or EOF. Any error\n   * thrown will have a `partial` property that indicates the slice of the\n   * buffer that has been successfully filled with data.\n   *\n   * Ported from https://golang.org/pkg/io/#ReadFull\n   *\n   * @example Usage\n   * ```ts\n   * import { BufReader, Buffer } from \"@std/io\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const reader = new Buffer(new TextEncoder().encode(\"hello world\"));\n   * const bufReader = new BufReader(reader);\n   * const buf = new Uint8Array(5);\n   * await bufReader.readFull(buf);\n   * assertEquals(new TextDecoder().decode(buf), \"hello\");\n   * ```\n   *\n   * @param p The buffer to read data into.\n   * @returns The buffer `p` if the read is successful, `null` if the end of the\n   * underlying stream has been reached, and there are no more bytes available in the buffer.\n   */ async readFull(p) {\n    let bytesRead = 0;\n    while(bytesRead < p.length){\n      const rr = await this.read(p.subarray(bytesRead));\n      if (rr === null) {\n        if (bytesRead === 0) {\n          return null;\n        } else {\n          throw new PartialReadError(p.subarray(0, bytesRead));\n        }\n      }\n      bytesRead += rr;\n    }\n    return p;\n  }\n  /**\n   * Returns the next byte ([0, 255]) or `null`.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufReader, Buffer } from \"@std/io\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const reader = new Buffer(new TextEncoder().encode(\"hello world\"));\n   * const bufReader = new BufReader(reader);\n   * const byte = await bufReader.readByte();\n   * assertEquals(byte, 104);\n   * ```\n   *\n   * @returns The next byte ([0, 255]) or `null`.\n   */ async readByte() {\n    while(this.#r === this.#w){\n      if (this.#eof) return null;\n      await this.#fill(); // buffer is empty.\n    }\n    const c = this.#buf[this.#r];\n    this.#r++;\n    // this.lastByte = c;\n    return c;\n  }\n  /**\n   * Reads until the first occurrence of delim in the input,\n   * returning a string containing the data up to and including the delimiter.\n   * If ReadString encounters an error before finding a delimiter,\n   * it returns the data read before the error and the error itself\n   * (often `null`).\n   * ReadString returns err !== null if and only if the returned data does not end\n   * in delim.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufReader, Buffer } from \"@std/io\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const reader = new Buffer(new TextEncoder().encode(\"hello world\"));\n   * const bufReader = new BufReader(reader);\n   * const str = await bufReader.readString(\" \");\n   * assertEquals(str, \"hello \");\n   *\n   * const str2 = await bufReader.readString(\" \");\n   * assertEquals(str2, \"world\");\n   * ```\n   *\n   * @param delim The delimiter to read until.\n   * @returns The string containing the data up to and including the delimiter.\n   */ async readString(delim) {\n    if (delim.length !== 1) {\n      throw new Error(\"Delimiter should be a single character\");\n    }\n    const buffer = await this.readSlice(delim.charCodeAt(0));\n    if (buffer === null) return null;\n    return new TextDecoder().decode(buffer);\n  }\n  /**\n   * A low-level line-reading primitive. Most callers should use\n   * `readString('\\n')` instead.\n   *\n   * `readLine()` tries to return a single line, not including the end-of-line\n   * bytes. If the line was too long for the buffer then `more` is set and the\n   * beginning of the line is returned. The rest of the line will be returned\n   * from future calls. `more` will be false when returning the last fragment\n   * of the line. The returned buffer is only valid until the next call to\n   * `readLine()`.\n   *\n   * The text returned from this method does not include the line end (\"\\r\\n\" or\n   * \"\\n\").\n   *\n   * When the end of the underlying stream is reached, the final bytes in the\n   * stream are returned. No indication or error is given if the input ends\n   * without a final line end. When there are no more trailing bytes to read,\n   * `readLine()` returns `null`.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufReader, Buffer } from \"@std/io\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const reader = new Buffer(new TextEncoder().encode(\"hello\\nworld\"));\n   * const bufReader = new BufReader(reader);\n   * const line1 = await bufReader.readLine();\n   * assertEquals(new TextDecoder().decode(line1!.line), \"hello\");\n   * const line2 = await bufReader.readLine();\n   * assertEquals(new TextDecoder().decode(line2!.line), \"world\");\n   * ```\n   *\n   * @returns The line read.\n   */ async readLine() {\n    let line = null;\n    try {\n      line = await this.readSlice(LF);\n    } catch (err) {\n      // Don't throw if `readSlice()` failed with `BufferFullError`, instead we\n      // just return whatever is available and set the `more` flag.\n      if (!(err instanceof BufferFullError)) {\n        throw err;\n      }\n      let partial = err.partial;\n      // Handle the case where \"\\r\\n\" straddles the buffer.\n      if (!this.#eof && partial && partial.byteLength > 0 && partial[partial.byteLength - 1] === CR) {\n        // Put the '\\r' back on buf and drop it from line.\n        // Let the next call to ReadLine check for \"\\r\\n\".\n        if (this.#r <= 0) {\n          throw new Error(\"Tried to rewind past start of buffer\");\n        }\n        this.#r--;\n        partial = partial.subarray(0, partial.byteLength - 1);\n      }\n      if (partial) {\n        return {\n          line: partial,\n          more: !this.#eof\n        };\n      }\n    }\n    if (line === null) {\n      return null;\n    }\n    if (line.byteLength === 0) {\n      return {\n        line,\n        more: false\n      };\n    }\n    if (line[line.byteLength - 1] === LF) {\n      let drop = 1;\n      if (line.byteLength > 1 && line[line.byteLength - 2] === CR) {\n        drop = 2;\n      }\n      line = line.subarray(0, line.byteLength - drop);\n    }\n    return {\n      line,\n      more: false\n    };\n  }\n  /**\n   * Reads until the first occurrence of `delim` in the input,\n   * returning a slice pointing at the bytes in the buffer. The bytes stop\n   * being valid at the next read.\n   *\n   * If `readSlice()` encounters an error before finding a delimiter, or the\n   * buffer fills without finding a delimiter, it throws an error with a\n   * `partial` property that contains the entire buffer.\n   *\n   * If `readSlice()` encounters the end of the underlying stream and there are\n   * any bytes left in the buffer, the rest of the buffer is returned. In other\n   * words, EOF is always treated as a delimiter. Once the buffer is empty,\n   * it returns `null`.\n   *\n   * Because the data returned from `readSlice()` will be overwritten by the\n   * next I/O operation, most clients should use `readString()` instead.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufReader, Buffer } from \"@std/io\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const reader = new Buffer(new TextEncoder().encode(\"hello world\"));\n   * const bufReader = new BufReader(reader);\n   * const slice = await bufReader.readSlice(0x20);\n   * assertEquals(new TextDecoder().decode(slice!), \"hello \");\n   * ```\n   *\n   * @param delim The delimiter to read until.\n   * @returns A slice pointing at the bytes in the buffer.\n   */ async readSlice(delim) {\n    let s = 0; // search start index\n    let slice;\n    while(true){\n      // Search buffer.\n      let i = this.#buf.subarray(this.#r + s, this.#w).indexOf(delim);\n      if (i >= 0) {\n        i += s;\n        slice = this.#buf.subarray(this.#r, this.#r + i + 1);\n        this.#r += i + 1;\n        break;\n      }\n      // EOF?\n      if (this.#eof) {\n        if (this.#r === this.#w) {\n          return null;\n        }\n        slice = this.#buf.subarray(this.#r, this.#w);\n        this.#r = this.#w;\n        break;\n      }\n      // Buffer full?\n      if (this.buffered() >= this.#buf.byteLength) {\n        this.#r = this.#w;\n        // #4521 The internal buffer should not be reused across reads because it causes corruption of data.\n        const oldbuf = this.#buf;\n        const newbuf = this.#buf.slice(0);\n        this.#buf = newbuf;\n        throw new BufferFullError(oldbuf);\n      }\n      s = this.#w - this.#r; // do not rescan area we scanned before\n      // Buffer is not full.\n      await this.#fill();\n    }\n    // Handle last byte, if any.\n    // const i = slice.byteLength - 1;\n    // if (i >= 0) {\n    //   this.lastByte = slice[i];\n    //   this.lastCharSize = -1\n    // }\n    return slice;\n  }\n  /**\n   * Returns the next `n` bytes without advancing the reader. The\n   * bytes stop being valid at the next read call.\n   *\n   * When the end of the underlying stream is reached, but there are unread\n   * bytes left in the buffer, those bytes are returned. If there are no bytes\n   * left in the buffer, it returns `null`.\n   *\n   * If an error is encountered before `n` bytes are available, `peek()` throws\n   * an error with the `partial` property set to a slice of the buffer that\n   * contains the bytes that were available before the error occurred.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufReader, Buffer } from \"@std/io\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const reader = new Buffer(new TextEncoder().encode(\"hello world\"));\n   * const bufReader = new BufReader(reader);\n   * const peeked = await bufReader.peek(5);\n   * assertEquals(new TextDecoder().decode(peeked!), \"hello\");\n   * ```\n   *\n   * @param n The number of bytes to peek.\n   * @returns The next `n` bytes without advancing the reader.\n   */ async peek(n) {\n    if (n < 0) {\n      throw new Error(\"Peek count cannot be negative\");\n    }\n    let avail = this.#w - this.#r;\n    while(avail < n && avail < this.#buf.byteLength && !this.#eof){\n      await this.#fill();\n      avail = this.#w - this.#r;\n    }\n    if (avail === 0 && this.#eof) {\n      return null;\n    } else if (avail < n && this.#eof) {\n      return this.#buf.subarray(this.#r, this.#r + avail);\n    } else if (avail < n) {\n      throw new BufferFullError(this.#buf.subarray(this.#r, this.#w));\n    }\n    return this.#buf.subarray(this.#r, this.#r + n);\n  }\n}",
      "BufWriter": "class BufWriter extends AbstractBufBase {\n  #writer;\n  /**\n   * return new BufWriter unless writer is BufWriter\n   *\n   * @example Usage\n   * ```ts\n   * import { BufWriter } from \"@std/io/buf-writer\";\n   * import { Writer } from \"@std/io/types\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const writer: Writer = {\n   *   write(p: Uint8Array): Promise<number> {\n   *     return Promise.resolve(p.length);\n   *   }\n   * };\n   *\n   * const bufWriter = BufWriter.create(writer);\n   * const data = new Uint8Array(1024);\n   *\n   * await bufWriter.write(data);\n   *\n   * assertEquals(bufWriter.buffered(), 1024);\n   * ```\n   *\n   * @param writer The writer to wrap.\n   * @param size The size of the buffer.\n   *\n   * @return a new {@linkcode BufWriter} instance.\n   */ static create(writer, size = DEFAULT_BUF_SIZE) {\n    return writer instanceof BufWriter ? writer : new BufWriter(writer, size);\n  }\n  /**\n   * Construct a new {@linkcode BufWriter}\n   *\n   * @param writer The writer to wrap.\n   * @param size The size of the buffer.\n   */ constructor(writer, size = DEFAULT_BUF_SIZE){\n    super(new Uint8Array(size <= 0 ? DEFAULT_BUF_SIZE : size));\n    this.#writer = writer;\n  }\n  /**\n   * Discards any unflushed buffered data, clears any error, and\n   * resets buffer to write its output to w.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufWriter } from \"@std/io/buf-writer\";\n   * import { Writer } from \"@std/io/types\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const writer: Writer = {\n   *   write(p: Uint8Array): Promise<number> {\n   *     return Promise.resolve(p.length);\n   *   }\n   * };\n   *\n   * const bufWriter = new BufWriter(writer);\n   * const data = new Uint8Array(1024);\n   *\n   * await bufWriter.write(data);\n   *\n   * assertEquals(bufWriter.buffered(), 1024);\n   *\n   * bufWriter.reset(writer);\n   *\n   * assertEquals(bufWriter.buffered(), 0);\n   * ```\n   *\n   * @param w The writer to write to.\n   */ reset(w) {\n    this.err = null;\n    this.usedBufferBytes = 0;\n    this.#writer = w;\n  }\n  /**\n   * Flush writes any buffered data to the underlying io.Writer.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufWriter } from \"@std/io/buf-writer\";\n   * import { Writer } from \"@std/io/types\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const writer: Writer = {\n   *   write(p: Uint8Array): Promise<number> {\n   *     return Promise.resolve(p.length);\n   *   }\n   * };\n   *\n   * const bufWriter = new BufWriter(writer);\n   * const data = new Uint8Array(1024);\n   *\n   * await bufWriter.write(data);\n   * await bufWriter.flush();\n   *\n   * assertEquals(bufWriter.buffered(), 0);\n   * ```\n   */ async flush() {\n    if (this.err !== null) throw this.err;\n    if (this.usedBufferBytes === 0) return;\n    try {\n      const p = this.buf.subarray(0, this.usedBufferBytes);\n      let nwritten = 0;\n      while(nwritten < p.length){\n        nwritten += await this.#writer.write(p.subarray(nwritten));\n      }\n    } catch (e) {\n      if (e instanceof Error) {\n        this.err = e;\n      }\n      throw e;\n    }\n    this.buf = new Uint8Array(this.buf.length);\n    this.usedBufferBytes = 0;\n  }\n  /**\n   * Writes the contents of `data` into the buffer. If the contents won't fully\n   * fit into the buffer, those bytes that are copied into the buffer will be flushed\n   * to the writer and the remaining bytes are then copied into the now empty buffer.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufWriter } from \"@std/io/buf-writer\";\n   * import { Writer } from \"@std/io/types\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const writer: Writer = {\n   *   write(p: Uint8Array): Promise<number> {\n   *     return Promise.resolve(p.length);\n   *   }\n   * };\n   *\n   * const bufWriter = new BufWriter(writer);\n   * const data = new Uint8Array(1024);\n   *\n   * await bufWriter.write(data);\n   *\n   * assertEquals(bufWriter.buffered(), 1024);\n   * ```\n   *\n   * @param data The data to write to the buffer.\n   * @return the number of bytes written to the buffer.\n   */ async write(data) {\n    if (this.err !== null) throw this.err;\n    if (data.length === 0) return 0;\n    let totalBytesWritten = 0;\n    let numBytesWritten = 0;\n    while(data.byteLength > this.available()){\n      if (this.buffered() === 0) {\n        // Large write, empty buffer.\n        // Write directly from data to avoid copy.\n        try {\n          numBytesWritten = await this.#writer.write(data);\n        } catch (e) {\n          if (e instanceof Error) {\n            this.err = e;\n          }\n          throw e;\n        }\n      } else {\n        numBytesWritten = copy(data, this.buf, this.usedBufferBytes);\n        this.usedBufferBytes += numBytesWritten;\n        await this.flush();\n      }\n      totalBytesWritten += numBytesWritten;\n      data = data.subarray(numBytesWritten);\n    }\n    numBytesWritten = copy(data, this.buf, this.usedBufferBytes);\n    this.usedBufferBytes += numBytesWritten;\n    totalBytesWritten += numBytesWritten;\n    return totalBytesWritten;\n  }\n}",
      "BufWriterSync": "class BufWriterSync extends AbstractBufBase {\n  #writer;\n  /**\n   * return new BufWriterSync unless writer is BufWriterSync\n   *\n   * @example Usage\n   * ```ts\n   * import { BufWriterSync } from \"@std/io/buf-writer\";\n   * import { WriterSync } from \"@std/io/types\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const writer: WriterSync = {\n   *   writeSync(p: Uint8Array): number {\n   *     return p.length;\n   *   }\n   * };\n   *\n   * const bufWriter = BufWriterSync.create(writer);\n   * const data = new Uint8Array(1024);\n   * bufWriter.writeSync(data);\n   * bufWriter.flush();\n   *\n   * assertEquals(bufWriter.buffered(), 0);\n   * ```\n   *\n   * @param writer The writer to wrap.\n   * @param size The size of the buffer.\n   * @returns a new {@linkcode BufWriterSync} instance.\n   */ static create(writer, size = DEFAULT_BUF_SIZE) {\n    return writer instanceof BufWriterSync ? writer : new BufWriterSync(writer, size);\n  }\n  /**\n   * Construct a new {@linkcode BufWriterSync}\n   *\n   * @param writer The writer to wrap.\n   * @param size The size of the buffer.\n   */ constructor(writer, size = DEFAULT_BUF_SIZE){\n    super(new Uint8Array(size <= 0 ? DEFAULT_BUF_SIZE : size));\n    this.#writer = writer;\n  }\n  /**\n   * Discards any unflushed buffered data, clears any error, and\n   * resets buffer to write its output to w.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufWriterSync } from \"@std/io/buf-writer\";\n   * import { WriterSync } from \"@std/io/types\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const writer: WriterSync = {\n   *   writeSync(p: Uint8Array): number {\n   *     return p.length;\n   *   }\n   * };\n   *\n   * const bufWriter = new BufWriterSync(writer);\n   * const data = new Uint8Array(1024);\n   *\n   * bufWriter.writeSync(data);\n   * bufWriter.flush();\n   *\n   * assertEquals(bufWriter.buffered(), 0);\n   * ```\n   *\n   * @param w The writer to write to.\n   */ reset(w) {\n    this.err = null;\n    this.usedBufferBytes = 0;\n    this.#writer = w;\n  }\n  /**\n   * Flush writes any buffered data to the underlying io.WriterSync.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufWriterSync } from \"@std/io/buf-writer\";\n   * import { WriterSync } from \"@std/io/types\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const writer: WriterSync = {\n   *   writeSync(p: Uint8Array): number {\n   *     return p.length;\n   *   }\n   * };\n   *\n   * const bufWriter = new BufWriterSync(writer);\n   * const data = new Uint8Array(1024);\n   *\n   * bufWriter.writeSync(data);\n   * bufWriter.flush();\n   *\n   * assertEquals(bufWriter.buffered(), 0);\n   * ```\n   */ flush() {\n    if (this.err !== null) throw this.err;\n    if (this.usedBufferBytes === 0) return;\n    try {\n      const p = this.buf.subarray(0, this.usedBufferBytes);\n      let nwritten = 0;\n      while(nwritten < p.length){\n        nwritten += this.#writer.writeSync(p.subarray(nwritten));\n      }\n    } catch (e) {\n      if (e instanceof Error) {\n        this.err = e;\n      }\n      throw e;\n    }\n    this.buf = new Uint8Array(this.buf.length);\n    this.usedBufferBytes = 0;\n  }\n  /** Writes the contents of `data` into the buffer.  If the contents won't fully\n   * fit into the buffer, those bytes that can are copied into the buffer, the\n   * buffer is the flushed to the writer and the remaining bytes are copied into\n   * the now empty buffer.\n   *\n   * @example Usage\n   * ```ts\n   * import { BufWriterSync } from \"@std/io/buf-writer\";\n   * import { WriterSync } from \"@std/io/types\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const writer: WriterSync = {\n   *   writeSync(p: Uint8Array): number {\n   *     return p.length;\n   *   }\n   * };\n   *\n   * const bufWriter = new BufWriterSync(writer);\n   * const data = new Uint8Array(1024);\n   *\n   * bufWriter.writeSync(data);\n   * bufWriter.flush();\n   *\n   * assertEquals(bufWriter.buffered(), 0);\n   * ```\n   *\n   * @param data The data to write to the buffer.\n   * @return the number of bytes written to the buffer.\n   */ writeSync(data) {\n    if (this.err !== null) throw this.err;\n    if (data.length === 0) return 0;\n    let totalBytesWritten = 0;\n    let numBytesWritten = 0;\n    while(data.byteLength > this.available()){\n      if (this.buffered() === 0) {\n        // Large write, empty buffer.\n        // Write directly from data to avoid copy.\n        try {\n          numBytesWritten = this.#writer.writeSync(data);\n        } catch (e) {\n          if (e instanceof Error) {\n            this.err = e;\n          }\n          throw e;\n        }\n      } else {\n        numBytesWritten = copy(data, this.buf, this.usedBufferBytes);\n        this.usedBufferBytes += numBytesWritten;\n        this.flush();\n      }\n      totalBytesWritten += numBytesWritten;\n      data = data.subarray(numBytesWritten);\n    }\n    numBytesWritten = copy(data, this.buf, this.usedBufferBytes);\n    this.usedBufferBytes += numBytesWritten;\n    totalBytesWritten += numBytesWritten;\n    return totalBytesWritten;\n  }\n}",
      "Buffer": "class Buffer {\n  #buf;\n  #off = 0;\n  /**\n   * Constructs a new instance with the specified {@linkcode ArrayBuffer} as its\n   * initial contents.\n   *\n   * @param ab The ArrayBuffer to use as the initial contents of the buffer.\n   */ constructor(ab){\n    this.#buf = ab === undefined ? new Uint8Array(0) : new Uint8Array(ab);\n  }\n  /**\n   * Returns a slice holding the unread portion of the buffer.\n   *\n   * The slice is valid for use only until the next buffer modification (that\n   * is, only until the next call to a method like `read()`, `write()`,\n   * `reset()`, or `truncate()`). If `options.copy` is false the slice aliases the buffer content at\n   * least until the next buffer modification, so immediate changes to the\n   * slice will affect the result of future reads.\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * await buf.write(new TextEncoder().encode(\"Hello, world!\"));\n   *\n   * const slice = buf.bytes();\n   * assertEquals(new TextDecoder().decode(slice), \"Hello, world!\");\n   * ```\n   *\n   * @param options The options for the slice.\n   * @returns A slice holding the unread portion of the buffer.\n   */ bytes(options = {\n    copy: true\n  }) {\n    if (options.copy === false) return this.#buf.subarray(this.#off);\n    return this.#buf.slice(this.#off);\n  }\n  /**\n   * Returns whether the unread portion of the buffer is empty.\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * assertEquals(buf.empty(), true);\n   * await buf.write(new TextEncoder().encode(\"Hello, world!\"));\n   * assertEquals(buf.empty(), false);\n   * ```\n   *\n   * @returns `true` if the unread portion of the buffer is empty, `false`\n   *          otherwise.\n   */ empty() {\n    return this.#buf.byteLength <= this.#off;\n  }\n  /**\n   * A read only number of bytes of the unread portion of the buffer.\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * await buf.write(new TextEncoder().encode(\"Hello, world!\"));\n   *\n   * assertEquals(buf.length, 13);\n   * ```\n   *\n   * @returns The number of bytes of the unread portion of the buffer.\n   */ get length() {\n    return this.#buf.byteLength - this.#off;\n  }\n  /**\n   * The read only capacity of the buffer's underlying byte slice, that is,\n   * the total space allocated for the buffer's data.\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * assertEquals(buf.capacity, 0);\n   * await buf.write(new TextEncoder().encode(\"Hello, world!\"));\n   * assertEquals(buf.capacity, 13);\n   * ```\n   *\n   * @returns The capacity of the buffer.\n   */ get capacity() {\n    return this.#buf.buffer.byteLength;\n  }\n  /**\n   * Discards all but the first `n` unread bytes from the buffer but\n   * continues to use the same allocated storage. It throws if `n` is\n   * negative or greater than the length of the buffer.\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * await buf.write(new TextEncoder().encode(\"Hello, world!\"));\n   * buf.truncate(6);\n   * assertEquals(buf.length, 6);\n   * ```\n   *\n   * @param n The number of bytes to keep.\n   */ truncate(n) {\n    if (n === 0) {\n      this.reset();\n      return;\n    }\n    if (n < 0 || n > this.length) {\n      throw new Error(\"Buffer truncation out of range\");\n    }\n    this.#reslice(this.#off + n);\n  }\n  /**\n   * Resets the contents\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * await buf.write(new TextEncoder().encode(\"Hello, world!\"));\n   * buf.reset();\n   * assertEquals(buf.length, 0);\n   * ```\n   */ reset() {\n    this.#reslice(0);\n    this.#off = 0;\n  }\n  #tryGrowByReslice(n) {\n    const l = this.#buf.byteLength;\n    if (n <= this.capacity - l) {\n      this.#reslice(l + n);\n      return l;\n    }\n    return -1;\n  }\n  #reslice(len) {\n    if (len > this.#buf.buffer.byteLength) {\n      throw new RangeError(\"Length is greater than buffer capacity\");\n    }\n    this.#buf = new Uint8Array(this.#buf.buffer, 0, len);\n  }\n  /**\n   * Reads the next `p.length` bytes from the buffer or until the buffer is\n   * drained. Returns the number of bytes read. If the buffer has no data to\n   * return, the return is EOF (`null`).\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * await buf.write(new TextEncoder().encode(\"Hello, world!\"));\n   *\n   * const data = new Uint8Array(5);\n   * const res = await buf.read(data);\n   *\n   * assertEquals(res, 5);\n   * assertEquals(new TextDecoder().decode(data), \"Hello\");\n   * ```\n   *\n   * @param p The buffer to read data into.\n   * @returns The number of bytes read.\n   */ readSync(p) {\n    if (this.empty()) {\n      // Buffer is empty, reset to recover space.\n      this.reset();\n      if (p.byteLength === 0) {\n        // this edge case is tested in 'bufferReadEmptyAtEOF' test\n        return 0;\n      }\n      return null;\n    }\n    const nread = copy(this.#buf.subarray(this.#off), p);\n    this.#off += nread;\n    return nread;\n  }\n  /**\n   * Reads the next `p.length` bytes from the buffer or until the buffer is\n   * drained. Resolves to the number of bytes read. If the buffer has no\n   * data to return, resolves to EOF (`null`).\n   *\n   * NOTE: This methods reads bytes synchronously; it's provided for\n   * compatibility with `Reader` interfaces.\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * await buf.write(new TextEncoder().encode(\"Hello, world!\"));\n   *\n   * const data = new Uint8Array(5);\n   * const res = await buf.read(data);\n   *\n   * assertEquals(res, 5);\n   * assertEquals(new TextDecoder().decode(data), \"Hello\");\n   * ```\n   *\n   * @param p The buffer to read data into.\n   * @returns The number of bytes read.\n   */ read(p) {\n    const rr = this.readSync(p);\n    return Promise.resolve(rr);\n  }\n  /**\n   * Writes the given data to the buffer.\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * const data = new TextEncoder().encode(\"Hello, world!\");\n   * buf.writeSync(data);\n   *\n   * const slice = buf.bytes();\n   * assertEquals(new TextDecoder().decode(slice), \"Hello, world!\");\n   * ```\n   *\n   * @param p The data to write to the buffer.\n   * @returns The number of bytes written.\n   */ writeSync(p) {\n    const m = this.#grow(p.byteLength);\n    return copy(p, this.#buf, m);\n  }\n  /**\n   * Writes the given data to the buffer. Resolves to the number of bytes\n   * written.\n   *\n   * > [!NOTE]\n   * > This methods writes bytes synchronously; it's provided for compatibility\n   * > with the {@linkcode Writer} interface.\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * const data = new TextEncoder().encode(\"Hello, world!\");\n   * await buf.write(data);\n   *\n   * const slice = buf.bytes();\n   * assertEquals(new TextDecoder().decode(slice), \"Hello, world!\");\n   * ```\n   *\n   * @param p The data to write to the buffer.\n   * @returns The number of bytes written.\n   */ write(p) {\n    const n = this.writeSync(p);\n    return Promise.resolve(n);\n  }\n  #grow(n) {\n    const m = this.length;\n    // If buffer is empty, reset to recover space.\n    if (m === 0 && this.#off !== 0) {\n      this.reset();\n    }\n    // Fast: Try to grow by means of a reslice.\n    const i = this.#tryGrowByReslice(n);\n    if (i >= 0) {\n      return i;\n    }\n    const c = this.capacity;\n    if (n <= Math.floor(c / 2) - m) {\n      // We can slide things down instead of allocating a new\n      // ArrayBuffer. We only need m+n <= c to slide, but\n      // we instead let capacity get twice as large so we\n      // don't spend all our time copying.\n      copy(this.#buf.subarray(this.#off), this.#buf);\n    } else if (c + n > MAX_SIZE) {\n      throw new Error(`The buffer cannot be grown beyond the maximum size of \"${MAX_SIZE}\"`);\n    } else {\n      // Not enough space anywhere, we need to allocate.\n      const buf = new Uint8Array(Math.min(2 * c + n, MAX_SIZE));\n      copy(this.#buf.subarray(this.#off), buf);\n      this.#buf = buf;\n    }\n    // Restore this.#off and len(this.#buf).\n    this.#off = 0;\n    this.#reslice(Math.min(m + n, MAX_SIZE));\n    return m;\n  }\n  /** Grows the buffer's capacity, if necessary, to guarantee space for\n   * another `n` bytes. After `.grow(n)`, at least `n` bytes can be written to\n   * the buffer without another allocation. If `n` is negative, `.grow()` will\n   * throw. If the buffer can't grow it will throw an error.\n   *\n   * Based on Go Lang's\n   * {@link https://golang.org/pkg/bytes/#Buffer.Grow | Buffer.Grow}.\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * buf.grow(10);\n   * assertEquals(buf.capacity, 10);\n   * ```\n   *\n   * @param n The number of bytes to grow the buffer by.\n   */ grow(n) {\n    if (n < 0) {\n      throw new Error(\"Buffer growth cannot be negative\");\n    }\n    const m = this.#grow(n);\n    this.#reslice(m);\n  }\n  /**\n   * Reads data from `r` until EOF (`null`) and appends it to the buffer,\n   * growing the buffer as needed. It resolves to the number of bytes read.\n   * If the buffer becomes too large, `.readFrom()` will reject with an error.\n   *\n   * Based on Go Lang's\n   * {@link https://golang.org/pkg/bytes/#Buffer.ReadFrom | Buffer.ReadFrom}.\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { StringReader } from \"@std/io/string-reader\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * const r = new StringReader(\"Hello, world!\");\n   * const n = await buf.readFrom(r);\n   *\n   * assertEquals(n, 13);\n   * ```\n   *\n   * @param r The reader to read from.\n   * @returns The number of bytes read.\n   */ async readFrom(r) {\n    let n = 0;\n    const tmp = new Uint8Array(MIN_READ);\n    while(true){\n      const shouldGrow = this.capacity - this.length < MIN_READ;\n      // read into tmp buffer if there's not enough room\n      // otherwise read directly into the internal buffer\n      const buf = shouldGrow ? tmp : new Uint8Array(this.#buf.buffer, this.length);\n      const nread = await r.read(buf);\n      if (nread === null) {\n        return n;\n      }\n      // write will grow if needed\n      if (shouldGrow) this.writeSync(buf.subarray(0, nread));\n      else this.#reslice(this.length + nread);\n      n += nread;\n    }\n  }\n  /** Reads data from `r` until EOF (`null`) and appends it to the buffer,\n   * growing the buffer as needed. It returns the number of bytes read. If the\n   * buffer becomes too large, `.readFromSync()` will throw an error.\n   *\n   * Based on Go Lang's\n   * {@link https://golang.org/pkg/bytes/#Buffer.ReadFrom | Buffer.ReadFrom}.\n   *\n   * @example Usage\n   * ```ts\n   * import { Buffer } from \"@std/io/buffer\";\n   * import { StringReader } from \"@std/io/string-reader\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const buf = new Buffer();\n   * const r = new StringReader(\"Hello, world!\");\n   * const n = buf.readFromSync(r);\n   *\n   * assertEquals(n, 13);\n   * ```\n   *\n   * @param r The reader to read from.\n   * @returns The number of bytes read.\n   */ readFromSync(r) {\n    let n = 0;\n    const tmp = new Uint8Array(MIN_READ);\n    while(true){\n      const shouldGrow = this.capacity - this.length < MIN_READ;\n      // read into tmp buffer if there's not enough room\n      // otherwise read directly into the internal buffer\n      const buf = shouldGrow ? tmp : new Uint8Array(this.#buf.buffer, this.length);\n      const nread = r.readSync(buf);\n      if (nread === null) {\n        return n;\n      }\n      // write will grow if needed\n      if (shouldGrow) this.writeSync(buf.subarray(0, nread));\n      else this.#reslice(this.length + nread);\n      n += nread;\n    }\n  }\n}",
      "BufferFullError": "class BufferFullError extends Error {\n  /**\n   * The partially read bytes\n   *\n   * @example Usage\n   * ```ts\n   * import { BufferFullError } from \"@std/io\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const err = new BufferFullError(new Uint8Array(2));\n   * assertEquals(err.partial, new Uint8Array(2));\n   * ```\n   */ partial;\n  /**\n   * Construct a new instance.\n   *\n   * @param partial The bytes partially read\n   */ constructor(partial){\n    super(\"Buffer full\");\n    this.name = this.constructor.name;\n    this.partial = partial;\n  }\n}",
      "LimitedReader": "class LimitedReader {\n  /**\n   * The reader to read from\n   *\n   * @example Usage\n   * ```ts\n   * import { StringReader } from \"@std/io/string-reader\";\n   * import { LimitedReader } from \"@std/io/limited-reader\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const r = new StringReader(\"hello world\");\n   * const lr = new LimitedReader(r, 5);\n   *\n   * assertEquals(lr.reader, r);\n   * ```\n   */ reader;\n  /**\n   * The number of bytes to limit the reader to\n   *\n   * @example Usage\n   * ```ts\n   * import { StringReader } from \"@std/io/string-reader\";\n   * import { LimitedReader } from \"@std/io/limited-reader\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const r = new StringReader(\"hello world\");\n   * const lr = new LimitedReader(r, 5);\n   *\n   * assertEquals(lr.limit, 5);\n   * ```\n   */ limit;\n  /**\n   * Construct a new instance.\n   *\n   * @param reader The reader to read from.\n   * @param limit The number of bytes to limit the reader to.\n   */ constructor(reader, limit){\n    this.reader = reader;\n    this.limit = limit;\n  }\n  /**\n   * Reads data from the reader.\n   *\n   * @example Usage\n   * ```ts\n   * import { StringReader } from \"@std/io/string-reader\";\n   * import { LimitedReader } from \"@std/io/limited-reader\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const r = new StringReader(\"hello world\");\n   * const lr = new LimitedReader(r, 5);\n   *\n   * const data = new Uint8Array(5);\n   * const res = await lr.read(data);\n   *\n   * assertEquals(res, 5);\n   * assertEquals(new TextDecoder().decode(data), \"hello\");\n   * ```\n   *\n   * @param p The buffer to read data into.\n   * @returns The number of bytes read.\n   */ async read(p) {\n    if (this.limit <= 0) {\n      return null;\n    }\n    if (p.length > this.limit) {\n      p = p.subarray(0, this.limit);\n    }\n    const n = await this.reader.read(p);\n    if (n === null) {\n      return null;\n    }\n    this.limit -= n;\n    return n;\n  }\n}",
      "MultiReader": "class MultiReader {\n  #readers;\n  #currentIndex = 0;\n  /**\n   * Construct a new instance.\n   *\n   * @param readers The readers to combine.\n   */ constructor(readers){\n    this.#readers = [\n      ...readers\n    ];\n  }\n  /**\n   * Reads data from the readers.\n   *\n   * @example Usage\n   * ```ts\n   * import { MultiReader } from \"@std/io/multi-reader\";\n   * import { StringReader } from \"@std/io/string-reader\";\n   * import { readAll } from \"@std/io/read-all\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const r1 = new StringReader(\"hello\");\n   * const r2 = new StringReader(\"world\");\n   * const mr = new MultiReader([r1, r2]);\n   *\n   * const data = new Uint8Array(5);\n   * const res = await mr.read(data);\n   *\n   * assertEquals(res, 5);\n   * assertEquals(new TextDecoder().decode(data), \"hello\");\n   *\n   * const res2 = await mr.read(data);\n   * assertEquals(res2, 0);\n   *\n   * const res3 = await mr.read(data);\n   * assertEquals(res3, 5);\n   * assertEquals(new TextDecoder().decode(data), \"world\");\n   * ```\n   *\n   * @param p The buffer to read data into.\n   * @returns The number of bytes read.\n   */ async read(p) {\n    const r = this.#readers[this.#currentIndex];\n    if (!r) return null;\n    const result = await r.read(p);\n    if (result === null) {\n      this.#currentIndex++;\n      return 0;\n    }\n    return result;\n  }\n}",
      "PartialReadError": "class PartialReadError extends Error {\n  /**\n   * The partially read bytes\n   *\n   * @example Usage\n   * ```ts\n   * import { PartialReadError } from \"@std/io\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const err = new PartialReadError(new Uint8Array(2));\n   * assertEquals(err.partial, new Uint8Array(2));\n   * ```\n   */ partial;\n  /**\n   * Construct a {@linkcode PartialReadError}.\n   *\n   * @param partial The bytes partially read\n   */ constructor(partial){\n    super(\"Encountered UnexpectedEof, data only partially read\");\n    this.name = this.constructor.name;\n    this.partial = partial;\n  }\n}",
      "SeekMode": {
        "0": "Start",
        "1": "Current",
        "2": "End",
        "Start": "0",
        "Current": "1",
        "End": "2"
      },
      "StringReader": "class StringReader extends Buffer {\n  /**\n   * Construct a new instance.\n   *\n   * @param s The string to read.\n   */ constructor(s){\n    super(new TextEncoder().encode(s).buffer);\n  }\n}",
      "StringWriter": "class StringWriter {\n  #chunks = [];\n  #byteLength = 0;\n  #cache;\n  #base;\n  /**\n   * Construct a new instance.\n   *\n   * @param base The base string to write to the buffer.\n   */ constructor(base = \"\"){\n    const c = new TextEncoder().encode(base);\n    this.#chunks.push(c);\n    this.#byteLength += c.byteLength;\n    this.#base = base;\n  }\n  /**\n   * Writes the bytes to the buffer asynchronously.\n   *\n   * @example Usage\n   * ```ts\n   * import { StringWriter } from \"@std/io/string-writer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const w = new StringWriter(\"base\");\n   * await w.write(new TextEncoder().encode(\"0123\"));\n   * assertEquals(w.toString(), \"base0123\");\n   * ```\n   *\n   * @param p The bytes to write to the buffer.\n   * @returns The number of bytes written to the buffer in total.\n   */ write(p) {\n    return Promise.resolve(this.writeSync(p));\n  }\n  /**\n   * Writes the bytes to the buffer synchronously.\n   *\n   * @example Usage\n   * ```ts\n   * import { StringWriter } from \"@std/io/string-writer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const w = new StringWriter(\"base\");\n   * w.writeSync(new TextEncoder().encode(\"0123\"));\n   * assertEquals(w.toString(), \"base0123\");\n   * ```\n   *\n   * @param p The bytes to write to the buffer.\n   * @returns The number of bytes written to the buffer in total.\n   */ writeSync(p) {\n    this.#chunks.push(new Uint8Array(p));\n    this.#byteLength += p.byteLength;\n    this.#cache = undefined;\n    return p.byteLength;\n  }\n  /**\n   * Returns the string written to the buffer.\n   *\n   * @example Usage\n   * ```ts\n   * import { StringWriter } from \"@std/io/string-writer\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const w = new StringWriter(\"base\");\n   * await w.write(new TextEncoder().encode(\"0123\"));\n   * assertEquals(w.toString(), \"base0123\");\n   * ```\n   *\n   * @returns the string written to the buffer.\n   */ toString() {\n    if (this.#cache) {\n      return this.#cache;\n    }\n    const buf = new Uint8Array(this.#byteLength);\n    let offs = 0;\n    for (const chunk of this.#chunks){\n      buf.set(chunk, offs);\n      offs += chunk.byteLength;\n    }\n    this.#cache = decoder.decode(buf);\n    return this.#cache;\n  }\n}",
      "copy": "async function copy(src, dst, options) {\n  let n = 0;\n  const b = new Uint8Array(options?.bufSize ?? DEFAULT_BUFFER_SIZE);\n  while(true){\n    const result = await src.read(b);\n    if (result === null) break;\n    await writeAll(dst, b.subarray(0, result));\n    n += result;\n  }\n  return n;\n}",
      "copyN": "async function copyN(r, dest, size) {\n  let bytesRead = 0;\n  let buf = new Uint8Array(DEFAULT_BUFFER_SIZE);\n  while(bytesRead < size){\n    if (size - bytesRead < DEFAULT_BUFFER_SIZE) {\n      buf = new Uint8Array(size - bytesRead);\n    }\n    const result = await r.read(buf);\n    const nread = result ?? 0;\n    bytesRead += nread;\n    if (nread > 0) {\n      let n = 0;\n      while(n < nread){\n        n += await dest.write(buf.slice(n, nread));\n      }\n      if (n !== nread) {\n        throw new Error(\"Could not write\");\n      }\n    }\n    if (result === null) {\n      break;\n    }\n  }\n  return bytesRead;\n}",
      "iterateReader": "async function* iterateReader(reader, options) {\n  const bufSize = options?.bufSize ?? DEFAULT_BUFFER_SIZE;\n  const b = new Uint8Array(bufSize);\n  while(true){\n    const result = await reader.read(b);\n    if (result === null) {\n      break;\n    }\n    yield b.slice(0, result);\n  }\n}",
      "iterateReaderSync": "function* iterateReaderSync(reader, options) {\n  const bufSize = options?.bufSize ?? DEFAULT_BUFFER_SIZE;\n  const b = new Uint8Array(bufSize);\n  while(true){\n    const result = reader.readSync(b);\n    if (result === null) {\n      break;\n    }\n    yield b.slice(0, result);\n  }\n}",
      "readAll": "async function readAll(reader) {\n  const chunks = [];\n  while(true){\n    let chunk = new Uint8Array(DEFAULT_CHUNK_SIZE);\n    const n = await reader.read(chunk);\n    if (n === null) {\n      break;\n    }\n    if (n < DEFAULT_CHUNK_SIZE) {\n      chunk = chunk.subarray(0, n);\n    }\n    chunks.push(chunk);\n  }\n  return concat(chunks);\n}",
      "readAllSync": "function readAllSync(reader) {\n  const chunks = [];\n  while(true){\n    const chunk = new Uint8Array(DEFAULT_CHUNK_SIZE);\n    const n = reader.readSync(chunk);\n    if (n === null) {\n      break;\n    }\n    if (n < DEFAULT_CHUNK_SIZE) {\n      chunks.push(chunk.subarray(0, n));\n      break;\n    }\n    chunks.push(chunk);\n  }\n  return concat(chunks);\n}",
      "readDelim": "async function* readDelim(reader, delim) {\n  // Avoid unicode problems\n  const delimLen = delim.length;\n  const delimLPS = createLPS(delim);\n  let chunks = new Uint8Array();\n  const bufSize = Math.max(1024, delimLen + 1);\n  // Modified KMP\n  let inspectIndex = 0;\n  let matchIndex = 0;\n  while(true){\n    const inspectArr = new Uint8Array(bufSize);\n    const result = await reader.read(inspectArr);\n    if (result === null) {\n      // Yield last chunk.\n      yield chunks;\n      return;\n    } else if (result < 0) {\n      // Discard all remaining and silently fail.\n      return;\n    }\n    chunks = concat([\n      chunks,\n      inspectArr.slice(0, result)\n    ]);\n    let localIndex = 0;\n    while(inspectIndex < chunks.length){\n      if (inspectArr[localIndex] === delim[matchIndex]) {\n        inspectIndex++;\n        localIndex++;\n        matchIndex++;\n        if (matchIndex === delimLen) {\n          // Full match\n          const matchEnd = inspectIndex - delimLen;\n          const readyBytes = chunks.slice(0, matchEnd);\n          yield readyBytes;\n          // Reset match, different from KMP.\n          chunks = chunks.slice(inspectIndex);\n          inspectIndex = 0;\n          matchIndex = 0;\n        }\n      } else {\n        if (matchIndex === 0) {\n          inspectIndex++;\n          localIndex++;\n        } else {\n          matchIndex = delimLPS[matchIndex - 1];\n        }\n      }\n    }\n  }\n}",
      "readInt": "async function readInt(buf) {\n  const high = await readShort(buf);\n  if (high === null) return null;\n  const low = await readShort(buf);\n  if (low === null) throw new Deno.errors.UnexpectedEof();\n  return high << 16 | low;\n}",
      "readLines": "async function* readLines(reader, decoderOpts) {\n  const bufReader = new BufReader(reader);\n  let chunks = [];\n  const decoder = new TextDecoder(decoderOpts?.encoding, decoderOpts);\n  while(true){\n    const res = await bufReader.readLine();\n    if (!res) {\n      if (chunks.length > 0) {\n        yield decoder.decode(concat(chunks));\n      }\n      break;\n    }\n    chunks.push(res.line);\n    if (!res.more) {\n      yield decoder.decode(concat(chunks));\n      chunks = [];\n    }\n  }\n}",
      "readLong": "async function readLong(buf) {\n  const high = await readInt(buf);\n  if (high === null) return null;\n  const low = await readInt(buf);\n  if (low === null) throw new Deno.errors.UnexpectedEof();\n  const big = BigInt(high) << 32n | BigInt(low);\n  // We probably should provide a similar API that returns BigInt values.\n  if (big > MAX_SAFE_INTEGER) {\n    throw new RangeError(\"Long value too big to be represented as a JavaScript number.\");\n  }\n  return Number(big);\n}",
      "readRange": "async function readRange(r, range) {\n  // byte ranges are inclusive, so we have to add one to the end\n  let length = range.end - range.start + 1;\n  if (length <= 0) {\n    throw new RangeError(\"Byte range start cannot be larger than end\");\n  }\n  await r.seek(range.start, Deno.SeekMode.Start);\n  const result = new Uint8Array(length);\n  let off = 0;\n  while(length){\n    const p = new Uint8Array(Math.min(length, DEFAULT_BUFFER_SIZE));\n    const nread = await r.read(p);\n    if (nread === null) {\n      throw new Error(\"Unexpected EOF reach while reading a range\");\n    }\n    if (nread === 0) {\n      throw new Error(\"Unexpected read of 0 bytes while reading a range\");\n    }\n    copyBytes(p, result, off);\n    off += nread;\n    length -= nread;\n    if (length < 0) {\n      throw new Error(\"Unexpected length remaining after reading range\");\n    }\n  }\n  return result;\n}",
      "readRangeSync": "function readRangeSync(r, range) {\n  // byte ranges are inclusive, so we have to add one to the end\n  let length = range.end - range.start + 1;\n  if (length <= 0) {\n    throw new RangeError(\"Byte range start cannot be larger than end\");\n  }\n  r.seekSync(range.start, Deno.SeekMode.Start);\n  const result = new Uint8Array(length);\n  let off = 0;\n  while(length){\n    const p = new Uint8Array(Math.min(length, DEFAULT_BUFFER_SIZE));\n    const nread = r.readSync(p);\n    if (nread === null) {\n      throw new Error(\"Unexpected EOF reach while reading a range\");\n    }\n    if (nread === 0) {\n      throw new Error(\"Unexpected read of 0 bytes while reading a range\");\n    }\n    copyBytes(p, result, off);\n    off += nread;\n    length -= nread;\n    if (length < 0) {\n      throw new Error(\"Unexpected length remaining after reading range\");\n    }\n  }\n  return result;\n}",
      "readShort": "async function readShort(buf) {\n  const high = await buf.readByte();\n  if (high === null) return null;\n  const low = await buf.readByte();\n  if (low === null) throw new Deno.errors.UnexpectedEof();\n  return high << 8 | low;\n}",
      "readStringDelim": "async function* readStringDelim(reader, delim, decoderOpts) {\n  const encoder = new TextEncoder();\n  const decoder = new TextDecoder(decoderOpts?.encoding, decoderOpts);\n  for await (const chunk of readDelim(reader, encoder.encode(delim))){\n    yield decoder.decode(chunk);\n  }\n}",
      "readerFromStreamReader": "function readerFromStreamReader(streamReader) {\n  const buffer = new Buffer();\n  return {\n    async read (p) {\n      if (buffer.empty()) {\n        const res = await streamReader.read();\n        if (res.done) {\n          return null; // EOF\n        }\n        await writeAll(buffer, res.value);\n      }\n      return buffer.read(p);\n    }\n  };\n}",
      "sliceLongToBytes": "function sliceLongToBytes(d, dest = Array.from({\n  length: 8\n})) {\n  let big = BigInt(d);\n  for(let i = 0; i < 8; i++){\n    dest[7 - i] = Number(big & 0xffn);\n    big >>= 8n;\n  }\n  return dest;\n}",
      "toReadableStream": "function toReadableStream(reader, options) {\n  const { autoClose = true, chunkSize = DEFAULT_CHUNK_SIZE, strategy } = options ?? {};\n  return new ReadableStream({\n    async pull (controller) {\n      const chunk = new Uint8Array(chunkSize);\n      try {\n        const read = await reader.read(chunk);\n        if (read === null) {\n          if (isCloser(reader) && autoClose) {\n            reader.close();\n          }\n          controller.close();\n          return;\n        }\n        controller.enqueue(chunk.subarray(0, read));\n      } catch (e) {\n        controller.error(e);\n        if (isCloser(reader)) {\n          reader.close();\n        }\n      }\n    },\n    cancel () {\n      if (isCloser(reader) && autoClose) {\n        reader.close();\n      }\n    }\n  }, strategy);\n}",
      "toWritableStream": "function toWritableStream(writer, options) {\n  const { autoClose = true } = options ?? {};\n  return new WritableStream({\n    async write (chunk, controller) {\n      try {\n        await writeAll(writer, chunk);\n      } catch (e) {\n        controller.error(e);\n        if (isCloser(writer) && autoClose) {\n          writer.close();\n        }\n      }\n    },\n    close () {\n      if (isCloser(writer) && autoClose) {\n        writer.close();\n      }\n    },\n    abort () {\n      if (isCloser(writer) && autoClose) {\n        writer.close();\n      }\n    }\n  });\n}",
      "writeAll": "async function writeAll(writer, data) {\n  let nwritten = 0;\n  while(nwritten < data.length){\n    nwritten += await writer.write(data.subarray(nwritten));\n  }\n}",
      "writeAllSync": "function writeAllSync(writer, data) {\n  let nwritten = 0;\n  while(nwritten < data.length){\n    nwritten += writer.writeSync(data.subarray(nwritten));\n  }\n}"
    }
  },
  {
    "jsr:@std/ini": {
      "IniMap": "class IniMap {\n  #global = new Map();\n  #sections = new Map();\n  #lines = [];\n  #comments = {\n    clear: ()=>{\n      this.#lines = this.#lines.filter((line)=>line.type !== \"comment\");\n      for (const [i, line] of this.#lines.entries()){\n        if (line.type === \"section\") {\n          line.end = line.end - line.num + i + 1;\n        }\n        line.num = i + 1;\n      }\n    },\n    deleteAtLine: (line)=>{\n      const comment = this.#getComment(line);\n      if (comment) {\n        this.#appendOrDeleteLine(comment, LineOp.Del);\n        return true;\n      }\n      return false;\n    },\n    deleteAtKey: (keyOrSection, noneOrKey)=>{\n      const lineValue = this.#getValue(keyOrSection, noneOrKey);\n      if (lineValue) {\n        return this.comments.deleteAtLine(lineValue.num - 1);\n      }\n      return false;\n    },\n    deleteAtSection: (sectionName)=>{\n      const section = this.#sections.get(sectionName);\n      if (section) {\n        return this.comments.deleteAtLine(section.num - 1);\n      }\n      return false;\n    },\n    getAtLine: (line)=>{\n      return this.#getComment(line)?.val;\n    },\n    getAtKey: (keyOrSection, noneOrKey)=>{\n      const lineValue = this.#getValue(keyOrSection, noneOrKey);\n      if (lineValue) {\n        return this.comments.getAtLine(lineValue.num - 1);\n      }\n    },\n    getAtSection: (sectionName)=>{\n      const section = this.#sections.get(sectionName);\n      if (section) {\n        return this.comments.getAtLine(section.num - 1);\n      }\n    },\n    setAtLine: (line, text)=>{\n      const comment = this.#getComment(line);\n      const mark = this.#formatting.commentChar ?? \"#\";\n      const formatted = text.startsWith(mark) || text === \"\" ? text : `${mark} ${text}`;\n      if (comment) {\n        comment.val = formatted;\n      } else {\n        if (line > this.#lines.length) {\n          for(let i = this.#lines.length + 1; i < line; i += 1){\n            this.#appendOrDeleteLine({\n              type: \"comment\",\n              num: i,\n              val: \"\"\n            }, LineOp.Add);\n          }\n        }\n        this.#appendOrDeleteLine({\n          type: \"comment\",\n          num: line,\n          val: formatted\n        }, LineOp.Add);\n      }\n      return this.comments;\n    },\n    setAtKey: (keyOrSection, textOrKey, noneOrText)=>{\n      if (noneOrText !== undefined) {\n        const lineValue = this.#getValue(keyOrSection, textOrKey);\n        if (lineValue) {\n          if (this.#getComment(lineValue.num - 1)) {\n            this.comments.setAtLine(lineValue.num - 1, noneOrText);\n          } else {\n            this.comments.setAtLine(lineValue.num, noneOrText);\n          }\n        }\n      } else {\n        const lineValue = this.#getValue(keyOrSection);\n        if (lineValue) {\n          if (this.#getComment(lineValue.num - 1)) {\n            this.comments.setAtLine(lineValue.num - 1, textOrKey);\n          } else {\n            this.comments.setAtLine(lineValue.num, textOrKey);\n          }\n        }\n      }\n      return this.comments;\n    },\n    setAtSection: (sectionName, text)=>{\n      const section = this.#sections.get(sectionName);\n      if (section) {\n        if (this.#getComment(section.num - 1)) {\n          this.comments.setAtLine(section.num - 1, text);\n        } else {\n          this.comments.setAtLine(section.num, text);\n        }\n      }\n      return this.comments;\n    }\n  };\n  #formatting;\n  /** Constructs a new `IniMap`.\n   *\n   * @example Usage\n   * ```ts\n   * import { IniMap } from \"@std/ini\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const ini = new IniMap();\n   * ini.set(\"section1\", \"keyA\", 100)\n   * assertEquals(ini.toString(), `[section1]\n   * keyA=100`)\n   *\n   * ini.set('keyA', 25)\n   * assertEquals(ini.toObject(), {\n   *   keyA: 25,\n   *   section1: {\n   *     keyA: 100,\n   *   },\n   * });\n   * ```\n   *\n   * @param formatting Optional formatting options when printing an INI file.\n   */ constructor(formatting){\n    this.#formatting = this.#cleanFormatting(formatting);\n  }\n  /**\n   * Gets the count of key/value pairs.\n   *\n   * @example Usage\n   * ```ts\n   * import { IniMap } from \"@std/ini/ini-map\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const iniMap = IniMap.from(`\n   * key0 = value0\n   * key1 = value1\n   *\n   * [section 1]\n   * foo = Spam\n   * bar = Ham\n   * baz = Egg\n   *\n   * [section 2]\n   * name = John`);\n   *\n   * assertEquals(iniMap.size, 6); // It has 6 keys in total\n   * ```\n   *\n   * @returns The number of key/value pairs.\n   */ get size() {\n    let size = this.#global.size;\n    for (const { map } of this.#sections.values()){\n      size += map.size;\n    }\n    return size;\n  }\n  /**\n   * Gets the formatting options.\n   *\n   * @example Usage\n   * ```ts\n   * import { IniMap } from \"@std/ini/ini-map\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const iniMap = IniMap.from(`\n   * key0 = value0\n   * key1 = value1`);\n   *\n   * assertEquals(iniMap.formatting.pretty, true);\n   * ```\n   *\n   * @returns The formatting options\n   */ get formatting() {\n    return this.#formatting;\n  }\n  /** Returns the comments in the INI.\n   *\n   * @example Usage\n   * ```ts\n   * import { IniMap } from \"@std/ini/ini-map\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const iniMap = IniMap.from(`\n   * // Hey\n   * key0 = value0\n   * key1 = value1\n   * // Hello\n   * [section 1]\n   * foo = Spam\n   * bar = Ham\n   * baz = Egg`);\n   *\n   * assertEquals(iniMap.comments.getAtLine(2), \"// Hey\")\n   * assertEquals(iniMap.comments.getAtLine(5), \"// Hello\")\n   * assertEquals(iniMap.comments.getAtSection(\"section 1\"), \"// Hello\")\n   * ```\n   *\n   * @returns The comments\n   */ get comments() {\n    return this.#comments;\n  }\n  /**\n   * Clears a single section or the entire INI.\n   *\n   * @example Usage\n   * ```ts\n   * import { IniMap } from \"@std/ini/ini-map\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const iniMap = IniMap.from(`\n   * key0 = value0\n   * key1 = value1\n   *\n   * [section 1]\n   * foo = Spam\n   * bar = Ham\n   * baz = Egg\n   *\n   * [section 2]\n   * name = John`);\n   *\n   * iniMap.clear(\"section 1\");\n   *\n   * assertEquals(iniMap.toObject(), {\n   *   key0: \"value0\",\n   *   key1: \"value1\",\n   *   \"section 2\": {\n   *     name: \"John\",\n   *   },\n   * });\n   *\n   * iniMap.clear(); // Clears all\n   *\n   * assertEquals(iniMap.toObject(), {});\n   * ```\n   *\n   * @param sectionName The section name to clear\n   */ clear(sectionName) {\n    if (sectionName) {\n      const section = this.#sections.get(sectionName);\n      if (section) {\n        section.map.clear();\n        this.#sections.delete(sectionName);\n        this.#lines.splice(section.num - 1, section.end - section.num);\n      }\n    } else {\n      this.#global.clear();\n      this.#sections.clear();\n      this.#lines.length = 0;\n    }\n  }\n  delete(keyOrSection, noneOrKey) {\n    const exists = this.#getValue(keyOrSection, noneOrKey);\n    if (exists) {\n      this.#appendOrDeleteLine(exists, LineOp.Del);\n      if (exists.sec) {\n        return this.#sections.get(exists.sec).map.delete(exists.key);\n      } else {\n        return this.#global.delete(exists.key);\n      }\n    }\n    return false;\n  }\n  get(keyOrSection, noneOrKey) {\n    return this.#getValue(keyOrSection, noneOrKey)?.val;\n  }\n  has(keyOrSection, noneOrKey) {\n    return this.#getValue(keyOrSection, noneOrKey) !== undefined;\n  }\n  // deno-lint-ignore no-explicit-any\n  set(keyOrSection, valueOrKey, value) {\n    if (typeof valueOrKey === \"string\" && value !== undefined) {\n      const section = this.#getOrCreateSection(keyOrSection);\n      const exists = section.map.get(valueOrKey);\n      if (exists) {\n        exists.val = value;\n      } else {\n        section.end += 1;\n        const lineValue = {\n          type: \"value\",\n          num: section.end,\n          sec: section.sec,\n          key: valueOrKey,\n          val: value\n        };\n        this.#appendValue(lineValue);\n        section.map.set(valueOrKey, lineValue);\n      }\n    } else {\n      const lineValue = {\n        type: \"value\",\n        num: 0,\n        key: keyOrSection,\n        val: valueOrKey\n      };\n      this.#appendValue(lineValue);\n      this.#global.set(keyOrSection, lineValue);\n    }\n    return this;\n  }\n  /**\n   * Iterate over each entry in the INI to retrieve key, value, and section.\n   *\n   * @example Usage\n   * ```ts\n   * import { IniMap } from \"@std/ini/ini-map\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const iniMap = IniMap.from(`\n   * key0 = value0\n   * key1 = value1\n   *\n   * [section 1]\n   * foo = Spam\n   * bar = Ham\n   * baz = Egg`);\n   *\n   * assertEquals([...iniMap.entries()], [\n   *   [\"key0\", \"value0\"],\n   *   [\"key1\", \"value1\"],\n   *   [\"foo\", \"Spam\", \"section 1\"],\n   *   [\"bar\", \"Ham\", \"section 1\"],\n   *   [\"baz\", \"Egg\", \"section 1\"]\n   * ]);\n   * ```\n   *\n   * @returns The iterator of entries\n   */ *entries() {\n    for (const { key, val } of this.#global.values()){\n      yield [\n        key,\n        val\n      ];\n    }\n    for (const { map } of this.#sections.values()){\n      for (const { key, val, sec } of map.values()){\n        yield [\n          key,\n          val,\n          sec\n        ];\n      }\n    }\n  }\n  #getOrCreateSection(section) {\n    const existing = this.#sections.get(section);\n    if (existing) {\n      return existing;\n    }\n    const lineSection = {\n      type: \"section\",\n      num: this.#lines.length + 1,\n      sec: section,\n      map: new Map(),\n      end: this.#lines.length + 1\n    };\n    this.#lines.push(lineSection);\n    this.#sections.set(section, lineSection);\n    return lineSection;\n  }\n  #getValue(keyOrSection, noneOrKey) {\n    if (noneOrKey) {\n      const section = this.#sections.get(keyOrSection);\n      return section?.map.get(noneOrKey);\n    }\n    return this.#global.get(keyOrSection);\n  }\n  #getComment(line) {\n    const comment = this.#lines[line - 1];\n    if (comment?.type === \"comment\") {\n      return comment;\n    }\n  }\n  #appendValue(lineValue) {\n    if (this.#lines.length === 0) {\n      // For an empty array, just insert the line value\n      lineValue.num = 1;\n      this.#lines.push(lineValue);\n    } else if (lineValue.sec) {\n      // For line values in a section, the end of the section is known\n      this.#appendOrDeleteLine(lineValue, LineOp.Add);\n    } else {\n      // For global values, find the line preceding the first section\n      lineValue.num = this.#lines.length + 1;\n      for (const [i, line] of this.#lines.entries()){\n        if (line.type === \"section\") {\n          lineValue.num = i + 1;\n          break;\n        }\n      }\n      // Append the line value at the end of all global values\n      this.#appendOrDeleteLine(lineValue, LineOp.Add);\n    }\n  }\n  #appendOrDeleteLine(input, op) {\n    if (op === LineOp.Add) {\n      this.#lines.splice(input.num - 1, 0, input);\n    } else {\n      this.#lines.splice(input.num - 1, 1);\n    }\n    // If the input is a comment, find the next section if any to update.\n    let updateSection = input.type === \"comment\";\n    const start = op === LineOp.Add ? input.num : input.num - 1;\n    for (const line of this.#lines.slice(start)){\n      line.num += op;\n      if (line.type === \"section\") {\n        line.end += op;\n        // If the comment is before the nearest section, don't update the section further.\n        updateSection = false;\n      }\n      if (updateSection) {\n        // if the comment precedes a value in a section, get and update the section end.\n        if (line.type === \"value\" && line.sec) {\n          const section = this.#sections.get(line.sec);\n          if (section) {\n            section.end += op;\n            updateSection = false;\n          }\n        }\n      }\n    }\n  }\n  *#readTextLines(text) {\n    const { length } = text;\n    let line = \"\";\n    for(let i = 0; i < length; i += 1){\n      const char = text[i];\n      if (char === \"\\n\" || char === \"\\r\") {\n        yield line;\n        line = \"\";\n        if (char === \"\\r\" && text[i + 1] === \"\\n\") {\n          i++;\n          if (!this.#formatting.lineBreak) {\n            this.#formatting.lineBreak = \"\\r\\n\";\n          }\n        } else if (!this.#formatting.lineBreak) {\n          this.#formatting.lineBreak = char;\n        }\n      } else {\n        line += char;\n      }\n    }\n    yield line;\n  }\n  #cleanFormatting(options) {\n    return Object.fromEntries(Object.entries(options ?? {}).filter(([key])=>FormattingKeys.includes(key)));\n  }\n  /**\n   * Convert this `IniMap` to a plain object.\n   *\n   * @example Usage\n   * ```ts\n   * import { IniMap } from \"@std/ini/ini-map\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const iniMap = IniMap.from(`\n   * key0 = value0\n   * key1 = value1\n   *\n   * [section 1]\n   * foo = Spam\n   * bar = Ham\n   * baz = Egg`);\n   *\n   * assertEquals(iniMap.toObject(), {\n   *   key0: \"value0\",\n   *   key1: \"value1\",\n   *   \"section 1\": {\n   *     foo: \"Spam\",\n   *     bar: \"Ham\",\n   *     baz: \"Egg\",\n   *   },\n   * });\n   * ```\n   *\n   * @returns The object equivalent to this {@code IniMap}\n   */ toObject() {\n    const obj = {};\n    for (const { key, val } of this.#global.values()){\n      Object.defineProperty(obj, key, {\n        value: val,\n        writable: true,\n        enumerable: true,\n        configurable: true\n      });\n    }\n    for (const { sec, map } of this.#sections.values()){\n      const section = {};\n      Object.defineProperty(obj, sec, {\n        value: section,\n        writable: true,\n        enumerable: true,\n        configurable: true\n      });\n      for (const { key, val } of map.values()){\n        Object.defineProperty(section, key, {\n          value: val,\n          writable: true,\n          enumerable: true,\n          configurable: true\n        });\n      }\n    }\n    return obj;\n  }\n  /**\n   * Convenience method for `JSON.stringify`.\n   *\n   * @example Usage\n   * ```ts\n   * import { IniMap } from \"@std/ini/ini-map\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const iniMap = IniMap.from(`\n   * key0 = value0\n   * key1 = value1\n   *\n   * [section 1]\n   * foo = Spam\n   * bar = Ham\n   * baz = Egg`);\n   *\n   * assertEquals(iniMap.toJSON(), {\n   *   key0: \"value0\",\n   *   key1: \"value1\",\n   *   \"section 1\": {\n   *     foo: \"Spam\",\n   *     bar: \"Ham\",\n   *     baz: \"Egg\",\n   *   },\n   * });\n   * ```\n   *\n   * @returns The object equivalent to this {@code IniMap}\n   */ toJSON() {\n    return this.toObject();\n  }\n  /**\n   * Convert this `IniMap` to an INI string.\n   *\n   * @example Usage\n   * ```ts\n   * import { IniMap } from \"@std/ini/ini-map\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const iniMap = IniMap.from(`\n   * // Hey\n   * key0 = value0\n   * key1 = value1\n   * // Hello\n   * [section 1]\n   * foo = Spam\n   * bar = Ham\n   * baz = Egg`);\n   *\n   * iniMap.set(\"section 1\", \"foo\", \"Bacon\");\n   *\n   * assertEquals(iniMap.toString(), `\n   * // Hey\n   * key0 = value0\n   * key1 = value1\n   * // Hello\n   * [section 1]\n   * foo = Bacon\n   * bar = Ham\n   * baz = Egg`)\n   * ```\n   * @param replacer The replacer\n   * @returns Ini string\n   */ toString(replacer) {\n    const replacerFunc = typeof replacer === \"function\" ? replacer : (_key, value, _section)=>`${value}`;\n    const pretty = this.#formatting?.pretty ?? false;\n    const assignmentMark = (this.#formatting?.assignment ?? \"=\")[0];\n    const assignment = pretty ? ` ${assignmentMark} ` : assignmentMark;\n    const lines = this.#formatting.deduplicate ? this.#lines.filter((lineA, index, self)=>{\n      if (lineA.type === \"value\") {\n        const lastIndex = self.findLastIndex((lineB)=>{\n          return lineA.sec === lineB.sec && lineA.key === lineB.key;\n        });\n        return index === lastIndex;\n      }\n      return true;\n    }) : this.#lines;\n    return lines.map((line)=>{\n      switch(line.type){\n        case \"comment\":\n          return line.val;\n        case \"section\":\n          return `[${line.sec}]`;\n        case \"value\":\n          return line.key + assignment + replacerFunc(line.key, line.val, line.sec);\n      }\n    }).join(this.#formatting?.lineBreak ?? \"\\n\");\n  }\n  /**\n   * Parse an INI string in this `IniMap`.\n   *\n   * @example Usage\n   * ```ts\n   * import { IniMap } from \"@std/ini/ini-map\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const iniMap = new IniMap();\n   *\n   * iniMap.parse(`\n   * key0 = value0\n   * key1 = value1\n   *\n   * [section 1]\n   * foo = Spam\n   * bar = Ham\n   * baz = Egg`);\n   *\n   * assertEquals(iniMap.toObject(), {\n   *   key0: \"value0\",\n   *   key1: \"value1\",\n   *   \"section 1\": {\n   *     foo: \"Spam\",\n   *     bar: \"Ham\",\n   *     baz: \"Egg\",\n   *   },\n   * });\n   * ```\n   *\n   * @param text The text to parse\n   * @param reviver The reviver function\n   * @returns This {@code IniMap} object\n   */ parse(text, reviver) {\n    if (typeof text !== \"string\") {\n      throw new SyntaxError(`Unexpected token ${text} in INI at line 0`);\n    }\n    const reviverFunc = typeof reviver === \"function\" ? reviver : (_key, value, _section)=>value;\n    const assignment = (this.#formatting.assignment ?? \"=\").substring(0, 1);\n    let lineNumber = 1;\n    let currentSection;\n    for (const line of this.#readTextLines(text)){\n      const trimmed = line.trim();\n      if (isComment(trimmed)) {\n        // If comment formatting mark is not set, discover it.\n        if (!this.#formatting.commentChar) {\n          const mark = trimmed[0];\n          if (mark) {\n            // if mark is truthy, use the character.\n            this.#formatting.commentChar = mark === \"/\" ? \"//\" : mark;\n          }\n        }\n        this.#lines.push({\n          type: \"comment\",\n          num: lineNumber,\n          val: trimmed\n        });\n      } else if (isSection(trimmed, lineNumber)) {\n        const sec = trimmed.substring(1, trimmed.length - 1);\n        if (sec.trim() === \"\") {\n          throw new SyntaxError(`Unexpected empty section name at line ${lineNumber}`);\n        }\n        currentSection = {\n          type: \"section\",\n          num: lineNumber,\n          sec,\n          map: new Map(),\n          end: lineNumber\n        };\n        this.#lines.push(currentSection);\n        this.#sections.set(currentSection.sec, currentSection);\n      } else {\n        const assignmentPos = trimmed.indexOf(assignment);\n        if (assignmentPos === -1) {\n          throw new SyntaxError(`Unexpected token ${trimmed[0]} in INI at line ${lineNumber}`);\n        }\n        if (assignmentPos === 0) {\n          throw new SyntaxError(`Unexpected empty key name at line ${lineNumber}`);\n        }\n        const leftHand = trimmed.substring(0, assignmentPos);\n        const rightHand = trimmed.substring(assignmentPos + 1);\n        if (this.#formatting.pretty === undefined) {\n          this.#formatting.pretty = leftHand.endsWith(\" \") && rightHand.startsWith(\" \");\n        }\n        const key = leftHand.trim();\n        const value = rightHand.trim();\n        if (currentSection) {\n          const lineValue = {\n            type: \"value\",\n            num: lineNumber,\n            sec: currentSection.sec,\n            key,\n            val: reviverFunc(key, value, currentSection.sec)\n          };\n          currentSection.map.set(key, lineValue);\n          this.#lines.push(lineValue);\n          currentSection.end = lineNumber;\n        } else {\n          const lineValue = {\n            type: \"value\",\n            num: lineNumber,\n            key,\n            val: reviverFunc(key, value)\n          };\n          this.#global.set(key, lineValue);\n          this.#lines.push(lineValue);\n        }\n      }\n      lineNumber += 1;\n    }\n    return this;\n  }\n  static from(// deno-lint-ignore no-explicit-any\n  input, formatting) {\n    const ini = new IniMap(formatting);\n    if (typeof input === \"object\" && input !== null) {\n      // deno-lint-ignore no-explicit-any\n      const isRecord = (val)=>typeof val === \"object\" && val !== null;\n      // deno-lint-ignore no-explicit-any\n      const sort = ([_a, valA], [_b, valB])=>{\n        if (isRecord(valA)) return 1;\n        if (isRecord(valB)) return -1;\n        return 0;\n      };\n      for (const [key, val] of Object.entries(input).sort(sort)){\n        if (isRecord(val)) {\n          for (const [sectionKey, sectionValue] of Object.entries(val)){\n            ini.set(key, sectionKey, sectionValue);\n          }\n        } else {\n          ini.set(key, val);\n        }\n      }\n    } else {\n      ini.parse(input, formatting?.reviver);\n    }\n    return ini;\n  }\n}",
      "parse": "function parse(text, options) {\n  return IniMap.from(text, options).toObject();\n}",
      "stringify": "function stringify(// deno-lint-ignore no-explicit-any\nobject, options) {\n  return IniMap.from(object, options).toString(options?.replacer);\n}"
    }
  },
  {
    "jsr:@std/http": {
      "STATUS_CODE": {
        "Continue": "100",
        "SwitchingProtocols": "101",
        "Processing": "102",
        "EarlyHints": "103",
        "OK": "200",
        "Created": "201",
        "Accepted": "202",
        "NonAuthoritativeInfo": "203",
        "NoContent": "204",
        "ResetContent": "205",
        "PartialContent": "206",
        "MultiStatus": "207",
        "AlreadyReported": "208",
        "IMUsed": "226",
        "MultipleChoices": "300",
        "MovedPermanently": "301",
        "Found": "302",
        "SeeOther": "303",
        "NotModified": "304",
        "UseProxy": "305",
        "TemporaryRedirect": "307",
        "PermanentRedirect": "308",
        "BadRequest": "400",
        "Unauthorized": "401",
        "PaymentRequired": "402",
        "Forbidden": "403",
        "NotFound": "404",
        "MethodNotAllowed": "405",
        "NotAcceptable": "406",
        "ProxyAuthRequired": "407",
        "RequestTimeout": "408",
        "Conflict": "409",
        "Gone": "410",
        "LengthRequired": "411",
        "PreconditionFailed": "412",
        "ContentTooLarge": "413",
        "URITooLong": "414",
        "UnsupportedMediaType": "415",
        "RangeNotSatisfiable": "416",
        "ExpectationFailed": "417",
        "Teapot": "418",
        "MisdirectedRequest": "421",
        "UnprocessableEntity": "422",
        "Locked": "423",
        "FailedDependency": "424",
        "TooEarly": "425",
        "UpgradeRequired": "426",
        "PreconditionRequired": "428",
        "TooManyRequests": "429",
        "RequestHeaderFieldsTooLarge": "431",
        "UnavailableForLegalReasons": "451",
        "InternalServerError": "500",
        "NotImplemented": "501",
        "BadGateway": "502",
        "ServiceUnavailable": "503",
        "GatewayTimeout": "504",
        "HTTPVersionNotSupported": "505",
        "VariantAlsoNegotiates": "506",
        "InsufficientStorage": "507",
        "LoopDetected": "508",
        "NotExtended": "510",
        "NetworkAuthenticationRequired": "511"
      },
      "STATUS_TEXT": {
        "100": "Continue",
        "101": "Switching Protocols",
        "102": "Processing",
        "103": "Early Hints",
        "200": "OK",
        "201": "Created",
        "202": "Accepted",
        "203": "Non Authoritative Info",
        "204": "No Content",
        "205": "Reset Content",
        "206": "Partial Content",
        "207": "Multi Status",
        "208": "Already Reported",
        "226": "IM Used",
        "300": "Multiple Choices",
        "301": "Moved Permanently",
        "302": "Found",
        "303": "See Other",
        "304": "Not Modified",
        "305": "Use Proxy",
        "307": "Temporary Redirect",
        "308": "Permanent Redirect",
        "400": "Bad Request",
        "401": "Unauthorized",
        "402": "Payment Required",
        "403": "Forbidden",
        "404": "Not Found",
        "405": "Method Not Allowed",
        "406": "Not Acceptable",
        "407": "Proxy Auth Required",
        "408": "Request Timeout",
        "409": "Conflict",
        "410": "Gone",
        "411": "Length Required",
        "412": "Precondition Failed",
        "413": "Content Too Large",
        "414": "URI Too Long",
        "415": "Unsupported Media Type",
        "416": "Range Not Satisfiable",
        "417": "Expectation Failed",
        "418": "I'm a teapot",
        "421": "Misdirected Request",
        "422": "Unprocessable Entity",
        "423": "Locked",
        "424": "Failed Dependency",
        "425": "Too Early",
        "426": "Upgrade Required",
        "428": "Precondition Required",
        "429": "Too Many Requests",
        "431": "Request Header Fields Too Large",
        "451": "Unavailable For Legal Reasons",
        "500": "Internal Server Error",
        "501": "Not Implemented",
        "502": "Bad Gateway",
        "503": "Service Unavailable",
        "504": "Gateway Timeout",
        "505": "HTTP Version Not Supported",
        "506": "Variant Also Negotiates",
        "507": "Insufficient Storage",
        "508": "Loop Detected",
        "510": "Not Extended",
        "511": "Network Authentication Required"
      },
      "ServerSentEventStream": "class ServerSentEventStream extends TransformStream {\n  constructor(){\n    super({\n      transform: (message, controller)=>{\n        controller.enqueue(stringify(message));\n      }\n    });\n  }\n}",
      "UserAgent": "class UserAgent {\n  #browser;\n  #cpu;\n  #device;\n  #engine;\n  #os;\n  #ua;\n  /**\n   * Constructs a new instance.\n   *\n   * @param ua The user agent string to construct this instance with.\n   */ constructor(ua){\n    this.#ua = ua ?? \"\";\n  }\n  /**\n   * The name and version of the browser extracted from the user agent\n   * string.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { UserAgent } from \"@std/http/user-agent\";\n   *\n   * Deno.serve((req) => {\n   *   const userAgent = new UserAgent(req.headers.get(\"user-agent\") ?? \"\");\n   *   return new Response(`Hello, ${userAgent.browser.name}!`);\n   * });\n   * ```\n   *\n   * @returns An object with information about the user agent's browser.\n   */ get browser() {\n    if (!this.#browser) {\n      this.#browser = {\n        name: undefined,\n        version: undefined,\n        major: undefined\n      };\n      mapper(this.#browser, this.#ua, matchers.browser);\n      // deno-lint-ignore no-explicit-any\n      this.#browser.major = majorize(this.#browser.version);\n      Object.freeze(this.#browser);\n    }\n    return this.#browser;\n  }\n  /**\n   * The architecture of the CPU extracted from the user agent string.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { UserAgent } from \"@std/http/user-agent\";\n   *\n   * Deno.serve((req) => {\n   *   const userAgent = new UserAgent(req.headers.get(\"user-agent\") ?? \"\");\n   *   return new Response(`Hello, ${userAgent.cpu.architecture}!`);\n   * });\n   * ```\n   *\n   * @returns An object with information about the user agent's CPU.\n   */ get cpu() {\n    if (!this.#cpu) {\n      this.#cpu = {\n        architecture: undefined\n      };\n      mapper(this.#cpu, this.#ua, matchers.cpu);\n      Object.freeze(this.#cpu);\n    }\n    return this.#cpu;\n  }\n  /**\n   * The model, type, and vendor of a device if present in a user agent\n   * string.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { UserAgent } from \"@std/http/user-agent\";\n   *\n   * Deno.serve((req) => {\n   *   const userAgent = new UserAgent(req.headers.get(\"user-agent\") ?? \"\");\n   *   return new Response(`Hello, ${userAgent.device.model}!`);\n   * });\n   * ```\n   *\n   * @returns An object with information about the user agent's device.\n   */ get device() {\n    if (!this.#device) {\n      this.#device = {\n        model: undefined,\n        type: undefined,\n        vendor: undefined\n      };\n      mapper(this.#device, this.#ua, matchers.device);\n      Object.freeze(this.#device);\n    }\n    return this.#device;\n  }\n  /**\n   * The name and version of the browser engine in a user agent string.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { UserAgent } from \"@std/http/user-agent\";\n   *\n   * Deno.serve((req) => {\n   *   const userAgent = new UserAgent(req.headers.get(\"user-agent\") ?? \"\");\n   *   return new Response(`Hello, ${userAgent.engine.name}!`);\n   * });\n   * ```\n   *\n   * @returns An object with information about the user agent's browser engine.\n   */ get engine() {\n    if (!this.#engine) {\n      this.#engine = {\n        name: undefined,\n        version: undefined\n      };\n      mapper(this.#engine, this.#ua, matchers.engine);\n      Object.freeze(this.#engine);\n    }\n    return this.#engine;\n  }\n  /**\n   * The name and version of the operating system in a user agent string.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { UserAgent } from \"@std/http/user-agent\";\n   *\n   * Deno.serve((req) => {\n   *   const userAgent = new UserAgent(req.headers.get(\"user-agent\") ?? \"\");\n   *   return new Response(`Hello, ${userAgent.os.name}!`);\n   * });\n   * ```\n   *\n   * @returns An object with information about the user agent's OS.\n   */ get os() {\n    if (!this.#os) {\n      this.#os = {\n        name: undefined,\n        version: undefined\n      };\n      mapper(this.#os, this.#ua, matchers.os);\n      Object.freeze(this.#os);\n    }\n    return this.#os;\n  }\n  /**\n   * A read only version of the user agent string related to the instance.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { UserAgent } from \"@std/http/user-agent\";\n   *\n   * Deno.serve((req) => {\n   *   const userAgent = new UserAgent(req.headers.get(\"user-agent\") ?? \"\");\n   *   return new Response(`Hello, ${userAgent.ua}!`);\n   * });\n   * ```\n   *\n   * @returns The user agent string.\n   */ get ua() {\n    return this.#ua;\n  }\n  /**\n   * Converts the current instance to a JSON representation.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { UserAgent } from \"@std/http/user-agent\";\n   *\n   * Deno.serve((req) => {\n   *   const userAgent = new UserAgent(req.headers.get(\"user-agent\") ?? \"\");\n   *   return new Response(`Hello, ${JSON.stringify(userAgent.toJSON())}!`);\n   * });\n   * ```\n   *\n   * @returns A JSON representation on this user agent instance.\n   */ toJSON() {\n    const { browser, cpu, device, engine, os, ua } = this;\n    return {\n      browser,\n      cpu,\n      device,\n      engine,\n      os,\n      ua\n    };\n  }\n  /**\n   * Converts the current instance to a string.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { UserAgent } from \"@std/http/user-agent\";\n   *\n   * Deno.serve((req) => {\n   *   const userAgent = new UserAgent(req.headers.get(\"user-agent\") ?? \"\");\n   *   return new Response(`Hello, ${userAgent.toString()}!`);\n   * });\n   * ```\n   *\n   * @returns The user agent string.\n   */ toString() {\n    return this.#ua;\n  }\n  /**\n   * Custom output for {@linkcode Deno.inspect}.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { UserAgent } from \"@std/http/user-agent\";\n   *\n   * Deno.serve((req) => {\n   *   const userAgent = new UserAgent(req.headers.get(\"user-agent\") ?? \"\");\n   *   Deno.inspect(userAgent);\n   *   return new Response(`Hello, ${userAgent.ua}!`);\n   * });\n   * ```\n   *\n   * @param inspect internal inspect function.\n   *\n   * @returns The custom value to inspect.\n   */ [_computedKey](inspect) {\n    const { browser, cpu, device, engine, os, ua } = this;\n    return `${this.constructor.name} ${inspect({\n      browser,\n      cpu,\n      device,\n      engine,\n      os,\n      ua\n    })}`;\n  }\n  /**\n   * Custom output for Node's\n   * {@linkcode https://nodejs.org/api/util.html#utilinspectobject-options | util.inspect}.\n   *\n   * @example Usage\n   * ```ts ignore\n   * import { UserAgent } from \"@std/http/user-agent\";\n   * import { inspect } from \"node:util\";\n   *\n   * Deno.serve((req) => {\n   *   const userAgent = new UserAgent(req.headers.get(\"user-agent\") ?? \"\");\n   *   inspect(userAgent);\n   *   return new Response(`Hello, ${userAgent.ua}!`);\n   * });\n   * ```\n   *\n   * @param depth internal inspect depth.\n   * @param options internal inspect option.\n   * @param inspect internal inspect function.\n   *\n   * @returns The custom value to inspect.\n   */ [_computedKey1](depth, // deno-lint-ignore no-explicit-any\n  options, inspect) {\n    if (depth < 0) {\n      return options.stylize(`[${this.constructor.name}]`, \"special\");\n    }\n    const newOptions = Object.assign({}, options, {\n      depth: options.depth === null ? null : options.depth - 1\n    });\n    const { browser, cpu, device, engine, os, ua } = this;\n    return `${options.stylize(this.constructor.name, \"special\")} ${inspect({\n      browser,\n      cpu,\n      device,\n      engine,\n      os,\n      ua\n    }, newOptions)}`;\n  }\n}",
      "accepts": "function accepts(request, ...types) {\n  const accept = request.headers.get(\"accept\");\n  return types.length ? accept ? preferredMediaTypes(accept, types)[0] : types[0] : accept ? preferredMediaTypes(accept) : [\n    \"*/*\"\n  ];\n}",
      "acceptsEncodings": "function acceptsEncodings(request, ...encodings) {\n  const acceptEncoding = request.headers.get(\"accept-encoding\");\n  return encodings.length ? acceptEncoding ? preferredEncodings(acceptEncoding, encodings)[0] : encodings[0] : acceptEncoding ? preferredEncodings(acceptEncoding) : [\n    \"*\"\n  ];\n}",
      "acceptsLanguages": "function acceptsLanguages(request, ...langs) {\n  const acceptLanguage = request.headers.get(\"accept-language\");\n  return langs.length ? acceptLanguage ? preferredLanguages(acceptLanguage, langs)[0] : langs[0] : acceptLanguage ? preferredLanguages(acceptLanguage) : [\n    \"*\"\n  ];\n}",
      "deleteCookie": "function deleteCookie(headers, name, attributes) {\n  setCookie(headers, {\n    name: name,\n    value: \"\",\n    expires: new Date(0),\n    ...attributes\n  });\n}",
      "eTag": "async function eTag(entity, options = {}) {\n  const weak = options.weak ?? isFileInfo(entity);\n  const tag = await (isFileInfo(entity) ? calcFileInfo(entity, options) : calcEntity(entity, options));\n  return tag ? weak ? `W/\"${tag}\"` : `\"${tag}\"` : undefined;\n}",
      "getCookies": "function getCookies(headers) {\n  const cookie = headers.get(\"Cookie\");\n  if (cookie !== null) {\n    const out = {};\n    const c = cookie.split(\";\");\n    for (const kv of c){\n      const [cookieKey, ...cookieVal] = kv.split(\"=\");\n      if (cookieKey === undefined) {\n        throw new SyntaxError(\"Cookie cannot start with '='\");\n      }\n      const key = cookieKey.trim();\n      out[key] = cookieVal.join(\"=\");\n    }\n    return out;\n  }\n  return {};\n}",
      "getSetCookies": "function getSetCookies(headers) {\n  return headers.getSetCookie()/** Parse each `set-cookie` header separately */ .map(parseSetCookie)/** Skip empty cookies */ .filter(Boolean);\n}",
      "ifMatch": "function ifMatch(value, etag) {\n  // Weak tags cannot be matched and return false.\n  if (!value || !etag || etag.startsWith(\"W/\")) {\n    return false;\n  }\n  if (STAR_REGEXP.test(value)) {\n    return true;\n  }\n  const tags = value.split(COMMA_REGEXP);\n  return tags.includes(etag);\n}",
      "ifNoneMatch": "function ifNoneMatch(value, etag) {\n  if (!value || !etag) {\n    return true;\n  }\n  if (STAR_REGEXP.test(value)) {\n    return false;\n  }\n  etag = etag.startsWith(\"W/\") ? etag.slice(2) : etag;\n  const tags = value.split(COMMA_REGEXP).map((tag)=>tag.startsWith(\"W/\") ? tag.slice(2) : tag);\n  return !tags.includes(etag);\n}",
      "isClientErrorStatus": "function isClientErrorStatus(status) {\n  return isStatus(status) && status >= 400 && status < 500;\n}",
      "isErrorStatus": "function isErrorStatus(status) {\n  return isStatus(status) && status >= 400 && status < 600;\n}",
      "isInformationalStatus": "function isInformationalStatus(status) {\n  return isStatus(status) && status >= 100 && status < 200;\n}",
      "isRedirectStatus": "function isRedirectStatus(status) {\n  return isStatus(status) && status >= 300 && status < 400;\n}",
      "isServerErrorStatus": "function isServerErrorStatus(status) {\n  return isStatus(status) && status >= 500 && status < 600;\n}",
      "isStatus": "function isStatus(status) {\n  return Object.values(STATUS_CODE).includes(status);\n}",
      "isSuccessfulStatus": "function isSuccessfulStatus(status) {\n  return isStatus(status) && status >= 200 && status < 300;\n}",
      "route": "function route(routes, defaultHandler) {\n  // TODO(iuioiua): Use `URLPatternList` once available (https://github.com/whatwg/urlpattern/pull/166)\n  return (request, info)=>{\n    for (const route of routes){\n      const match = route.pattern.exec(request.url);\n      if (match && (Array.isArray(route.method) ? route.method.includes(request.method) : request.method === (route.method ?? \"GET\"))) {\n        return route.handler(request, info, match);\n      }\n    }\n    return defaultHandler(request, info);\n  };\n}",
      "serveDir": "async function serveDir(req, opts = {}) {\n  if (req.method !== METHOD.Get) {\n    return createStandardResponse(STATUS_CODE.MethodNotAllowed);\n  }\n  let response;\n  try {\n    response = await createServeDirResponse(req, opts);\n  } catch (error) {\n    if (!opts.quiet) logError(error);\n    response = error instanceof Deno.errors.NotFound ? createStandardResponse(STATUS_CODE.NotFound) : createStandardResponse(STATUS_CODE.InternalServerError);\n  }\n  // Do not update the header if the response is a 301 redirect.\n  const isRedirectResponse = isRedirectStatus(response.status);\n  if (opts.enableCors && !isRedirectResponse) {\n    response.headers.append(HEADER.AccessControlAllowOrigin, \"*\");\n    response.headers.append(HEADER.AccessControlAllowHeaders, \"Origin, X-Requested-With, Content-Type, Accept, Range\");\n  }\n  if (!opts.quiet) serverLog(req, response.status);\n  if (opts.headers && !isRedirectResponse) {\n    for (const header of opts.headers){\n      const headerSplit = header.split(\":\");\n      const name = headerSplit[0];\n      const value = headerSplit.slice(1).join(\":\");\n      response.headers.append(name, value);\n    }\n  }\n  return response;\n}",
      "serveFile": "async function serveFile(req, filePath, options) {\n  if (req.method !== METHOD.Get) {\n    return createStandardResponse(STATUS_CODE.MethodNotAllowed);\n  }\n  let { etagAlgorithm: algorithm = \"SHA-256\", fileInfo } = options ?? {};\n  try {\n    fileInfo ??= await Deno.stat(filePath);\n  } catch (error) {\n    if (error instanceof Deno.errors.NotFound) {\n      await req.body?.cancel();\n      return createStandardResponse(STATUS_CODE.NotFound);\n    } else {\n      throw error;\n    }\n  }\n  if (fileInfo.isDirectory) {\n    await req.body?.cancel();\n    return createStandardResponse(STATUS_CODE.NotFound);\n  }\n  const headers = createBaseHeaders();\n  // Set date header if access timestamp is available\n  if (fileInfo.atime) {\n    headers.set(HEADER.Date, fileInfo.atime.toUTCString());\n  }\n  const etag = fileInfo.mtime ? await eTag(fileInfo, {\n    algorithm\n  }) : await HASHED_DENO_DEPLOYMENT_ID;\n  // Set last modified header if last modification timestamp is available\n  if (fileInfo.mtime) {\n    headers.set(HEADER.LastModified, fileInfo.mtime.toUTCString());\n  }\n  if (etag) {\n    headers.set(HEADER.ETag, etag);\n  }\n  if (etag || fileInfo.mtime) {\n    // If a `if-none-match` header is present and the value matches the tag or\n    // if a `if-modified-since` header is present and the value is bigger than\n    // the access timestamp value, then return 304\n    const ifNoneMatchValue = req.headers.get(HEADER.IfNoneMatch);\n    const ifModifiedSinceValue = req.headers.get(HEADER.IfModifiedSince);\n    if (!ifNoneMatch(ifNoneMatchValue, etag) || ifNoneMatchValue === null && fileInfo.mtime && ifModifiedSinceValue && fileInfo.mtime.getTime() < new Date(ifModifiedSinceValue).getTime() + 1000) {\n      const status = STATUS_CODE.NotModified;\n      return new Response(null, {\n        status,\n        statusText: STATUS_TEXT[status],\n        headers\n      });\n    }\n  }\n  // Set mime-type using the file extension in filePath\n  const contentTypeValue = contentType(extname(filePath));\n  if (contentTypeValue) {\n    headers.set(HEADER.ContentType, contentTypeValue);\n  }\n  const fileSize = fileInfo.size;\n  const rangeValue = req.headers.get(HEADER.Range);\n  // handle range request\n  // Note: Some clients add a Range header to all requests to limit the size of the response.\n  // If the file is empty, ignore the range header and respond with a 200 rather than a 416.\n  // https://github.com/golang/go/blob/0d347544cbca0f42b160424f6bc2458ebcc7b3fc/src/net/http/fs.go#L273-L276\n  if (rangeValue && 0 < fileSize) {\n    const parsed = parseRangeHeader(rangeValue, fileSize);\n    // Returns 200 OK if parsing the range header fails\n    if (!parsed) {\n      // Set content length\n      headers.set(HEADER.ContentLength, `${fileSize}`);\n      const file = await Deno.open(filePath);\n      const status = STATUS_CODE.OK;\n      return new Response(file.readable, {\n        status,\n        statusText: STATUS_TEXT[status],\n        headers\n      });\n    }\n    // Return 416 Range Not Satisfiable if invalid range header value\n    if (parsed.end < 0 || parsed.end < parsed.start || fileSize <= parsed.start) {\n      // Set the \"Content-range\" header\n      headers.set(HEADER.ContentRange, `bytes */${fileSize}`);\n      return createStandardResponse(STATUS_CODE.RangeNotSatisfiable, {\n        headers\n      });\n    }\n    // clamps the range header value\n    const start = Math.max(0, parsed.start);\n    const end = Math.min(parsed.end, fileSize - 1);\n    // Set the \"Content-range\" header\n    headers.set(HEADER.ContentRange, `bytes ${start}-${end}/${fileSize}`);\n    // Set content length\n    const contentLength = end - start + 1;\n    headers.set(HEADER.ContentLength, `${contentLength}`);\n    // Return 206 Partial Content\n    const file = await Deno.open(filePath);\n    await file.seek(start, Deno.SeekMode.Start);\n    const sliced = file.readable.pipeThrough(new ByteSliceStream(0, contentLength - 1));\n    const status = STATUS_CODE.PartialContent;\n    return new Response(sliced, {\n      status,\n      statusText: STATUS_TEXT[status],\n      headers\n    });\n  }\n  // Set content length\n  headers.set(HEADER.ContentLength, `${fileSize}`);\n  const file = await Deno.open(filePath);\n  const status = STATUS_CODE.OK;\n  return new Response(file.readable, {\n    status,\n    statusText: STATUS_TEXT[status],\n    headers\n  });\n}",
      "setCookie": "function setCookie(headers, cookie) {\n  // Parsing cookie headers to make consistent set-cookie header\n  // ref: https://www.rfc-editor.org/rfc/rfc6265.html#section-4.1.1\n  const v = toString(cookie);\n  if (v) {\n    headers.append(\"Set-Cookie\", v);\n  }\n}"
    }
  },
  {
    "jsr:@std/html": {
      "escape": "function escape(str) {\n  return str.replaceAll(rawRe, (m)=>rawToEntity.get(m));\n}",
      "unescape": "function unescape(str, options = {}) {\n  const { entityList } = {\n    ...defaultUnescapeOptions,\n    ...options\n  };\n  let entityRe = entityListRegexCache.get(entityList);\n  if (!entityRe) {\n    entityRe = new RegExp(`(${Object.keys(entityList).sort((a, b)=>b.length - a.length).join(\"|\")})`, \"g\");\n    entityListRegexCache.set(entityList, entityRe);\n  }\n  return str.replaceAll(entityRe, (m)=>entityList[m]).replaceAll(RX_DEC_ENTITY, (_, dec)=>codePointStrToChar(dec, 10)).replaceAll(RX_HEX_ENTITY, (_, hex)=>codePointStrToChar(hex, 16));\n}"
    }
  },
  {
    "jsr:@std/fs": {
      "CRLF": "\r\n",
      "EOL": "\n",
      "LF": "\n",
      "copy": "async function copy(src, dest, options = {}) {\n  src = resolve(toPathString(src));\n  dest = resolve(toPathString(dest));\n  if (src === dest) {\n    throw new Error(\"Source and destination cannot be the same\");\n  }\n  const srcStat = await Deno.lstat(src);\n  if (srcStat.isDirectory && isSubdir(src, dest)) {\n    throw new Error(`Cannot copy '${src}' to a subdirectory of itself: '${dest}'`);\n  }\n  if (srcStat.isSymlink) {\n    await copySymLink(src, dest, options);\n  } else if (srcStat.isDirectory) {\n    await copyDir(src, dest, options);\n  } else if (srcStat.isFile) {\n    await copyFile(src, dest, options);\n  }\n}",
      "copySync": "function copySync(src, dest, options = {}) {\n  src = resolve(toPathString(src));\n  dest = resolve(toPathString(dest));\n  if (src === dest) {\n    throw new Error(\"Source and destination cannot be the same\");\n  }\n  const srcStat = Deno.lstatSync(src);\n  if (srcStat.isDirectory && isSubdir(src, dest)) {\n    throw new Error(`Cannot copy '${src}' to a subdirectory of itself: '${dest}'`);\n  }\n  if (srcStat.isSymlink) {\n    copySymlinkSync(src, dest, options);\n  } else if (srcStat.isDirectory) {\n    copyDirSync(src, dest, options);\n  } else if (srcStat.isFile) {\n    copyFileSync(src, dest, options);\n  }\n}",
      "detect": "function detect(content) {\n  const d = content.match(regDetect);\n  if (!d || d.length === 0) {\n    return null;\n  }\n  const hasCRLF = d.some((x)=>x === CRLF);\n  return hasCRLF ? CRLF : LF;\n}",
      "emptyDir": "async function emptyDir(dir) {\n  try {\n    const items = await Array.fromAsync(Deno.readDir(dir));\n    await Promise.all(items.map((item)=>{\n      if (item && item.name) {\n        const filepath = join(toPathString(dir), item.name);\n        return Deno.remove(filepath, {\n          recursive: true\n        });\n      }\n    }));\n  } catch (err) {\n    if (!(err instanceof Deno.errors.NotFound)) {\n      throw err;\n    }\n    // if not exist. then create it\n    await Deno.mkdir(dir, {\n      recursive: true\n    });\n  }\n}",
      "emptyDirSync": "function emptyDirSync(dir) {\n  try {\n    const items = [\n      ...Deno.readDirSync(dir)\n    ];\n    // If the directory exists, remove all entries inside it.\n    while(items.length){\n      const item = items.shift();\n      if (item && item.name) {\n        const filepath = join(toPathString(dir), item.name);\n        Deno.removeSync(filepath, {\n          recursive: true\n        });\n      }\n    }\n  } catch (err) {\n    if (!(err instanceof Deno.errors.NotFound)) {\n      throw err;\n    }\n    // if not exist. then create it\n    Deno.mkdirSync(dir, {\n      recursive: true\n    });\n  }\n}",
      "ensureDir": "async function ensureDir(dir) {\n  try {\n    const fileInfo = await Deno.stat(dir);\n    throwIfNotDirectory(fileInfo);\n    return;\n  } catch (err) {\n    if (!(err instanceof Deno.errors.NotFound)) {\n      throw err;\n    }\n  }\n  // The dir doesn't exist. Create it.\n  // This can be racy. So we catch AlreadyExists and check stat again.\n  try {\n    await Deno.mkdir(dir, {\n      recursive: true\n    });\n  } catch (err) {\n    if (!(err instanceof Deno.errors.AlreadyExists)) {\n      throw err;\n    }\n    const fileInfo = await Deno.stat(dir);\n    throwIfNotDirectory(fileInfo);\n  }\n}",
      "ensureDirSync": "function ensureDirSync(dir) {\n  try {\n    const fileInfo = Deno.statSync(dir);\n    throwIfNotDirectory(fileInfo);\n    return;\n  } catch (err) {\n    if (!(err instanceof Deno.errors.NotFound)) {\n      throw err;\n    }\n  }\n  // The dir doesn't exist. Create it.\n  // This can be racy. So we catch AlreadyExists and check stat again.\n  try {\n    Deno.mkdirSync(dir, {\n      recursive: true\n    });\n  } catch (err) {\n    if (!(err instanceof Deno.errors.AlreadyExists)) {\n      throw err;\n    }\n    const fileInfo = Deno.statSync(dir);\n    throwIfNotDirectory(fileInfo);\n  }\n}",
      "ensureFile": "async function ensureFile(filePath) {\n  try {\n    // if file exists\n    const stat = await Deno.lstat(filePath);\n    if (!stat.isFile) {\n      throw new Error(`Failed to ensure file exists: expected 'file', got '${getFileInfoType(stat)}'`);\n    }\n  } catch (err) {\n    // if file not exists\n    if (err instanceof Deno.errors.NotFound) {\n      // ensure dir exists\n      await ensureDir(dirname(toPathString(filePath)));\n      // create file\n      await Deno.writeFile(filePath, new Uint8Array());\n      return;\n    }\n    throw err;\n  }\n}",
      "ensureFileSync": "function ensureFileSync(filePath) {\n  try {\n    // if file exists\n    const stat = Deno.lstatSync(filePath);\n    if (!stat.isFile) {\n      throw new Error(`Failed to ensure file exists: expected 'file', got '${getFileInfoType(stat)}'`);\n    }\n  } catch (err) {\n    // if file not exists\n    if (err instanceof Deno.errors.NotFound) {\n      // ensure dir exists\n      ensureDirSync(dirname(toPathString(filePath)));\n      // create file\n      Deno.writeFileSync(filePath, new Uint8Array());\n      return;\n    }\n    throw err;\n  }\n}",
      "ensureLink": "async function ensureLink(src, dest) {\n  dest = toPathString(dest);\n  await ensureDir(dirname(dest));\n  await Deno.link(toPathString(src), dest);\n}",
      "ensureLinkSync": "function ensureLinkSync(src, dest) {\n  dest = toPathString(dest);\n  ensureDirSync(dirname(dest));\n  Deno.linkSync(toPathString(src), dest);\n}",
      "ensureSymlink": "async function ensureSymlink(target, linkName) {\n  const targetRealPath = resolveSymlinkTarget(target, linkName);\n  const srcStatInfo = await Deno.lstat(targetRealPath);\n  const srcFilePathType = getFileInfoType(srcStatInfo);\n  await ensureDir(dirname(toPathString(linkName)));\n  const options = getSymlinkOption(srcFilePathType);\n  try {\n    await Deno.symlink(target, linkName, options);\n  } catch (error) {\n    if (!(error instanceof Deno.errors.AlreadyExists)) {\n      throw error;\n    }\n    const linkStatInfo = await Deno.lstat(linkName);\n    if (!linkStatInfo.isSymlink) {\n      const type = getFileInfoType(linkStatInfo);\n      throw new Deno.errors.AlreadyExists(`A '${type}' already exists at the path: ${linkName}`);\n    }\n    const linkPath = await Deno.readLink(linkName);\n    const linkRealPath = resolve(linkPath);\n    if (linkRealPath !== targetRealPath) {\n      throw new Deno.errors.AlreadyExists(`A symlink targeting to an undesired path already exists: ${linkName} -> ${linkRealPath}`);\n    }\n  }\n}",
      "ensureSymlinkSync": "function ensureSymlinkSync(target, linkName) {\n  const targetRealPath = resolveSymlinkTarget(target, linkName);\n  const srcStatInfo = Deno.lstatSync(targetRealPath);\n  const srcFilePathType = getFileInfoType(srcStatInfo);\n  ensureDirSync(dirname(toPathString(linkName)));\n  const options = getSymlinkOption(srcFilePathType);\n  try {\n    Deno.symlinkSync(target, linkName, options);\n  } catch (error) {\n    if (!(error instanceof Deno.errors.AlreadyExists)) {\n      throw error;\n    }\n    const linkStatInfo = Deno.lstatSync(linkName);\n    if (!linkStatInfo.isSymlink) {\n      const type = getFileInfoType(linkStatInfo);\n      throw new Deno.errors.AlreadyExists(`A '${type}' already exists at the path: ${linkName}`);\n    }\n    const linkPath = Deno.readLinkSync(linkName);\n    const linkRealPath = resolve(linkPath);\n    if (linkRealPath !== targetRealPath) {\n      throw new Deno.errors.AlreadyExists(`A symlink targeting to an undesired path already exists: ${linkName} -> ${linkRealPath}`);\n    }\n  }\n}",
      "exists": "async function exists(path, options) {\n  try {\n    const stat = await Deno.stat(path);\n    if (options && (options.isReadable || options.isDirectory || options.isFile)) {\n      if (options.isDirectory && options.isFile) {\n        throw new TypeError(\"ExistsOptions.options.isDirectory and ExistsOptions.options.isFile must not be true together\");\n      }\n      if (options.isDirectory && !stat.isDirectory || options.isFile && !stat.isFile) {\n        return false;\n      }\n      if (options.isReadable) {\n        return fileIsReadable(stat);\n      }\n    }\n    return true;\n  } catch (error) {\n    if (error instanceof Deno.errors.NotFound) {\n      return false;\n    }\n    if (error instanceof Deno.errors.PermissionDenied) {\n      if ((await Deno.permissions.query({\n        name: \"read\",\n        path\n      })).state === \"granted\") {\n        // --allow-read not missing\n        return !options?.isReadable; // PermissionDenied was raised by file system, so the item exists, but can't be read\n      }\n    }\n    throw error;\n  }\n}",
      "existsSync": "function existsSync(path, options) {\n  try {\n    const stat = Deno.statSync(path);\n    if (options && (options.isReadable || options.isDirectory || options.isFile)) {\n      if (options.isDirectory && options.isFile) {\n        throw new TypeError(\"ExistsOptions.options.isDirectory and ExistsOptions.options.isFile must not be true together\");\n      }\n      if (options.isDirectory && !stat.isDirectory || options.isFile && !stat.isFile) {\n        return false;\n      }\n      if (options.isReadable) {\n        return fileIsReadable(stat);\n      }\n    }\n    return true;\n  } catch (error) {\n    if (error instanceof Deno.errors.NotFound) {\n      return false;\n    }\n    if (error instanceof Deno.errors.PermissionDenied) {\n      if (Deno.permissions.querySync({\n        name: \"read\",\n        path\n      }).state === \"granted\") {\n        // --allow-read not missing\n        return !options?.isReadable; // PermissionDenied was raised by file system, so the item exists, but can't be read\n      }\n    }\n    throw error;\n  }\n}",
      "expandGlob": "async function* expandGlob(glob, options) {\n  let { root, exclude = [], includeDirs = true, extended = true, globstar = true, caseInsensitive = false, followSymlinks = false, canonicalize = true } = options ?? {};\n  const { segments, isAbsolute: isGlobAbsolute, hasTrailingSep, winRoot } = split(toPathString(glob));\n  root ??= isGlobAbsolute ? winRoot ?? \"/\" : Deno.cwd();\n  const globOptions = {\n    extended,\n    globstar,\n    caseInsensitive\n  };\n  const absRoot = isGlobAbsolute ? root : resolve(root); // root is always string here\n  const resolveFromRoot = (path)=>resolve(absRoot, path);\n  const excludePatterns = exclude.map(resolveFromRoot).map((s)=>globToRegExp(s, globOptions));\n  const shouldInclude = (path)=>!excludePatterns.some((p)=>!!path.match(p));\n  let fixedRoot = isGlobAbsolute ? winRoot ?? \"/\" : absRoot;\n  while(segments.length > 0 && !isGlob(segments[0])){\n    const seg = segments.shift();\n    fixedRoot = joinGlobs([\n      fixedRoot,\n      seg\n    ], globOptions);\n  }\n  let fixedRootInfo;\n  try {\n    fixedRootInfo = await createWalkEntry(fixedRoot);\n  } catch (error) {\n    return throwUnlessNotFound(error);\n  }\n  async function* advanceMatch(walkInfo, globSegment) {\n    if (!walkInfo.isDirectory) {\n      return;\n    } else if (globSegment === \"..\") {\n      const parentPath = joinGlobs([\n        walkInfo.path,\n        \"..\"\n      ], globOptions);\n      if (shouldInclude(parentPath)) {\n        return yield await createWalkEntry(parentPath);\n      }\n      return;\n    } else if (globSegment === \"**\") {\n      return yield* walk(walkInfo.path, {\n        skip: excludePatterns,\n        maxDepth: globstar ? Infinity : 1,\n        followSymlinks,\n        canonicalize\n      });\n    }\n    const globPattern = globToRegExp(globSegment, globOptions);\n    for await (const walkEntry of walk(walkInfo.path, {\n      maxDepth: 1,\n      skip: excludePatterns,\n      followSymlinks\n    })){\n      if (walkEntry.path !== walkInfo.path && walkEntry.name.match(globPattern)) {\n        yield walkEntry;\n      }\n    }\n  }\n  let currentMatches = [\n    fixedRootInfo\n  ];\n  for (const segment of segments){\n    // Advancing the list of current matches may introduce duplicates, so we\n    // pass everything through this Map.\n    const nextMatchMap = new Map();\n    await Promise.all(currentMatches.map(async (currentMatch)=>{\n      for await (const nextMatch of advanceMatch(currentMatch, segment)){\n        nextMatchMap.set(nextMatch.path, nextMatch);\n      }\n    }));\n    currentMatches = [\n      ...nextMatchMap.values()\n    ].sort(comparePath);\n  }\n  if (hasTrailingSep) {\n    currentMatches = currentMatches.filter((entry)=>entry.isDirectory);\n  }\n  if (!includeDirs) {\n    currentMatches = currentMatches.filter((entry)=>!entry.isDirectory);\n  }\n  yield* currentMatches;\n}",
      "expandGlobSync": "function* expandGlobSync(glob, options) {\n  let { root, exclude = [], includeDirs = true, extended = true, globstar = true, caseInsensitive = false, followSymlinks = false, canonicalize = true } = options ?? {};\n  const { segments, isAbsolute: isGlobAbsolute, hasTrailingSep, winRoot } = split(toPathString(glob));\n  root ??= isGlobAbsolute ? winRoot ?? \"/\" : Deno.cwd();\n  const globOptions = {\n    extended,\n    globstar,\n    caseInsensitive\n  };\n  const absRoot = isGlobAbsolute ? root : resolve(root); // root is always string here\n  const resolveFromRoot = (path)=>resolve(absRoot, path);\n  const excludePatterns = exclude.map(resolveFromRoot).map((s)=>globToRegExp(s, globOptions));\n  const shouldInclude = (path)=>!excludePatterns.some((p)=>!!path.match(p));\n  let fixedRoot = isGlobAbsolute ? winRoot ?? \"/\" : absRoot;\n  while(segments.length > 0 && !isGlob(segments[0])){\n    const seg = segments.shift();\n    fixedRoot = joinGlobs([\n      fixedRoot,\n      seg\n    ], globOptions);\n  }\n  let fixedRootInfo;\n  try {\n    fixedRootInfo = createWalkEntrySync(fixedRoot);\n  } catch (error) {\n    return throwUnlessNotFound(error);\n  }\n  function* advanceMatch(walkInfo, globSegment) {\n    if (!walkInfo.isDirectory) {\n      return;\n    } else if (globSegment === \"..\") {\n      const parentPath = joinGlobs([\n        walkInfo.path,\n        \"..\"\n      ], globOptions);\n      if (shouldInclude(parentPath)) {\n        return yield createWalkEntrySync(parentPath);\n      }\n      return;\n    } else if (globSegment === \"**\") {\n      return yield* walkSync(walkInfo.path, {\n        skip: excludePatterns,\n        maxDepth: globstar ? Infinity : 1,\n        followSymlinks,\n        canonicalize\n      });\n    }\n    const globPattern = globToRegExp(globSegment, globOptions);\n    for (const walkEntry of walkSync(walkInfo.path, {\n      maxDepth: 1,\n      skip: excludePatterns,\n      followSymlinks\n    })){\n      if (walkEntry.path !== walkInfo.path && walkEntry.name.match(globPattern)) {\n        yield walkEntry;\n      }\n    }\n  }\n  let currentMatches = [\n    fixedRootInfo\n  ];\n  for (const segment of segments){\n    // Advancing the list of current matches may introduce duplicates, so we\n    // pass everything through this Map.\n    const nextMatchMap = new Map();\n    for (const currentMatch of currentMatches){\n      for (const nextMatch of advanceMatch(currentMatch, segment)){\n        nextMatchMap.set(nextMatch.path, nextMatch);\n      }\n    }\n    currentMatches = [\n      ...nextMatchMap.values()\n    ].sort(comparePath);\n  }\n  if (hasTrailingSep) {\n    currentMatches = currentMatches.filter((entry)=>entry.isDirectory);\n  }\n  if (!includeDirs) {\n    currentMatches = currentMatches.filter((entry)=>!entry.isDirectory);\n  }\n  yield* currentMatches;\n}",
      "format": "function format(content, eol) {\n  return content.replace(regDetect, eol);\n}",
      "move": "async function move(src, dest, options) {\n  const { overwrite = false } = options ?? {};\n  const srcStat = await Deno.stat(src);\n  if (srcStat.isDirectory && (isSubdir(src, dest) || isSamePath(src, dest))) {\n    throw new Deno.errors.NotSupported(`Cannot move '${src}' to a subdirectory of itself, '${dest}'.`);\n  }\n  if (overwrite) {\n    if (isSamePath(src, dest)) return;\n    try {\n      await Deno.remove(dest, {\n        recursive: true\n      });\n    } catch (error) {\n      if (!(error instanceof Deno.errors.NotFound)) {\n        throw error;\n      }\n    }\n  } else {\n    try {\n      await Deno.lstat(dest);\n      return Promise.reject(EXISTS_ERROR);\n    } catch  {\n    // Do nothing...\n    }\n  }\n  await Deno.rename(src, dest);\n}",
      "moveSync": "function moveSync(src, dest, options) {\n  const { overwrite = false } = options ?? {};\n  const srcStat = Deno.statSync(src);\n  if (srcStat.isDirectory && (isSubdir(src, dest) || isSamePath(src, dest))) {\n    throw new Deno.errors.NotSupported(`Cannot move '${src}' to a subdirectory of itself, '${dest}'.`);\n  }\n  if (overwrite) {\n    if (isSamePath(src, dest)) return;\n    try {\n      Deno.removeSync(dest, {\n        recursive: true\n      });\n    } catch (error) {\n      if (!(error instanceof Deno.errors.NotFound)) {\n        throw error;\n      }\n    }\n  } else {\n    try {\n      Deno.lstatSync(dest);\n      throw EXISTS_ERROR;\n    } catch (error) {\n      if (error === EXISTS_ERROR) {\n        throw error;\n      }\n    }\n  }\n  Deno.renameSync(src, dest);\n}",
      "walk": "async function* walk(root, options) {\n  let { maxDepth = Infinity, includeFiles = true, includeDirs = true, includeSymlinks = true, followSymlinks = false, canonicalize = true, exts = undefined, match = undefined, skip = undefined } = options ?? {};\n  if (maxDepth < 0) {\n    return;\n  }\n  root = toPathString(root);\n  if (exts) {\n    exts = exts.map((ext)=>ext.startsWith(\".\") ? ext : `.${ext}`);\n  }\n  if (includeDirs && include(root, exts, match, skip)) {\n    yield await createWalkEntry(root);\n  }\n  if (maxDepth < 1 || !include(root, undefined, undefined, skip)) {\n    return;\n  }\n  for await (const entry of Deno.readDir(root)){\n    let path = join(root, entry.name);\n    let { isSymlink, isDirectory } = entry;\n    if (isSymlink) {\n      if (!followSymlinks) {\n        if (includeSymlinks && include(path, exts, match, skip)) {\n          yield {\n            path,\n            ...entry\n          };\n        }\n        continue;\n      }\n      const realPath = await Deno.realPath(path);\n      if (canonicalize) {\n        path = realPath;\n      }\n      // Caveat emptor: don't assume |path| is not a symlink. realpath()\n      // resolves symlinks but another process can replace the file system\n      // entity with a different type of entity before we call lstat().\n      ({ isSymlink, isDirectory } = await Deno.lstat(realPath));\n    }\n    if (isSymlink || isDirectory) {\n      const opts = {\n        maxDepth: maxDepth - 1,\n        includeFiles,\n        includeDirs,\n        includeSymlinks,\n        followSymlinks\n      };\n      if (exts !== undefined) {\n        opts.exts = exts;\n      }\n      if (match !== undefined) {\n        opts.match = match;\n      }\n      if (skip !== undefined) {\n        opts.skip = skip;\n      }\n      yield* walk(path, opts);\n    } else if (includeFiles && include(path, exts, match, skip)) {\n      yield {\n        path,\n        ...entry\n      };\n    }\n  }\n}",
      "walkSync": "function* walkSync(root, options) {\n  let { maxDepth = Infinity, includeFiles = true, includeDirs = true, includeSymlinks = true, followSymlinks = false, canonicalize = true, exts = undefined, match = undefined, skip = undefined } = options ?? {};\n  root = toPathString(root);\n  if (exts) {\n    exts = exts.map((ext)=>ext.startsWith(\".\") ? ext : `.${ext}`);\n  }\n  if (maxDepth < 0) {\n    return;\n  }\n  if (includeDirs && include(root, exts, match, skip)) {\n    yield createWalkEntrySync(root);\n  }\n  if (maxDepth < 1 || !include(root, undefined, undefined, skip)) {\n    return;\n  }\n  const entries = Deno.readDirSync(root);\n  for (const entry of entries){\n    let path = join(root, entry.name);\n    let { isSymlink, isDirectory } = entry;\n    if (isSymlink) {\n      if (!followSymlinks) {\n        if (includeSymlinks && include(path, exts, match, skip)) {\n          yield {\n            path,\n            ...entry\n          };\n        }\n        continue;\n      }\n      const realPath = Deno.realPathSync(path);\n      if (canonicalize) {\n        path = realPath;\n      }\n      // Caveat emptor: don't assume |path| is not a symlink. realpath()\n      // resolves symlinks but another process can replace the file system\n      // entity with a different type of entity before we call lstat().\n      ({ isSymlink, isDirectory } = Deno.lstatSync(realPath));\n    }\n    if (isSymlink || isDirectory) {\n      const opts = {\n        maxDepth: maxDepth - 1,\n        includeFiles,\n        includeDirs,\n        includeSymlinks,\n        followSymlinks\n      };\n      if (exts !== undefined) {\n        opts.exts = exts;\n      }\n      if (match !== undefined) {\n        opts.match = match;\n      }\n      if (skip !== undefined) {\n        opts.skip = skip;\n      }\n      yield* walkSync(path, opts);\n    } else if (includeFiles && include(path, exts, match, skip)) {\n      yield {\n        path,\n        ...entry\n      };\n    }\n  }\n}"
    }
  },
  {
    "jsr:@std/frontMatter": {
      "extractJson": "function extract(text) {\n  return extractAndParse(text, EXTRACT_JSON_REGEXP, JSON.parse);\n}",
      "extractToml": "function extract(text) {\n  return extractAndParse(text, EXTRACT_TOML_REGEXP, parse);\n}",
      "extractYaml": "function extract(text) {\n  return extractAndParse(text, EXTRACT_YAML_REGEXP, (s)=>parse(s));\n}",
      "test": "function test(str, formats) {\n  if (!formats) formats = [\n    ...EXTRACT_REGEXP_MAP.keys()\n  ];\n  for (const format of formats){\n    const regexp = EXTRACT_REGEXP_MAP.get(format);\n    if (!regexp) {\n      throw new TypeError(`Unable to test for ${format} front matter format`);\n    }\n    const match = regexp.exec(str);\n    if (match?.index === 0) {\n      return true;\n    }\n  }\n  return false;\n}"
    }
  },
  {
    "jsr:@std/expect": {
      "expect": "function expect(value, customMessage) {\n  let isNot = false;\n  let isPromised = false;\n  const self = new Proxy({}, {\n    get (_, name) {\n      if (name === \"not\") {\n        isNot = !isNot;\n        return self;\n      }\n      if (name === \"resolves\") {\n        if (!isPromiseLike(value)) {\n          throw new AssertionError(\"Expected value must be PromiseLike\");\n        }\n        isPromised = true;\n        return self;\n      }\n      if (name === \"rejects\") {\n        if (!isPromiseLike(value)) {\n          throw new AssertionError(\"Expected value must be a PromiseLike\");\n        }\n        value = value.then((value)=>{\n          throw new AssertionError(`Promise did not reject: resolved to ${value}`);\n        }, (err)=>err);\n        isPromised = true;\n        return self;\n      }\n      const extendMatchers = getExtendMatchers();\n      const allMatchers = {\n        ...extendMatchers,\n        ...matchers\n      };\n      const matcher = allMatchers[name];\n      if (!matcher) {\n        throw new TypeError(typeof name === \"string\" ? `matcher not found: ${name}` : \"matcher not found\");\n      }\n      return (...args)=>{\n        function applyMatcher(value, args) {\n          const context = {\n            value,\n            equal,\n            isNot: false,\n            customMessage,\n            customTesters: getCustomEqualityTesters()\n          };\n          if (isNot) {\n            context.isNot = true;\n          }\n          if (name in extendMatchers) {\n            const result = matcher(context, ...args);\n            if (context.isNot) {\n              if (result.pass) {\n                throw new AssertionError(result.message());\n              }\n            } else if (!result.pass) {\n              throw new AssertionError(result.message());\n            }\n          } else {\n            matcher(context, ...args);\n          }\n          emitAssertionTrigger();\n        }\n        return isPromised ? value.then((value)=>applyMatcher(value, args)) : applyMatcher(value, args);\n      };\n    }\n  });\n  return self;\n}",
      "fn": "function fn(...stubs) {\n  const calls = [];\n  const f = (...args)=>{\n    const stub = stubs.length === 1 ? stubs[0] : stubs[calls.length];\n    try {\n      const returned = stub ? stub(...args) : undefined;\n      calls.push({\n        args,\n        returned,\n        timestamp: Date.now(),\n        returns: true,\n        throws: false\n      });\n      return returned;\n    } catch (err) {\n      calls.push({\n        args,\n        timestamp: Date.now(),\n        returns: false,\n        thrown: err,\n        throws: true\n      });\n      throw err;\n    }\n  };\n  Object.defineProperty(f, MOCK_SYMBOL, {\n    value: {\n      calls\n    },\n    writable: false\n  });\n  return f;\n}"
    }
  },
  {
    "jsr:@std/encoding": {
      "MaxUint64": "18446744073709551615",
      "MaxVarintLen32": "5",
      "MaxVarintLen64": "10",
      "decodeAscii85": "function decodeAscii85(ascii85, options = {}) {\n  const { standard = \"Adobe\" } = options;\n  // translate all encodings to most basic adobe/btoa one and decompress some special characters (\"z\" and \"y\")\n  switch(standard){\n    case \"Adobe\":\n      ascii85 = ascii85.replaceAll(/(<~|~>)/g, \"\").replaceAll(\"z\", \"!!!!!\");\n      break;\n    case \"btoa\":\n      ascii85 = ascii85.replaceAll(/(xbtoa Begin|xbtoa End|\\n)/g, \"\").replaceAll(\"z\", \"!!!!!\").replaceAll(\"y\", \"+<VdL\");\n      break;\n    case \"RFC 1924\":\n      ascii85 = ascii85.replaceAll(/./g, (match)=>String.fromCharCode(rfc1924.indexOf(match) + 33));\n      break;\n    case \"Z85\":\n      ascii85 = ascii85.replaceAll(/./g, (match)=>String.fromCharCode(Z85.indexOf(match) + 33));\n      break;\n  }\n  // remove all invalid characters\n  ascii85 = ascii85.replaceAll(/[^!-u]/g, \"\");\n  const len = ascii85.length;\n  const output = new Uint8Array(len + 4 - len % 4);\n  const view = new DataView(output.buffer);\n  let v = 0;\n  let n = 0;\n  let max = 0;\n  for(let i = 0; i < len;){\n    for(max += 5; i < max; i++){\n      v = v * 85 + (i < len ? ascii85.charCodeAt(i) : 117) - 33;\n    }\n    view.setUint32(n, v);\n    v = 0;\n    n += 4;\n  }\n  return output.slice(0, Math.trunc(len * 0.8));\n}",
      "decodeBase32": "function decodeBase32(b32) {\n  return decode(b32, lookup);\n}",
      "decodeBase58": "function decodeBase58(b58) {\n  const splitInput = b58.trim().split(\"\");\n  let length = 0;\n  let ones = 0;\n  // Counting leading ones\n  let index = 0;\n  while(splitInput[index] === \"1\"){\n    ones++;\n    index++;\n  }\n  const notZeroData = splitInput.slice(index);\n  const size = Math.round(b58.length * 733 / 1000 + 1);\n  const output = [];\n  notZeroData.forEach((char, idx)=>{\n    let carry = mapBase58[char];\n    let i = 0;\n    if (carry === undefined) {\n      throw new TypeError(`Invalid base58 char at index ${idx} with value ${char}`);\n    }\n    for(let reverseIterator = size - 1; (carry > 0 || i < length) && reverseIterator !== -1; reverseIterator--, i++){\n      carry += 58 * (output[reverseIterator] ?? 0);\n      output[reverseIterator] = Math.round(carry % 256);\n      carry = Math.floor(carry / 256);\n    }\n    length = i;\n  });\n  const validOutput = output.filter((item)=>item !== undefined);\n  if (ones > 0) {\n    const onesResult = Array.from({\n      length: ones\n    }).fill(0, 0, ones);\n    return new Uint8Array([\n      ...onesResult,\n      ...validOutput\n    ]);\n  }\n  return new Uint8Array(validOutput);\n}",
      "decodeBase64": "function decodeBase64(b64) {\n  const binString = atob(b64);\n  const size = binString.length;\n  const bytes = new Uint8Array(size);\n  for(let i = 0; i < size; i++){\n    bytes[i] = binString.charCodeAt(i);\n  }\n  return bytes;\n}",
      "decodeBase64Url": "function decodeBase64Url(b64url) {\n  return base64.decodeBase64(convertBase64urlToBase64(b64url));\n}",
      "decodeHex": "function decodeHex(src) {\n  const u8 = textEncoder.encode(src);\n  const dst = new Uint8Array(u8.length / 2);\n  for(let i = 0; i < dst.length; i++){\n    const a = fromHexChar(u8[i * 2]);\n    const b = fromHexChar(u8[i * 2 + 1]);\n    dst[i] = a << 4 | b;\n  }\n  if (u8.length % 2 === 1) {\n    // Check for invalid char before reporting bad length,\n    // since the invalid char (if present) is an earlier problem.\n    fromHexChar(u8[dst.length * 2]);\n    throw errLength(u8.length);\n  }\n  return dst;\n}",
      "decodeVarint": "function decodeVarint(buf, offset = 0) {\n  // Clear the last result from the Two's complement view\n  U64_VIEW[0] = 0n;\n  // Setup the initiat state of the function\n  let intermediate = 0;\n  let position = 0;\n  let i = offset;\n  // If the buffer is empty Throw\n  if (buf.length === 0) throw new RangeError(\"Cannot read empty buffer\");\n  let byte;\n  do {\n    // Get a single byte from the buffer\n    byte = buf[i];\n    // 1. Take the lower 7 bits of the byte.\n    // 2. Shift the bits into the correct position.\n    // 3. Bitwise OR it with the intermediate value\n    // QUIRK: in the 5th (and 10th) iteration of this loop it will overflow on the shift.\n    // This causes only the lower 4 bits to be shifted into place and removing the upper 3 bits\n    intermediate |= (byte & 0b01111111) << position;\n    // If position is 28\n    // it means that this iteration needs to be written the the two's complement view\n    // This only happens once due to the `-4` in this branch\n    if (position === 28) {\n      // Write to the view\n      U32_VIEW[0] = intermediate;\n      // set `intermediate` to the remaining 3 bits\n      // We only want the remaining three bits because the other 4 have been \"consumed\" on line 21\n      intermediate = (byte & 0b01110000) >>> 4;\n      // set `position` to -4 because later 7 will be added, making it 3\n      position = -4;\n    }\n    // Increment the shift position by 7\n    position += 7;\n    // Increment the iterator by 1\n    i++;\n  // Keep going while there is a continuation bit\n  }while ((byte & 0b10000000) === 0b10000000)\n  // subtract the initial offset from `i` to get the bytes read\n  const nRead = i - offset;\n  // If 10 bytes have been read and intermediate has overflown\n  // it means that the varint is malformed\n  // If 11 bytes have been read it means that the varint is malformed\n  // If `i` is bigger than the buffer it means we overread the buffer and the varint is malformed\n  if (nRead === 10 && intermediate > -1 || nRead === 11 || i > buf.length) {\n    throw new RangeError(\"Cannot decode the varint input: Malformed or overflow varint\");\n  }\n  // Write the intermediate value to the \"empty\" slot\n  // if the first slot is taken. Take the second slot\n  U32_VIEW[Number(nRead > 4)] = intermediate;\n  return [\n    U64_VIEW[0],\n    i\n  ];\n}",
      "decodeVarint32": "function decodeVarint32(buf, offset = 0) {\n  let shift = 0;\n  let decoded = 0;\n  for(let i = offset; i <= Math.min(buf.length, offset + MaxVarintLen32); i += 1, shift += SHIFT){\n    const byte = buf[i];\n    decoded += (byte & REST) * Math.pow(2, shift);\n    if (!(byte & MSB)) return [\n      decoded,\n      i + 1\n    ];\n  }\n  throw new RangeError(\"Cannot decode the varint input: Malformed or overflow varint\");\n}",
      "encodeAscii85": "function encodeAscii85(data, options = {}) {\n  let uint8 = validateBinaryLike(data);\n  const { standard = \"Adobe\" } = options;\n  let output = [];\n  let v;\n  let n = 0;\n  let difference = 0;\n  if (uint8.length % 4 !== 0) {\n    const tmp = uint8;\n    difference = 4 - tmp.length % 4;\n    uint8 = new Uint8Array(tmp.length + difference);\n    uint8.set(tmp);\n  }\n  const view = new DataView(uint8.buffer, uint8.byteOffset, uint8.byteLength);\n  for(let i = 0; i < uint8.length; i += 4){\n    v = view.getUint32(i);\n    // Adobe and btoa standards compress 4 zeroes to single \"z\" character\n    if ((standard === \"Adobe\" || standard === \"btoa\") && v === 0 && i < uint8.length - difference - 3) {\n      output[n++] = \"z\";\n      continue;\n    }\n    // btoa compresses 4 spaces - that is, bytes equal to 32 - into single \"y\" character\n    if (standard === \"btoa\" && v === 538976288) {\n      output[n++] = \"y\";\n      continue;\n    }\n    for(let j = 4; j >= 0; j--){\n      output[n + j] = String.fromCharCode(v % 85 + 33);\n      v = Math.trunc(v / 85);\n    }\n    n += 5;\n  }\n  switch(standard){\n    case \"Adobe\":\n      if (options?.delimiter) {\n        return `<~${output.slice(0, output.length - difference).join(\"\")}~>`;\n      }\n      break;\n    case \"btoa\":\n      if (options?.delimiter) {\n        return `xbtoa Begin\\n${output.slice(0, output.length - difference).join(\"\")}\\nxbtoa End`;\n      }\n      break;\n    case \"RFC 1924\":\n      output = output.map((val)=>rfc1924[val.charCodeAt(0) - 33]);\n      break;\n    case \"Z85\":\n      output = output.map((val)=>Z85[val.charCodeAt(0) - 33]);\n      break;\n  }\n  return output.slice(0, output.length - difference).join(\"\");\n}",
      "encodeBase32": "function encodeBase32(data) {\n  return encode(data, lookup);\n}",
      "encodeBase58": "function encodeBase58(data) {\n  const uint8tData = validateBinaryLike(data);\n  let length = 0;\n  let zeroes = 0;\n  // Counting leading zeroes\n  let index = 0;\n  while(uint8tData[index] === 0){\n    zeroes++;\n    index++;\n  }\n  const notZeroUint8Data = uint8tData.slice(index);\n  const size = Math.round(uint8tData.length * 138 / 100 + 1);\n  const b58Encoding = [];\n  notZeroUint8Data.forEach((byte)=>{\n    let i = 0;\n    let carry = byte;\n    for(let reverseIterator = size - 1; (carry > 0 || i < length) && reverseIterator !== -1; reverseIterator--, i++){\n      carry += (b58Encoding[reverseIterator] ?? 0) * 256;\n      b58Encoding[reverseIterator] = Math.round(carry % 58);\n      carry = Math.floor(carry / 58);\n    }\n    length = i;\n  });\n  const strResult = Array.from({\n    length: b58Encoding.length + zeroes\n  });\n  if (zeroes > 0) {\n    strResult.fill(\"1\", 0, zeroes);\n  }\n  b58Encoding.forEach((byteValue)=>strResult.push(base58alphabet[byteValue]));\n  return strResult.join(\"\");\n}",
      "encodeBase64": "function encodeBase64(data) {\n  // CREDIT: https://gist.github.com/enepomnyaschih/72c423f727d395eeaa09697058238727\n  const uint8 = validateBinaryLike(data);\n  let result = \"\";\n  let i;\n  const l = uint8.length;\n  for(i = 2; i < l; i += 3){\n    result += base64abc[uint8[i - 2] >> 2];\n    result += base64abc[(uint8[i - 2] & 0x03) << 4 | uint8[i - 1] >> 4];\n    result += base64abc[(uint8[i - 1] & 0x0f) << 2 | uint8[i] >> 6];\n    result += base64abc[uint8[i] & 0x3f];\n  }\n  if (i === l + 1) {\n    // 1 octet yet to write\n    result += base64abc[uint8[i - 2] >> 2];\n    result += base64abc[(uint8[i - 2] & 0x03) << 4];\n    result += \"==\";\n  }\n  if (i === l) {\n    // 2 octets yet to write\n    result += base64abc[uint8[i - 2] >> 2];\n    result += base64abc[(uint8[i - 2] & 0x03) << 4 | uint8[i - 1] >> 4];\n    result += base64abc[(uint8[i - 1] & 0x0f) << 2];\n    result += \"=\";\n  }\n  return result;\n}",
      "encodeBase64Url": "function encodeBase64Url(data) {\n  return convertBase64ToBase64url(base64.encodeBase64(data));\n}",
      "encodeHex": "function encodeHex(src) {\n  const u8 = validateBinaryLike(src);\n  const dst = new Uint8Array(u8.length * 2);\n  for(let i = 0; i < u8.length; i++){\n    const v = u8[i];\n    dst[i * 2] = hexTable[v >> 4];\n    dst[i * 2 + 1] = hexTable[v & 0x0f];\n  }\n  return textDecoder.decode(dst);\n}",
      "encodeVarint": "function encodeVarint(num, buf = new Uint8Array(MaxVarintLen64), offset = 0) {\n  num = BigInt(num);\n  if (num < 0n) {\n    throw new RangeError(`Cannot encode the input into varint as it should be non-negative integer: received ${num}`);\n  }\n  for(let i = offset; i <= Math.min(buf.length, MaxVarintLen64); i += 1){\n    if (num < MSBN) {\n      buf[i] = Number(num);\n      i += 1;\n      return [\n        buf.slice(offset, i),\n        i\n      ];\n    }\n    buf[i] = Number(num & 0xFFn | MSBN);\n    num >>= SHIFTN;\n  }\n  throw new RangeError(`Cannot encode the input ${num} into varint as it overflows uint64`);\n}"
    }
  },
  {
    "jsr:@std/dotenv": {
      "load": "async function load(options = {}) {\n  const { envPath = \".env\", export: _export = false } = options;\n  const conf = envPath ? await parseFile(envPath) : {};\n  if (_export) {\n    for (const [key, value] of Object.entries(conf)){\n      if (Deno.env.get(key) !== undefined) continue;\n      Deno.env.set(key, value);\n    }\n  }\n  return conf;\n}",
      "loadSync": "function loadSync(options = {}) {\n  const { envPath = \".env\", export: _export = false } = options;\n  const conf = envPath ? parseFileSync(envPath) : {};\n  if (_export) {\n    for (const [key, value] of Object.entries(conf)){\n      if (Deno.env.get(key) !== undefined) continue;\n      Deno.env.set(key, value);\n    }\n  }\n  return conf;\n}",
      "parse": "function parse(text) {\n  const env = {};\n  let match;\n  const keysForExpandCheck = [];\n  while((match = RE_KEY_VALUE.exec(text)) !== null){\n    const { key, interpolated, notInterpolated, unquoted } = match?.groups;\n    if (!RE_VALID_KEY.test(key)) {\n      console.warn(`Ignored the key \"${key}\" as it is not a valid identifier: The key need to match the pattern /^[a-zA-Z_][a-zA-Z0-9_]*$/.`);\n      continue;\n    }\n    if (unquoted) {\n      keysForExpandCheck.push(key);\n    }\n    env[key] = typeof notInterpolated === \"string\" ? notInterpolated : typeof interpolated === \"string\" ? expandCharacters(interpolated) : unquoted.trim();\n  }\n  //https://github.com/motdotla/dotenv-expand/blob/ed5fea5bf517a09fd743ce2c63150e88c8a5f6d1/lib/main.js#L23\n  const variablesMap = {\n    ...env\n  };\n  keysForExpandCheck.forEach((key)=>{\n    env[key] = expand(env[key], variablesMap);\n  });\n  return env;\n}",
      "stringify": "function stringify(object) {\n  const lines = [];\n  for (const [key, value] of Object.entries(object)){\n    let quote;\n    let escapedValue = value ?? \"\";\n    if (key.startsWith(\"#\")) {\n      console.warn(`key starts with a '#' indicates a comment and is ignored: '${key}'`);\n      continue;\n    } else if (escapedValue.includes(\"\\n\") || escapedValue.includes(\"'\")) {\n      // escape inner new lines\n      escapedValue = escapedValue.replaceAll(\"\\n\", \"\\\\n\");\n      quote = `\"`;\n    } else if (escapedValue.match(/\\W/)) {\n      quote = \"'\";\n    }\n    if (quote) {\n      // escape inner quotes\n      escapedValue = escapedValue.replaceAll(quote, `\\\\${quote}`);\n      escapedValue = `${quote}${escapedValue}${quote}`;\n    }\n    const line = `${key}=${escapedValue}`;\n    lines.push(line);\n  }\n  return lines.join(\"\\n\");\n}"
    }
  },
  {
    "jsr:@std/datetime": {
      "DAY": "86400000",
      "HOUR": "3600000",
      "MINUTE": "60000",
      "SECOND": "1000",
      "WEEK": "604800000",
      "dayOfYear": "function dayOfYear(date) {\n  // Values from 0 to 99 map to the years 1900 to 1999. All other values are the actual year. (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/Date)\n  // Using setFullYear as a workaround\n  const yearStart = new Date(date);\n  yearStart.setFullYear(date.getFullYear(), 0, 0);\n  const diff = date.getTime() - date.getTimezoneOffset() * 60 * 1000 - (yearStart.getTime() - yearStart.getTimezoneOffset() * 60 * 1000);\n  return Math.floor(diff / DAY);\n}",
      "dayOfYearUtc": "function dayOfYearUtc(date) {\n  // Values from 0 to 99 map to the years 1900 to 1999. All other values are the actual year. (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/Date)\n  // Using setUTCFullYear as a workaround\n  const yearStart = new Date(date);\n  yearStart.setUTCFullYear(date.getUTCFullYear(), 0, 0);\n  const diff = date.getTime() - yearStart.getTime();\n  return Math.floor(diff / DAY);\n}",
      "difference": "function difference(from, to, options) {\n  [from, to] = from < to ? [\n    from,\n    to\n  ] : [\n    to,\n    from\n  ];\n  const uniqueUnits = options?.units ? [\n    ...new Set(options?.units)\n  ] : [\n    \"milliseconds\",\n    \"seconds\",\n    \"minutes\",\n    \"hours\",\n    \"days\",\n    \"weeks\",\n    \"months\",\n    \"quarters\",\n    \"years\"\n  ];\n  const differenceInMs = Math.abs(from.getTime() - to.getTime());\n  const differences = {};\n  for (const uniqueUnit of uniqueUnits){\n    switch(uniqueUnit){\n      case \"milliseconds\":\n        differences.milliseconds = differenceInMs;\n        break;\n      case \"seconds\":\n        differences.seconds = Math.floor(differenceInMs / SECOND);\n        break;\n      case \"minutes\":\n        differences.minutes = Math.floor(differenceInMs / MINUTE);\n        break;\n      case \"hours\":\n        differences.hours = Math.floor(differenceInMs / HOUR);\n        break;\n      case \"days\":\n        differences.days = Math.floor(differenceInMs / DAY);\n        break;\n      case \"weeks\":\n        differences.weeks = Math.floor(differenceInMs / WEEK);\n        break;\n      case \"months\":\n        differences.months = calculateMonthsDifference(from, to);\n        break;\n      case \"quarters\":\n        differences.quarters = Math.floor(differences.months !== undefined && differences.months / 3 || calculateMonthsDifference(from, to) / 3);\n        break;\n      case \"years\":\n        differences.years = Math.floor(differences.months !== undefined && differences.months / 12 || calculateMonthsDifference(from, to) / 12);\n        break;\n    }\n  }\n  return differences;\n}",
      "format": "function format(date, formatString, options = {}) {\n  const formatter = new DateTimeFormatter(formatString);\n  return formatter.format(date, options);\n}",
      "isLeap": "function isLeap(year) {\n  const yearNumber = year instanceof Date ? year.getFullYear() : year;\n  return isYearNumberALeapYear(yearNumber);\n}",
      "isUtcLeap": "function isUtcLeap(year) {\n  const yearNumber = year instanceof Date ? year.getUTCFullYear() : year;\n  return isYearNumberALeapYear(yearNumber);\n}",
      "parse": "function parse(dateString, formatString) {\n  const formatter = new DateTimeFormatter(formatString);\n  return formatter.parse(dateString);\n}",
      "weekOfYear": "function weekOfYear(date) {\n  const workingDate = new Date(Date.UTC(date.getFullYear(), date.getMonth(), date.getDate()));\n  const day = workingDate.getUTCDay();\n  const nearestThursday = workingDate.getUTCDate() + Day.Thu - (day === Day.Sun ? DAYS_PER_WEEK : day);\n  workingDate.setUTCDate(nearestThursday);\n  // Get first day of year\n  const yearStart = new Date(Date.UTC(workingDate.getUTCFullYear(), 0, 1));\n  // return the calculated full weeks to nearest Thursday\n  return Math.ceil((workingDate.getTime() - yearStart.getTime() + DAY) / WEEK);\n}"
    }
  },
  {
    "jsr:@std/dataStructures": {
      "BinaryHeap": "class BinaryHeap {\n  #data = [];\n  #compare;\n  /**\n   * Construct an empty binary heap.\n   *\n   * @param compare A custom comparison function to sort the values in the heap. By default, the values are sorted in descending order.\n   */ constructor(compare = descend){\n    if (typeof compare !== \"function\") {\n      throw new TypeError(\"Cannot construct a BinaryHeap: the 'compare' parameter is not a function, did you mean to call BinaryHeap.from?\");\n    }\n    this.#compare = compare;\n  }\n  /**\n   * Returns the underlying cloned array in arbitrary order without sorting.\n   *\n   * @example Getting the underlying array\n   * ```ts\n   * import { BinaryHeap } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const heap = BinaryHeap.from([4, 1, 3, 5, 2]);\n   *\n   * assertEquals(heap.toArray(), [ 5, 4, 3, 1, 2 ]);\n   * ```\n   *\n   * @returns An array containing the values in the binary heap.\n   */ toArray() {\n    return Array.from(this.#data);\n  }\n  static from(collection, options) {\n    let result;\n    let unmappedValues = [];\n    if (collection instanceof BinaryHeap) {\n      result = new BinaryHeap(options?.compare ?? collection.#compare);\n      if (options?.compare || options?.map) {\n        unmappedValues = collection.#data;\n      } else {\n        result.#data = Array.from(collection.#data);\n      }\n    } else {\n      result = options?.compare ? new BinaryHeap(options.compare) : new BinaryHeap();\n      unmappedValues = collection;\n    }\n    const values = options?.map ? Array.from(unmappedValues, options.map, options.thisArg) : unmappedValues;\n    result.push(...values);\n    return result;\n  }\n  /**\n   * The count of values stored in the binary heap.\n   *\n   * The complexity of this operation is O(1).\n   *\n   * @example Getting the length of the binary heap\n   * ```ts\n   * import { BinaryHeap } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const heap = BinaryHeap.from([4, 1, 3, 5, 2]);\n   *\n   * assertEquals(heap.length, 5);\n   * ```\n   *\n   * @returns The count of values stored in the binary heap.\n   */ get length() {\n    return this.#data.length;\n  }\n  /**\n   * Get the greatest value from the binary heap without removing it, or\n   * undefined if the heap is empty.\n   *\n   * The complexity of this operation is O(1).\n   *\n   * @example Getting the greatest value from the binary heap\n   * ```ts\n   * import { BinaryHeap } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const heap = BinaryHeap.from([4, 1, 3, 5, 2]);\n   *\n   * assertEquals(heap.peek(), 5);\n   * ```\n   *\n   * @example Getting the greatest value from an empty binary heap\n   * ```ts\n   * import { BinaryHeap } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const heap = new BinaryHeap<number>();\n   *\n   * assertEquals(heap.peek(), undefined);\n   * ```\n   *\n   * @returns The greatest value from the binary heap, or undefined if it is empty.\n   */ peek() {\n    return this.#data[0];\n  }\n  /**\n   * Remove the greatest value from the binary heap and return it, or return\n   * undefined if the heap is empty.\n   *\n   * @example Removing the greatest value from the binary heap\n   * ```ts\n   * import { BinaryHeap } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const heap = BinaryHeap.from([4, 1, 3, 5, 2]);\n   *\n   * assertEquals(heap.pop(), 5);\n   * assertEquals([...heap], [4, 3, 2, 1]);\n   * ```\n   *\n   * The complexity of this operation is on average and worst case O(log n),\n   * where n is the count of values stored in the binary heap.\n   *\n   * @example Removing the greatest value from an empty binary heap\n   * ```ts\n   * import { BinaryHeap } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const heap = new BinaryHeap<number>();\n   *\n   * assertEquals(heap.pop(), undefined);\n   * ```\n   *\n   * @returns The greatest value from the binary heap, or undefined if the heap is empty.\n   */ pop() {\n    const size = this.#data.length - 1;\n    swap(this.#data, 0, size);\n    let parent = 0;\n    let right = 2 * (parent + 1);\n    let left = right - 1;\n    while(left < size){\n      const greatestChild = right === size || this.#compare(this.#data[left], this.#data[right]) <= 0 ? left : right;\n      if (this.#compare(this.#data[greatestChild], this.#data[parent]) < 0) {\n        swap(this.#data, parent, greatestChild);\n        parent = greatestChild;\n      } else {\n        break;\n      }\n      right = 2 * (parent + 1);\n      left = right - 1;\n    }\n    return this.#data.pop();\n  }\n  /**\n   * Add one or more values to the binary heap, returning the new length of the\n   * heap.\n   *\n   * The complexity of this operation is O(1) on average and O(log n) in the\n   * worst case, where n is the count of values stored in the binary heap.\n   *\n   * @example Adding values to the binary heap\n   * ```ts\n   * import { BinaryHeap } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const heap = BinaryHeap.from([4, 1, 3, 2]);\n   * heap.push(5);\n   *\n   * assertEquals([...heap], [5, 4, 3, 2, 1]);\n   * ```\n   *\n   * @param values The values to add to the binary heap.\n   * @returns The new length of the binary heap.\n   */ push(...values) {\n    for (const value of values){\n      let index = this.#data.length;\n      let parent = getParentIndex(index);\n      this.#data.push(value);\n      while(index !== 0 && this.#compare(this.#data[index], this.#data[parent]) < 0){\n        swap(this.#data, parent, index);\n        index = parent;\n        parent = getParentIndex(index);\n      }\n    }\n    return this.#data.length;\n  }\n  /**\n   * Remove all values from the binary heap.\n   *\n   * @example Clearing the binary heap\n   * ```ts\n   * import { BinaryHeap } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const heap = BinaryHeap.from([4, 1, 3, 5, 2]);\n   * heap.clear();\n   *\n   * assertEquals([...heap], []);\n   * ```\n   */ clear() {\n    this.#data = [];\n  }\n  /**\n   * Check if the binary heap is empty.\n   *\n   * @example Checking if the binary heap is empty\n   * ```ts\n   * import { BinaryHeap } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const heap = new BinaryHeap<number>();\n   *\n   * assertEquals(heap.isEmpty(), true);\n   *\n   * heap.push(42);\n   *\n   * assertEquals(heap.isEmpty(), false);\n   * ```\n   *\n   * @returns true if the binary heap is empty, otherwise false.\n   */ isEmpty() {\n    return this.#data.length === 0;\n  }\n  /**\n   * Create an iterator that retrieves values from the binary heap in order\n   * from greatest to least. The binary heap is drained in the process.\n   *\n   * To avoid draining the binary heap, create a copy using\n   * {@link BinaryHeap.from} and then call {@link BinaryHeap.prototype.drain}\n   * on the copy.\n   *\n   * @example Draining the binary heap\n   * ```ts\n   * import { BinaryHeap } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const heap = BinaryHeap.from([4, 1, 3, 5, 2]);\n   *\n   * assertEquals([...heap.drain()], [ 5, 4, 3, 2, 1 ]);\n   * assertEquals([...heap.drain()], []);\n   * ```\n   *\n   * @returns An iterator for retrieving and removing values from the binary heap.\n   */ *drain() {\n    while(!this.isEmpty()){\n      yield this.pop();\n    }\n  }\n  /**\n   * Create an iterator that retrieves values from the binary heap in order\n   * from greatest to least. The binary heap is drained in the process.\n   *\n   * @example Getting an iterator for the binary heap\n   * ```ts\n   * import { BinaryHeap } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const heap = BinaryHeap.from([4, 1, 3, 5, 2]);\n   *\n   * assertEquals([...heap], [ 5, 4, 3, 2, 1 ]);\n   * assertEquals([...heap], []);\n   * ```\n   *\n   * @returns An iterator for retrieving and removing values from the binary heap.\n   */ *[_computedKey]() {\n    yield* this.drain();\n  }\n}",
      "BinarySearchTree": "class BinarySearchTree {\n  #root = null;\n  #size = 0;\n  #compare;\n  /**\n   * Construct an empty binary search tree.\n   *\n   * To create a binary search tree from an array like, an iterable object, or an\n   * existing binary search tree, use the {@link BinarySearchTree.from} method.\n   *\n   * @param compare A custom comparison function to sort the values in the tree.\n   * By default, the values are sorted in ascending order.\n   */ constructor(compare = ascend){\n    if (typeof compare !== \"function\") {\n      throw new TypeError(\"Cannot construct a BinarySearchTree: the 'compare' parameter is not a function, did you mean to call BinarySearchTree.from?\");\n    }\n    this.#compare = compare;\n  }\n  static{\n    internals.getRoot = (tree)=>tree.#root;\n    internals.setRoot = (tree, node)=>{\n      tree.#root = node;\n    };\n    internals.getCompare = (tree)=>tree.#compare;\n    internals.findNode = (tree, value)=>tree.#findNode(value);\n    internals.rotateNode = (tree, node, direction)=>tree.#rotateNode(node, direction);\n    internals.insertNode = (tree, Node, value)=>tree.#insertNode(Node, value);\n    internals.removeNode = (tree, node)=>tree.#removeNode(node);\n  }\n  static from(collection, options) {\n    let result;\n    let unmappedValues = [];\n    if (collection instanceof BinarySearchTree) {\n      result = new BinarySearchTree(options?.compare ?? collection.#compare);\n      if (options?.compare || options?.map) {\n        unmappedValues = collection;\n      } else {\n        const nodes = [];\n        if (collection.#root) {\n          result.#root = BinarySearchNode.from(collection.#root);\n          nodes.push(result.#root);\n        }\n        while(nodes.length){\n          const node = nodes.pop();\n          const left = node.left ? BinarySearchNode.from(node.left) : null;\n          const right = node.right ? BinarySearchNode.from(node.right) : null;\n          if (left) {\n            left.parent = node;\n            nodes.push(left);\n          }\n          if (right) {\n            right.parent = node;\n            nodes.push(right);\n          }\n        }\n      }\n    } else {\n      result = options?.compare ? new BinarySearchTree(options.compare) : new BinarySearchTree();\n      unmappedValues = collection;\n    }\n    const values = options?.map ? Array.from(unmappedValues, options.map, options.thisArg) : unmappedValues;\n    for (const value of values)result.insert(value);\n    return result;\n  }\n  /**\n   * The count of values stored in the binary search tree.\n   *\n   * The complexity of this operation is O(1).\n   *\n   * @example Getting the size of the tree\n   * ```ts no-assert\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = BinarySearchTree.from<number>([42, 43, 41]);\n   *\n   * assertEquals(tree.size, 3);\n   * ```\n   *\n   * @returns The count of values stored in the binary search tree.\n   */ get size() {\n    return this.#size;\n  }\n  #findNode(value) {\n    let node = this.#root;\n    while(node){\n      const order = this.#compare(value, node.value);\n      if (order === 0) break;\n      const direction = order < 0 ? \"left\" : \"right\";\n      node = node[direction];\n    }\n    return node;\n  }\n  #rotateNode(node, direction) {\n    const replacementDirection = direction === \"left\" ? \"right\" : \"left\";\n    if (!node[replacementDirection]) {\n      throw new TypeError(`Cannot rotate ${direction} without ${replacementDirection} child`);\n    }\n    const replacement = node[replacementDirection];\n    node[replacementDirection] = replacement[direction] ?? null;\n    if (replacement[direction]) replacement[direction].parent = node;\n    replacement.parent = node.parent;\n    if (node.parent) {\n      const parentDirection = node === node.parent[direction] ? direction : replacementDirection;\n      node.parent[parentDirection] = replacement;\n    } else {\n      this.#root = replacement;\n    }\n    replacement[direction] = node;\n    node.parent = replacement;\n  }\n  #insertNode(Node, value) {\n    if (!this.#root) {\n      this.#root = new Node(null, value);\n      this.#size++;\n      return this.#root;\n    } else {\n      let node = this.#root;\n      while(true){\n        const order = this.#compare(value, node.value);\n        if (order === 0) break;\n        const direction = order < 0 ? \"left\" : \"right\";\n        if (node[direction]) {\n          node = node[direction];\n        } else {\n          node[direction] = new Node(node, value);\n          this.#size++;\n          return node[direction];\n        }\n      }\n    }\n    return null;\n  }\n  /** Removes the given node, and returns the node that was physically removed from the tree. */ #removeNode(node) {\n    /**\n     * The node to physically remove from the tree.\n     * Guaranteed to have at most one child.\n     */ const flaggedNode = !node.left || !node.right ? node : node.findSuccessorNode();\n    /** Replaces the flagged node. */ const replacementNode = flaggedNode.left ?? flaggedNode.right;\n    if (replacementNode) replacementNode.parent = flaggedNode.parent;\n    if (!flaggedNode.parent) {\n      this.#root = replacementNode;\n    } else {\n      flaggedNode.parent[flaggedNode.directionFromParent()] = replacementNode;\n    }\n    if (flaggedNode !== node) {\n      /** Swaps values, in case value of the removed node is still needed by consumer. */ const swapValue = node.value;\n      node.value = flaggedNode.value;\n      flaggedNode.value = swapValue;\n    }\n    this.#size--;\n    return flaggedNode;\n  }\n  /**\n   * Add a value to the binary search tree if it does not already exist in the\n   * tree.\n   *\n   * The complexity of this operation is on average O(log n), where n is the\n   * number of values in the tree. In the worst case, the complexity is O(n).\n   *\n   * @example Inserting values into the tree\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = new BinarySearchTree<number>();\n   *\n   * assertEquals(tree.insert(42), true);\n   * assertEquals(tree.insert(42), false);\n   * ```\n   *\n   * @param value The value to insert into the binary search tree.\n   * @returns `true` if the value was inserted, `false` if the value already exists in the tree.\n   */ insert(value) {\n    return !!this.#insertNode(BinarySearchNode, value);\n  }\n  /**\n   * Remove a value from the binary search tree if it exists in the tree.\n   *\n   * The complexity of this operation is on average O(log n), where n is the\n   * number of values in the tree. In the worst case, the complexity is O(n).\n   *\n   * @example Removing values from the tree\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = BinarySearchTree.from<number>([42]);\n   *\n   * assertEquals(tree.remove(42), true);\n   * assertEquals(tree.remove(42), false);\n   * ```\n   *\n   * @param value The value to remove from the binary search tree.\n   * @returns `true` if the value was found and removed, `false` if the value was not found in the tree.\n   */ remove(value) {\n    const node = this.#findNode(value);\n    if (node) this.#removeNode(node);\n    return node !== null;\n  }\n  /**\n   * Check if a value exists in the binary search tree.\n   *\n   * The complexity of this operation depends on the underlying structure of the\n   * tree. Refer to the documentation of the structure itself for more details.\n   *\n   * @example Finding values in the tree\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = BinarySearchTree.from<number>([42]);\n   *\n   * assertEquals(tree.find(42), 42);\n   * assertEquals(tree.find(43), null);\n   * ```\n   *\n   * @param value The value to search for in the binary search tree.\n   * @returns The value if it was found, or null if not found.\n   */ find(value) {\n    return this.#findNode(value)?.value ?? null;\n  }\n  /**\n   * Retrieve the lowest (left most) value in the binary search tree, or null if\n   * the tree is empty.\n   *\n   * The complexity of this operation depends on the underlying structure of the\n   * tree. Refer to the documentation of the structure itself for more details.\n   *\n   * @example Finding the minimum value in the tree\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = BinarySearchTree.from<number>([42, 43, 41]);\n   *\n   * assertEquals(tree.min(), 41);\n   * ```\n   *\n   * @returns The minimum value in the binary search tree, or null if the tree is empty.\n   */ min() {\n    return this.#root ? this.#root.findMinNode().value : null;\n  }\n  /**\n   * Retrieve the highest (right most) value in the binary search tree, or null\n   * if the tree is empty.\n   *\n   * The complexity of this operation depends on the underlying structure of the\n   * tree. Refer to the documentation of the structure itself for more details.\n   *\n   * @example Finding the maximum value in the tree\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = BinarySearchTree.from<number>([42, 43, 41]);\n   *\n   * assertEquals(tree.max(), 43);\n   * ```\n   *\n   * @returns The maximum value in the binary search tree, or null if the tree is empty.\n   */ max() {\n    return this.#root ? this.#root.findMaxNode().value : null;\n  }\n  /**\n   * Remove all values from the binary search tree.\n   *\n   * The complexity of this operation is O(1).\n   *\n   * @example Clearing the tree\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = BinarySearchTree.from<number>([42, 43, 41]);\n   * tree.clear();\n   *\n   * assertEquals(tree.size, 0);\n   * assertEquals(tree.find(42), null);\n   * ```\n   */ clear() {\n    this.#root = null;\n    this.#size = 0;\n  }\n  /**\n   * Check if the binary search tree is empty.\n   *\n   * The complexity of this operation is O(1).\n   *\n   * @example Checking if the tree is empty\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = new BinarySearchTree<number>();\n   *\n   * assertEquals(tree.isEmpty(), true);\n   *\n   * tree.insert(42);\n   *\n   * assertEquals(tree.isEmpty(), false);\n   * ```\n   *\n   * @returns `true` if the binary search tree is empty, `false` otherwise.\n   */ isEmpty() {\n    return this.size === 0;\n  }\n  /**\n   * Create an iterator over this tree that traverses the tree in-order (LNR,\n   * Left-Node-Right).\n   *\n   * @example Using the in-order LNR iterator\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = BinarySearchTree.from([4, 1, 2, 5, 3]);\n   *\n   * assertEquals([...tree.lnrValues()], [1, 2, 3, 4, 5]);\n   * ```\n   *\n   * @returns An iterator that traverses the tree in-order (LNR).\n   */ *lnrValues() {\n    const nodes = [];\n    let node = this.#root;\n    while(nodes.length || node){\n      if (node) {\n        nodes.push(node);\n        node = node.left;\n      } else {\n        node = nodes.pop();\n        yield node.value;\n        node = node.right;\n      }\n    }\n  }\n  /**\n   * Create an iterator over this tree that traverses the tree in reverse\n   * in-order (RNL, Right-Node-Left).\n   *\n   * @example Using the reverse in-order RNL iterator\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = BinarySearchTree.from([4, 1, 2, 5, 3]);\n   * [...tree.rnlValues()] // 5, 4, 3, 2, 1\n   * ```\n   *\n   * @returns An iterator that traverses the tree in reverse in-order (RNL).\n   */ *rnlValues() {\n    const nodes = [];\n    let node = this.#root;\n    while(nodes.length || node){\n      if (node) {\n        nodes.push(node);\n        node = node.right;\n      } else {\n        node = nodes.pop();\n        yield node.value;\n        node = node.left;\n      }\n    }\n  }\n  /**\n   * Create an iterator over this tree that traverses the tree in pre-order (NLR,\n   * Node-Left-Right).\n   *\n   * @example Using the pre-order NLR iterator\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = BinarySearchTree.from([4, 1, 2, 5, 3]);\n   *\n   * assertEquals([...tree.nlrValues()], [4, 1, 2, 3, 5]);\n   * ```\n   *\n   * @returns An iterator that traverses the tree in pre-order (NLR).\n   */ *nlrValues() {\n    const nodes = [];\n    if (this.#root) nodes.push(this.#root);\n    while(nodes.length){\n      const node = nodes.pop();\n      yield node.value;\n      if (node.right) nodes.push(node.right);\n      if (node.left) nodes.push(node.left);\n    }\n  }\n  /**\n   * Create an iterator over this tree that traverses the tree in post-order (LRN,\n   * Left-Right-Node).\n   *\n   * @example Using the post-order LRN iterator\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = BinarySearchTree.from([4, 1, 2, 5, 3]);\n   *\n   * assertEquals([...tree.lrnValues()], [3, 2, 1, 5, 4]);\n   * ```\n   *\n   * @returns An iterator that traverses the tree in post-order (LRN).\n   */ *lrnValues() {\n    const nodes = [];\n    let node = this.#root;\n    let lastNodeVisited = null;\n    while(nodes.length || node){\n      if (node) {\n        nodes.push(node);\n        node = node.left;\n      } else {\n        const lastNode = nodes.at(-1);\n        if (lastNode.right && lastNode.right !== lastNodeVisited) {\n          node = lastNode.right;\n        } else {\n          yield lastNode.value;\n          lastNodeVisited = nodes.pop();\n        }\n      }\n    }\n  }\n  /**\n   * Create an iterator over this tree that traverses the tree in level-order (BFS,\n   * Breadth-First Search).\n   *\n   * @example Using the level-order BFS iterator\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = BinarySearchTree.from([4, 1, 2, 5, 3]);\n   *\n   * assertEquals([...tree.lvlValues()], [4, 1, 5, 2, 3]);\n   * ```\n   *\n   * @returns An iterator that traverses the tree in level-order (BFS).\n   */ *lvlValues() {\n    const children = [];\n    let cursor = this.#root;\n    while(cursor){\n      yield cursor.value;\n      if (cursor.left) children.push(cursor.left);\n      if (cursor.right) children.push(cursor.right);\n      cursor = children.shift() ?? null;\n    }\n  }\n  /**\n   * Create an iterator over this tree that traverses the tree in-order (LNR,\n   * Left-Node-Right).\n   *\n   * @example Using the in-order iterator\n   * ```ts\n   * import { BinarySearchTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = BinarySearchTree.from([4, 1, 2, 5, 3]);\n   *\n   * assertEquals([...tree], [1, 2, 3, 4, 5]);\n   * ```\n   *\n   * See {@link BinarySearchTree.prototype.lnrValues}.\n   *\n   * @returns An iterator that traverses the tree in-order (LNR).\n   */ *[_computedKey]() {\n    yield* this.lnrValues();\n  }\n}",
      "RedBlackTree": "class RedBlackTree extends BinarySearchTree {\n  /**\n   * Construct an empty red-black tree.\n   *\n   * @param compare A custom comparison function for the values. The default comparison function sorts by ascending order.\n   */ constructor(compare = ascend){\n    if (typeof compare !== \"function\") {\n      throw new TypeError(\"Cannot construct a RedBlackTree: the 'compare' parameter is not a function, did you mean to call RedBlackTree.from?\");\n    }\n    super(compare);\n  }\n  static from(collection, options) {\n    let result;\n    let unmappedValues = [];\n    if (collection instanceof RedBlackTree) {\n      result = new RedBlackTree(options?.compare ?? getCompare(collection));\n      if (options?.compare || options?.map) {\n        unmappedValues = collection;\n      } else {\n        const nodes = [];\n        const root = getRoot(collection);\n        if (root) {\n          setRoot(result, root);\n          nodes.push(root);\n        }\n        while(nodes.length){\n          const node = nodes.pop();\n          const left = node.left ? RedBlackNode.from(node.left) : null;\n          const right = node.right ? RedBlackNode.from(node.right) : null;\n          if (left) {\n            left.parent = node;\n            nodes.push(left);\n          }\n          if (right) {\n            right.parent = node;\n            nodes.push(right);\n          }\n        }\n      }\n    } else {\n      result = options?.compare ? new RedBlackTree(options.compare) : new RedBlackTree();\n      unmappedValues = collection;\n    }\n    const values = options?.map ? Array.from(unmappedValues, options.map, options.thisArg) : unmappedValues;\n    for (const value of values)result.insert(value);\n    return result;\n  }\n  #removeFixup(parent, current) {\n    while(parent && !current?.red){\n      const direction = parent.left === current ? \"left\" : \"right\";\n      const siblingDirection = direction === \"right\" ? \"left\" : \"right\";\n      let sibling = parent[siblingDirection];\n      if (sibling?.red) {\n        sibling.red = false;\n        parent.red = true;\n        rotateNode(this, parent, direction);\n        sibling = parent[siblingDirection];\n      }\n      if (sibling) {\n        if (!sibling.left?.red && !sibling.right?.red) {\n          sibling.red = true;\n          current = parent;\n          parent = current.parent;\n        } else {\n          if (!sibling[siblingDirection]?.red) {\n            sibling[direction].red = false;\n            sibling.red = true;\n            rotateNode(this, sibling, siblingDirection);\n            sibling = parent[siblingDirection];\n          }\n          sibling.red = parent.red;\n          parent.red = false;\n          sibling[siblingDirection].red = false;\n          rotateNode(this, parent, direction);\n          current = getRoot(this);\n          parent = null;\n        }\n      }\n    }\n    if (current) current.red = false;\n  }\n  /**\n   * Add a value to the red-black tree if it does not already exist in the tree.\n   *\n   * The complexity of this operation is on average and at worst O(log n), where\n   * n is the number of values in the tree.\n   *\n   * @example Inserting a value into the tree\n   * ```ts\n   * import { RedBlackTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = new RedBlackTree<number>();\n   *\n   * assertEquals(tree.insert(42), true);\n   * assertEquals(tree.insert(42), false);\n   * ```\n   *\n   * @param value The value to insert into the tree.\n   * @returns `true` if the value was inserted, `false` if the value already exists in the tree.\n   */ insert(value) {\n    let node = insertNode(this, RedBlackNode, value);\n    if (node) {\n      while(node.parent?.red){\n        let parent = node.parent;\n        const parentDirection = parent.directionFromParent();\n        const uncleDirection = parentDirection === \"right\" ? \"left\" : \"right\";\n        const uncle = parent.parent[uncleDirection] ?? null;\n        if (uncle?.red) {\n          parent.red = false;\n          uncle.red = false;\n          parent.parent.red = true;\n          node = parent.parent;\n        } else {\n          if (node === parent[uncleDirection]) {\n            node = parent;\n            rotateNode(this, node, parentDirection);\n            parent = node.parent;\n          }\n          parent.red = false;\n          parent.parent.red = true;\n          rotateNode(this, parent.parent, uncleDirection);\n        }\n      }\n      getRoot(this).red = false;\n    }\n    return !!node;\n  }\n  /**\n   * Remove a value from the red-black tree if it exists in the tree.\n   *\n   * The complexity of this operation is on average and at worst O(log n), where\n   * n is the number of values in the tree.\n   *\n   * @example Removing values from the tree\n   * ```ts\n   * import { RedBlackTree } from \"@std/data-structures\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const tree = RedBlackTree.from<number>([42]);\n   *\n   * assertEquals(tree.remove(42), true);\n   * assertEquals(tree.remove(42), false);\n   * ```\n   *\n   * @param value The value to remove from the tree.\n   * @returns `true` if the value was found and removed, `false` if the value was not found in the tree.\n   */ remove(value) {\n    const node = findNode(this, value);\n    if (!node) {\n      return false;\n    }\n    const removedNode = removeNode(this, node);\n    if (removedNode && !removedNode.red) {\n      this.#removeFixup(removedNode.parent, removedNode.left ?? removedNode.right);\n    }\n    return true;\n  }\n}",
      "ascend": "function ascend(a, b) {\n  return a < b ? -1 : a > b ? 1 : 0;\n}",
      "descend": "function descend(a, b) {\n  return a < b ? 1 : a > b ? -1 : 0;\n}"
    }
  },
  {
    "jsr:@std/csv": {
      "CsvParseStream": "class CsvParseStream {\n  #readable;\n  #options;\n  #lineReader;\n  #lines;\n  #zeroBasedLineIndex = 0;\n  #isFirstRow = true;\n  // The number of fields per record that is either inferred from the first row\n  // (when options.fieldsPerRecord = 0), or set by the caller (when\n  // options.fieldsPerRecord > 0).\n  //\n  // Each possible variant means the following:\n  // \"ANY\": Variable number of fields is allowed.\n  // \"UNINITIALIZED\": The first row has not been read yet. Once it's read, the\n  //                  number of fields will be set.\n  // <number>: The number of fields per record that every record must follow.\n  #fieldsPerRecord;\n  #headers = [];\n  /** Construct a new instance.\n   *\n   * @param options Options for the stream.\n   */ constructor(options){\n    this.#options = {\n      ...options,\n      separator: options?.separator ?? \",\",\n      trimLeadingSpace: options?.trimLeadingSpace ?? false\n    };\n    if (this.#options.fieldsPerRecord === undefined || this.#options.fieldsPerRecord < 0) {\n      this.#fieldsPerRecord = \"ANY\";\n    } else if (this.#options.fieldsPerRecord === 0) {\n      this.#fieldsPerRecord = \"UNINITIALIZED\";\n    } else {\n      // TODO: Should we check if it's a valid integer?\n      this.#fieldsPerRecord = this.#options.fieldsPerRecord;\n    }\n    this.#lines = new TextDelimiterStream(\"\\n\");\n    this.#lineReader = new StreamLineReader(this.#lines.readable.getReader());\n    this.#readable = new ReadableStream({\n      pull: (controller)=>this.#pull(controller),\n      cancel: ()=>this.#lineReader.cancel()\n    });\n  }\n  async #pull(controller) {\n    const line = await this.#lineReader.readLine();\n    if (line === \"\") {\n      // Found an empty line\n      this.#zeroBasedLineIndex++;\n      return this.#pull(controller);\n    }\n    if (line === null) {\n      // Reached to EOF\n      controller.close();\n      this.#lineReader.cancel();\n      return;\n    }\n    const record = await parseRecord(line, this.#lineReader, this.#options, this.#zeroBasedLineIndex);\n    if (this.#isFirstRow) {\n      this.#isFirstRow = false;\n      if (this.#options.skipFirstRow || this.#options.columns) {\n        this.#headers = [];\n        if (this.#options.skipFirstRow) {\n          const head = record;\n          this.#headers = head;\n        }\n        if (this.#options.columns) {\n          this.#headers = this.#options.columns;\n        }\n      }\n      if (this.#options.skipFirstRow) {\n        return this.#pull(controller);\n      }\n      if (this.#fieldsPerRecord === \"UNINITIALIZED\") {\n        this.#fieldsPerRecord = record.length;\n      }\n    }\n    if (typeof this.#fieldsPerRecord === \"number\" && record.length !== this.#fieldsPerRecord) {\n      throw new SyntaxError(`Syntax error on line ${this.#zeroBasedLineIndex + 1}: expected ${this.#fieldsPerRecord} fields but got ${record.length}`);\n    }\n    this.#zeroBasedLineIndex++;\n    if (record.length > 0) {\n      if (this.#options.skipFirstRow || this.#options.columns) {\n        controller.enqueue(convertRowToObject(record, this.#headers, this.#zeroBasedLineIndex));\n      } else {\n        controller.enqueue(record);\n      }\n    } else {\n      return this.#pull(controller);\n    }\n  }\n  /**\n   * The instance's {@linkcode ReadableStream}.\n   *\n   * @example Usage\n   * ```ts\n   * import { CsvParseStream } from \"@std/csv/parse-stream\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const source = ReadableStream.from([\n   *   \"name,age\\n\",\n   *   \"Alice,34\\n\",\n   *   \"Bob,24\\n\",\n   * ]);\n   * const parseStream = new CsvParseStream({ skipFirstRow: true });\n   * const parts = source.pipeTo(parseStream.writable);\n   * assertEquals(await Array.fromAsync(parseStream.readable), [\n   *   { name: \"Alice\", age: \"34\" },\n   *   { name: \"Bob\", age: \"24\" },\n   * ]);\n   * ```\n   *\n   * @returns The instance's {@linkcode ReadableStream}.\n   */ get readable() {\n    return this.#readable;\n  }\n  /**\n   * The instance's {@linkcode WritableStream}.\n   *\n   * @example Usage\n   * ```ts\n   * import { CsvParseStream } from \"@std/csv/parse-stream\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const source = ReadableStream.from([\n   *   \"name,age\\n\",\n   *   \"Alice,34\\n\",\n   *   \"Bob,24\\n\",\n   * ]);\n   * const parseStream = new CsvParseStream({ skipFirstRow: true });\n   * const parts = source.pipeTo(parseStream.writable);\n   * assertEquals(await Array.fromAsync(parseStream.readable), [\n   *   { name: \"Alice\", age: \"34\" },\n   *   { name: \"Bob\", age: \"24\" },\n   * ]);\n   * ```\n   *\n   * @returns The instance's {@linkcode WritableStream}.\n   */ get writable() {\n    return this.#lines.writable;\n  }\n}",
      "CsvStringifyStream": "class CsvStringifyStream extends TransformStream {\n  /**\n   * Construct a new instance.\n   *\n   * @param options Options for the stream.\n   */ constructor(options){\n    const { separator, columns = [] } = options ?? {};\n    super({\n      start (controller) {\n        if (columns && columns.length > 0) {\n          try {\n            controller.enqueue(stringify([\n              columns\n            ], separator !== undefined ? {\n              separator,\n              headers: false\n            } : {\n              headers: false\n            }));\n          } catch (error) {\n            controller.error(error);\n          }\n        }\n      },\n      transform (chunk, controller) {\n        try {\n          controller.enqueue(stringify([\n            chunk\n          ], separator !== undefined ? {\n            separator,\n            headers: false,\n            columns\n          } : {\n            headers: false,\n            columns\n          }));\n        } catch (error) {\n          controller.error(error);\n        }\n      }\n    });\n  }\n}",
      "parse": "function parse(input, options = {\n  skipFirstRow: false\n}) {\n  const parser = new Parser(options);\n  const r = parser.parse(input);\n  if (options.skipFirstRow || options.columns) {\n    let headers = [];\n    if (options.skipFirstRow) {\n      const head = r.shift();\n      if (head === undefined) {\n        throw new TypeError(\"Cannot parse input: headers must be defined\");\n      }\n      headers = head;\n    }\n    if (options.columns) {\n      headers = options.columns;\n    }\n    const zeroBasedFirstLineIndex = options.skipFirstRow ? 1 : 0;\n    return r.map((row, i)=>{\n      return convertRowToObject(row, headers, zeroBasedFirstLineIndex + i);\n    });\n  }\n  return r;\n}",
      "stringify": "function stringify(data, options) {\n  const { headers = true, separator: sep = \",\", columns = [], bom = false } = options ?? {};\n  if (sep.includes(QUOTE) || sep.includes(CRLF)) {\n    const message = [\n      \"Separator cannot include the following strings:\",\n      '  - U+0022: Quotation mark (\")',\n      \"  - U+000D U+000A: Carriage Return + Line Feed (\\\\r\\\\n)\"\n    ].join(\"\\n\");\n    throw new TypeError(message);\n  }\n  const normalizedColumns = columns.map(normalizeColumn);\n  let output = \"\";\n  if (bom) {\n    output += BYTE_ORDER_MARK;\n  }\n  if (headers && normalizedColumns.length > 0) {\n    output += normalizedColumns.map((column)=>getEscapedString(column.header, sep)).join(sep);\n    output += CRLF;\n  }\n  for (const item of data){\n    const values = getValuesFromItem(item, normalizedColumns);\n    output += values.map((value)=>getEscapedString(value, sep)).join(sep);\n    output += CRLF;\n  }\n  return output;\n}"
    }
  },
  {
    "jsr:@std/crypto": {
      "DIGEST_ALGORITHM_NAMES": {
        "0": "BLAKE2B",
        "1": "BLAKE2B-128",
        "2": "BLAKE2B-160",
        "3": "BLAKE2B-224",
        "4": "BLAKE2B-256",
        "5": "BLAKE2B-384",
        "6": "BLAKE2S",
        "7": "BLAKE3",
        "8": "KECCAK-224",
        "9": "KECCAK-256",
        "10": "KECCAK-384",
        "11": "KECCAK-512",
        "12": "SHA-384",
        "13": "SHA3-224",
        "14": "SHA3-256",
        "15": "SHA3-384",
        "16": "SHA3-512",
        "17": "SHAKE128",
        "18": "SHAKE256",
        "19": "TIGER",
        "20": "RIPEMD-160",
        "21": "SHA-224",
        "22": "SHA-256",
        "23": "SHA-512",
        "24": "MD4",
        "25": "MD5",
        "26": "SHA-1",
        "27": "FNV32",
        "28": "FNV32A",
        "29": "FNV64",
        "30": "FNV64A"
      },
      "crypto": {
        "getRandomValues": "function () { [native code] }",
        "randomUUID": "function () { [native code] }",
        "subtle": {
          "decrypt": "function () { [native code] }",
          "deriveBits": "function () { [native code] }",
          "deriveKey": "function () { [native code] }",
          "digest": "async digest (algorithm, data) {\n      const { name, length } = normalizeAlgorithm(algorithm);\n      assertValidDigestLength(length);\n      // We delegate to WebCrypto whenever possible,\n      if (// if the algorithm is supported by the WebCrypto standard,\n      WEB_CRYPTO_DIGEST_ALGORITHM_NAMES.includes(name) && // and the data is a single buffer,\n      isBufferSource(data)) {\n        return await webCrypto.subtle.digest(algorithm, data);\n      } else if (DIGEST_ALGORITHM_NAMES.includes(name)) {\n        if (isBufferSource(data)) {\n          // Otherwise, we use our bundled Wasm implementation via digestSync\n          // if it supports the algorithm.\n          return stdCrypto.subtle.digestSync(algorithm, data);\n        } else if (isIterable(data)) {\n          return stdCrypto.subtle.digestSync(algorithm, data);\n        } else if (isAsyncIterable(data)) {\n          const wasmCrypto = instantiateWasm();\n          const context = new wasmCrypto.DigestContext(name);\n          for await (const chunk of data){\n            const chunkBytes = toUint8Array(chunk);\n            if (!chunkBytes) {\n              throw new TypeError(\"Cannot digest the data: A chunk is not ArrayBuffer nor ArrayBufferView\");\n            }\n            context.update(chunkBytes);\n          }\n          return context.digestAndDrop(length).buffer;\n        } else {\n          throw new TypeError(\"data must be a BufferSource or [Async]Iterable<BufferSource>\");\n        }\n      }\n      // (TypeScript type definitions prohibit this case.) If they're trying\n      // to call an algorithm we don't recognize, pass it along to WebCrypto\n      // in case it's a non-standard algorithm supported by the the runtime\n      // they're using.\n      return await webCrypto.subtle.digest(algorithm, data);\n    }",
          "encrypt": "function () { [native code] }",
          "exportKey": "function () { [native code] }",
          "generateKey": "function () { [native code] }",
          "importKey": "function () { [native code] }",
          "sign": "function () { [native code] }",
          "unwrapKey": "function () { [native code] }",
          "verify": "function () { [native code] }",
          "wrapKey": "function () { [native code] }",
          "digestSync": "digestSync (algorithm, data) {\n      const { name, length } = normalizeAlgorithm(algorithm);\n      assertValidDigestLength(length);\n      const wasmCrypto = instantiateWasm();\n      if (isBufferSource(data)) {\n        const bytes = toUint8Array(data);\n        return wasmCrypto.digest(name, bytes, length).buffer;\n      }\n      if (isIterable(data)) {\n        const context = new wasmCrypto.DigestContext(name);\n        for (const chunk of data){\n          const chunkBytes = toUint8Array(chunk);\n          if (!chunkBytes) {\n            throw new TypeError(\"Cannot digest the data: A chunk is not ArrayBuffer nor ArrayBufferView\");\n          }\n          context.update(chunkBytes);\n        }\n        return context.digestAndDrop(length).buffer;\n      }\n      throw new TypeError(\"data must be a BufferSource or Iterable<BufferSource>\");\n    }"
        }
      },
      "timingSafeEqual": "function timingSafeEqual(a, b) {\n  if (a.byteLength !== b.byteLength) return false;\n  const dataViewA = toDataView(a);\n  const dataViewB = toDataView(b);\n  const length = a.byteLength;\n  let out = 0;\n  let i = -1;\n  while(++i < length){\n    out |= dataViewA.getUint8(i) ^ dataViewB.getUint8(i);\n  }\n  return out === 0;\n}"
    }
  },
  {
    "jsr:@std/collections": {
      "aggregateGroups": "function aggregateGroups(record, aggregator) {\n  return mapEntries(record, ([key, values])=>[\n      key,\n      // Need the type assertions here because the reduce type does not support\n      // the type transition we need\n      values.reduce((accumulator, current, currentIndex)=>aggregator(current, key, currentIndex === 0, accumulator), undefined)\n    ]);\n}",
      "associateBy": "function associateBy(array, selector) {\n  const result = {};\n  for (const element of array){\n    result[selector(element)] = element;\n  }\n  return result;\n}",
      "associateWith": "function associateWith(array, selector) {\n  const result = {};\n  for (const element of array){\n    result[element] = selector(element);\n  }\n  return result;\n}",
      "chunk": "function chunk(array, size) {\n  if (size <= 0 || !Number.isInteger(size)) {\n    throw new RangeError(`Expected size to be an integer greater than 0 but found ${size}`);\n  }\n  const result = [];\n  let index = 0;\n  while(index < array.length){\n    result.push(array.slice(index, index + size));\n    index += size;\n  }\n  return result;\n}",
      "deepMerge": "function deepMerge(record, other, options) {\n  return deepMergeInternal(record, other, new Set(), options);\n}",
      "distinct": "function distinct(array) {\n  const set = new Set(array);\n  return Array.from(set);\n}",
      "distinctBy": "function distinctBy(array, selector) {\n  const selectedValues = new Set();\n  const result = [];\n  for (const element of array){\n    const selected = selector(element);\n    if (!selectedValues.has(selected)) {\n      selectedValues.add(selected);\n      result.push(element);\n    }\n  }\n  return result;\n}",
      "dropLastWhile": "function dropLastWhile(array, predicate) {\n  let offset = array.length;\n  while(0 < offset && predicate(array[offset - 1]))offset--;\n  return array.slice(0, offset);\n}",
      "dropWhile": "function dropWhile(array, predicate) {\n  let offset = 0;\n  const length = array.length;\n  while(length > offset && predicate(array[offset])){\n    offset++;\n  }\n  return array.slice(offset, length);\n}",
      "filterEntries": "function filterEntries(record, predicate) {\n  const result = {};\n  const entries = Object.entries(record);\n  for (const [key, value] of entries){\n    if (predicate([\n      key,\n      value\n    ])) {\n      result[key] = value;\n    }\n  }\n  return result;\n}",
      "filterKeys": "function filterKeys(record, predicate) {\n  const result = {};\n  for (const [key, value] of Object.entries(record)){\n    if (predicate(key)) {\n      result[key] = value;\n    }\n  }\n  return result;\n}",
      "filterValues": "function filterValues(record, predicate) {\n  const result = {};\n  const entries = Object.entries(record);\n  for (const [key, value] of entries){\n    if (predicate(value)) {\n      result[key] = value;\n    }\n  }\n  return result;\n}",
      "findSingle": "function findSingle(array, predicate) {\n  let match;\n  let found = false;\n  for (const element of array){\n    if (predicate(element)) {\n      if (found) return undefined;\n      found = true;\n      match = element;\n    }\n  }\n  return match;\n}",
      "firstNotNullishOf": "function firstNotNullishOf(array, selector) {\n  for (const current of array){\n    const selected = selector(current);\n    if (selected !== null && selected !== undefined) {\n      return selected;\n    }\n  }\n  return undefined;\n}",
      "includesValue": "function includesValue(record, value) {\n  for(const i in record){\n    if (Object.hasOwn(record, i) && (record[i] === value || Number.isNaN(value) && Number.isNaN(record[i]))) {\n      return true;\n    }\n  }\n  return false;\n}",
      "intersect": "function intersect(...arrays) {\n  const [array, ...otherArrays] = arrays;\n  let set = new Set(array);\n  for (const array of otherArrays){\n    set = set.intersection(new Set(array));\n    if (set.size === 0) break;\n  }\n  return [\n    ...set\n  ];\n}",
      "invert": "function invert(record) {\n  return Object.fromEntries(Object.entries(record).map(([key, value])=>[\n      value,\n      key\n    ]));\n}",
      "invertBy": "function invertBy(record, transformer) {\n  const result = {};\n  for (const [key, value] of Object.entries(record)){\n    const mappedKey = transformer(value);\n    if (!Object.hasOwn(result, mappedKey)) {\n      result[mappedKey] = [\n        key\n      ];\n    } else {\n      result[mappedKey].push(key);\n    }\n  }\n  return result;\n}",
      "joinToString": "function joinToString(array, selector, options = {}) {\n  const { separator = \",\", prefix = \"\", suffix = \"\", limit = -1, truncated = \"...\" } = options;\n  let result = \"\";\n  let index = 0;\n  for (const el of array){\n    if (index > 0) {\n      result += separator;\n    }\n    if (limit >= 0 && index >= limit) {\n      result += truncated;\n      break;\n    }\n    result += selector(el);\n    index++;\n  }\n  return prefix + result + suffix;\n}",
      "mapEntries": "function mapEntries(record, transformer) {\n  const result = {};\n  const entries = Object.entries(record);\n  for (const entry of entries){\n    const [mappedKey, mappedValue] = transformer(entry);\n    result[mappedKey] = mappedValue;\n  }\n  return result;\n}",
      "mapKeys": "function mapKeys(record, transformer) {\n  const result = {};\n  for (const [key, value] of Object.entries(record)){\n    const mappedKey = transformer(key);\n    result[mappedKey] = value;\n  }\n  return result;\n}",
      "mapNotNullish": "function mapNotNullish(array, transformer) {\n  const result = [];\n  for (const element of array){\n    const transformedElement = transformer(element);\n    if (transformedElement !== undefined && transformedElement !== null) {\n      result.push(transformedElement);\n    }\n  }\n  return result;\n}",
      "mapValues": "function mapValues(record, transformer) {\n  // deno-lint-ignore no-explicit-any\n  const result = {};\n  const entries = Object.entries(record);\n  for (const [key, value] of entries){\n    const mappedValue = transformer(value, key);\n    result[key] = mappedValue;\n  }\n  return result;\n}",
      "maxBy": "function maxBy(array, selector) {\n  let max;\n  let maxValue;\n  for (const current of array){\n    const currentValue = selector(current);\n    if (maxValue === undefined || currentValue > maxValue) {\n      max = current;\n      maxValue = currentValue;\n    }\n  }\n  return max;\n}",
      "maxOf": "function maxOf(array, selector) {\n  let maximumValue;\n  for (const element of array){\n    const currentValue = selector(element);\n    if (maximumValue === undefined || currentValue > maximumValue) {\n      maximumValue = currentValue;\n      continue;\n    }\n    if (Number.isNaN(currentValue)) {\n      return currentValue;\n    }\n  }\n  return maximumValue;\n}",
      "maxWith": "function maxWith(array, comparator) {\n  let max;\n  let isFirst = true;\n  for (const current of array){\n    if (isFirst || comparator(current, max) > 0) {\n      max = current;\n      isFirst = false;\n    }\n  }\n  return max;\n}",
      "minBy": "function minBy(array, selector) {\n  let min;\n  let minValue;\n  for (const current of array){\n    const currentValue = selector(current);\n    if (minValue === undefined || currentValue < minValue) {\n      min = current;\n      minValue = currentValue;\n    }\n  }\n  return min;\n}",
      "minOf": "function minOf(array, selector) {\n  let minimumValue;\n  for (const element of array){\n    const currentValue = selector(element);\n    if (minimumValue === undefined || currentValue < minimumValue) {\n      minimumValue = currentValue;\n      continue;\n    }\n    if (Number.isNaN(currentValue)) {\n      return currentValue;\n    }\n  }\n  return minimumValue;\n}",
      "minWith": "function minWith(array, comparator) {\n  let min;\n  let isFirst = true;\n  for (const current of array){\n    if (isFirst || comparator(current, min) < 0) {\n      min = current;\n      isFirst = false;\n    }\n  }\n  return min;\n}",
      "omit": "function omit(obj, keys) {\n  const excludes = new Set(keys);\n  return Object.fromEntries(Object.entries(obj).filter(([k, _])=>!excludes.has(k)));\n}",
      "partition": "function partition(array, predicate) {\n  const matches = [];\n  const rest = [];\n  for (const element of array){\n    if (predicate(element)) {\n      matches.push(element);\n    } else {\n      rest.push(element);\n    }\n  }\n  return [\n    matches,\n    rest\n  ];\n}",
      "partitionEntries": "function partitionEntries(record, predicate) {\n  const match = {};\n  const rest = {};\n  const entries = Object.entries(record);\n  for (const [key, value] of entries){\n    if (predicate([\n      key,\n      value\n    ])) {\n      match[key] = value;\n    } else {\n      rest[key] = value;\n    }\n  }\n  return [\n    match,\n    rest\n  ];\n}",
      "permutations": "function permutations(inputArray) {\n  const result = [];\n  const array = [\n    ...inputArray\n  ];\n  const k = array.length;\n  if (k === 0) {\n    return result;\n  }\n  // Heap's Algorithm\n  const c = new Array(k).fill(0);\n  result.push([\n    ...array\n  ]);\n  let i = 1;\n  while(i < k){\n    if (c[i] < i) {\n      if (i % 2 === 0) {\n        [array[0], array[i]] = [\n          array[i],\n          array[0]\n        ];\n      } else {\n        [array[c[i]], array[i]] = [\n          array[i],\n          array[c[i]]\n        ];\n      }\n      result.push([\n        ...array\n      ]);\n      c[i] += 1;\n      i = 1;\n    } else {\n      c[i] = 0;\n      i += 1;\n    }\n  }\n  return result;\n}",
      "pick": "function pick(obj, keys) {\n  const result = {};\n  for (const key of keys)if (key in obj) result[key] = obj[key];\n  return result;\n}",
      "reduceGroups": "function reduceGroups(record, reducer, initialValue) {\n  return mapValues(record, (value)=>value.reduce(reducer, initialValue));\n}",
      "runningReduce": "function runningReduce(array, reducer, initialValue) {\n  let currentResult = initialValue;\n  return array.map((el, currentIndex)=>currentResult = reducer(currentResult, el, currentIndex));\n}",
      "sample": "function sample(array) {\n  const length = array.length;\n  return length ? array[randomInteger(0, length - 1)] : undefined;\n}",
      "slidingWindows": "function slidingWindows(array, size, options = {}) {\n  const { step = 1, partial = false } = options;\n  if (!Number.isInteger(size) || !Number.isInteger(step) || size <= 0 || step <= 0) {\n    throw new RangeError(\"Both size and step must be positive integer.\");\n  }\n  return Array.from({\n    length: Math.floor((array.length - (partial ? 1 : size)) / step + 1)\n  }, (_, i)=>array.slice(i * step, i * step + size));\n}",
      "sortBy": "function sortBy(array, selector, options) {\n  const len = array.length;\n  const indexes = new Array(len);\n  const selectors = new Array(len);\n  const order = options?.order ?? \"asc\";\n  array.forEach((element, index)=>{\n    indexes[index] = index;\n    const selected = selector(element);\n    selectors[index] = Number.isNaN(selected) ? null : selected;\n  });\n  indexes.sort((ai, bi)=>{\n    let a = selectors[ai];\n    let b = selectors[bi];\n    if (order === \"desc\") {\n      [a, b] = [\n        b,\n        a\n      ];\n    }\n    if (a === null) return 1;\n    if (b === null) return -1;\n    return a > b ? 1 : a < b ? -1 : 0;\n  });\n  for(let i = 0; i < len; i++){\n    indexes[i] = array[indexes[i]];\n  }\n  return indexes;\n}",
      "sumOf": "function sumOf(array, selector) {\n  let sum = 0;\n  for (const i of array){\n    sum += selector(i);\n  }\n  return sum;\n}",
      "takeLastWhile": "function takeLastWhile(array, predicate) {\n  let offset = array.length;\n  while(0 < offset && predicate(array[offset - 1]))offset--;\n  return array.slice(offset, array.length);\n}",
      "takeWhile": "function takeWhile(array, predicate) {\n  let offset = 0;\n  const length = array.length;\n  while(length > offset && predicate(array[offset])){\n    offset++;\n  }\n  return array.slice(0, offset);\n}",
      "union": "function union(...arrays) {\n  const set = new Set();\n  for (const array of arrays){\n    for (const element of array){\n      set.add(element);\n    }\n  }\n  return Array.from(set);\n}",
      "unzip": "function unzip(pairs) {\n  const { length } = pairs;\n  const result = [\n    new Array(length),\n    new Array(length)\n  ];\n  for(let i = 0; i < length; ++i){\n    const pair = pairs[i];\n    result[0][i] = pair[0];\n    result[1][i] = pair[1];\n  }\n  return result;\n}",
      "withoutAll": "function withoutAll(array, values) {\n  const toExclude = new Set(values);\n  return array.filter((it)=>!toExclude.has(it));\n}",
      "zip": "function zip(...arrays) {\n  const minLength = minOf(arrays, (element)=>element.length) ?? 0;\n  const result = new Array(minLength);\n  for(let i = 0; i < minLength; i += 1){\n    const arr = arrays.map((it)=>it[i]);\n    result[i] = arr;\n  }\n  return result;\n}"
    }
  },
  {
    "jsr:@std/cli": {
      "parseArgs": "function parseArgs(args, options) {\n  const { \"--\": doubleDash = false, alias = {}, boolean = false, default: defaults = {}, stopEarly = false, string = [], collect = [], negatable = [], unknown: unknownFn = (i)=>i } = options ?? {};\n  const aliasMap = new Map();\n  const booleanSet = new Set();\n  const stringSet = new Set();\n  const collectSet = new Set();\n  const negatableSet = new Set();\n  let allBools = false;\n  if (alias) {\n    for (const [key, value] of Object.entries(alias)){\n      if (value === undefined) {\n        throw new TypeError(\"Alias value must be defined\");\n      }\n      const aliases = Array.isArray(value) ? value : [\n        value\n      ];\n      aliasMap.set(key, new Set(aliases));\n      aliases.forEach((alias)=>aliasMap.set(alias, new Set([\n          key,\n          ...aliases.filter((it)=>it !== alias)\n        ])));\n    }\n  }\n  if (boolean) {\n    if (typeof boolean === \"boolean\") {\n      allBools = boolean;\n    } else {\n      const booleanArgs = Array.isArray(boolean) ? boolean : [\n        boolean\n      ];\n      for (const key of booleanArgs.filter(Boolean)){\n        booleanSet.add(key);\n        aliasMap.get(key)?.forEach((al)=>{\n          booleanSet.add(al);\n        });\n      }\n    }\n  }\n  if (string) {\n    const stringArgs = Array.isArray(string) ? string : [\n      string\n    ];\n    for (const key of stringArgs.filter(Boolean)){\n      stringSet.add(key);\n      aliasMap.get(key)?.forEach((al)=>stringSet.add(al));\n    }\n  }\n  if (collect) {\n    const collectArgs = Array.isArray(collect) ? collect : [\n      collect\n    ];\n    for (const key of collectArgs.filter(Boolean)){\n      collectSet.add(key);\n      aliasMap.get(key)?.forEach((al)=>collectSet.add(al));\n    }\n  }\n  if (negatable) {\n    const negatableArgs = Array.isArray(negatable) ? negatable : [\n      negatable\n    ];\n    for (const key of negatableArgs.filter(Boolean)){\n      negatableSet.add(key);\n      aliasMap.get(key)?.forEach((alias)=>negatableSet.add(alias));\n    }\n  }\n  const argv = {\n    _: []\n  };\n  function setArgument(key, value, arg, collect) {\n    if (!booleanSet.has(key) && !stringSet.has(key) && !aliasMap.has(key) && !(allBools && FLAG_NAME_REGEXP.test(arg)) && unknownFn?.(arg, key, value) === false) {\n      return;\n    }\n    if (typeof value === \"string\" && !stringSet.has(key)) {\n      value = isNumber(value) ? Number(value) : value;\n    }\n    const collectable = collect && collectSet.has(key);\n    setNested(argv, key.split(\".\"), value, collectable);\n    aliasMap.get(key)?.forEach((key)=>{\n      setNested(argv, key.split(\".\"), value, collectable);\n    });\n  }\n  let notFlags = [];\n  // all args after \"--\" are not parsed\n  const index = args.indexOf(\"--\");\n  if (index !== -1) {\n    notFlags = args.slice(index + 1);\n    args = args.slice(0, index);\n  }\n  argsLoop: for(let i = 0; i < args.length; i++){\n    const arg = args[i];\n    const groups = arg.match(FLAG_REGEXP)?.groups;\n    if (groups) {\n      const { doubleDash, negated } = groups;\n      let key = groups.key;\n      let value = groups.value;\n      if (doubleDash) {\n        if (value) {\n          if (booleanSet.has(key)) value = parseBooleanString(value);\n          setArgument(key, value, arg, true);\n          continue;\n        }\n        if (negated) {\n          if (negatableSet.has(key)) {\n            setArgument(key, false, arg, false);\n            continue;\n          }\n          key = `no-${key}`;\n        }\n        const next = args[i + 1];\n        if (next) {\n          if (!booleanSet.has(key) && !allBools && !next.startsWith(\"-\") && (!aliasMap.has(key) || !aliasIsBoolean(aliasMap, booleanSet, key))) {\n            value = next;\n            i++;\n            setArgument(key, value, arg, true);\n            continue;\n          }\n          if (isBooleanString(next)) {\n            value = parseBooleanString(next);\n            i++;\n            setArgument(key, value, arg, true);\n            continue;\n          }\n        }\n        value = stringSet.has(key) ? \"\" : true;\n        setArgument(key, value, arg, true);\n        continue;\n      }\n      const letters = arg.slice(1, -1).split(\"\");\n      for (const [j, letter] of letters.entries()){\n        const next = arg.slice(j + 2);\n        if (next === \"-\") {\n          setArgument(letter, next, arg, true);\n          continue;\n        }\n        if (LETTER_REGEXP.test(letter)) {\n          const groups = VALUE_REGEXP.exec(next)?.groups;\n          if (groups) {\n            setArgument(letter, groups.value, arg, true);\n            continue argsLoop;\n          }\n          if (NUMBER_REGEXP.test(next)) {\n            setArgument(letter, next, arg, true);\n            continue argsLoop;\n          }\n        }\n        if (letters[j + 1]?.match(SPECIAL_CHAR_REGEXP)) {\n          setArgument(letter, arg.slice(j + 2), arg, true);\n          continue argsLoop;\n        }\n        setArgument(letter, stringSet.has(letter) ? \"\" : true, arg, true);\n      }\n      key = arg.slice(-1);\n      if (key === \"-\") continue;\n      const nextArg = args[i + 1];\n      if (nextArg) {\n        if (!HYPHEN_REGEXP.test(nextArg) && !booleanSet.has(key) && (!aliasMap.has(key) || !aliasIsBoolean(aliasMap, booleanSet, key))) {\n          setArgument(key, nextArg, arg, true);\n          i++;\n          continue;\n        }\n        if (isBooleanString(nextArg)) {\n          const value = parseBooleanString(nextArg);\n          setArgument(key, value, arg, true);\n          i++;\n          continue;\n        }\n      }\n      setArgument(key, stringSet.has(key) ? \"\" : true, arg, true);\n      continue;\n    }\n    if (unknownFn?.(arg) !== false) {\n      argv._.push(stringSet.has(\"_\") || !isNumber(arg) ? arg : Number(arg));\n    }\n    if (stopEarly) {\n      argv._.push(...args.slice(i + 1));\n      break;\n    }\n  }\n  for (const [key, value] of Object.entries(defaults)){\n    const keys = key.split(\".\");\n    if (!hasNested(argv, keys)) {\n      setNested(argv, keys, value);\n      aliasMap.get(key)?.forEach((key)=>setNested(argv, key.split(\".\"), value));\n    }\n  }\n  for (const key of booleanSet.keys()){\n    const keys = key.split(\".\");\n    if (!hasNested(argv, keys)) {\n      const value = collectSet.has(key) ? [] : false;\n      setNested(argv, keys, value);\n    }\n  }\n  for (const key of stringSet.keys()){\n    const keys = key.split(\".\");\n    if (!hasNested(argv, keys) && collectSet.has(key)) {\n      setNested(argv, keys, []);\n    }\n  }\n  if (doubleDash) {\n    argv[\"--\"] = notFlags;\n  } else {\n    argv._.push(...notFlags);\n  }\n  return argv;\n}",
      "promptSecret": "function promptSecret(message = \"Secret\", options) {\n  const { mask = \"*\", clear } = options ?? {};\n  if (!input.isTerminal()) {\n    return null;\n  }\n  // Make the output consistent with the built-in prompt()\n  message += \" \";\n  const callback = !mask ? undefined : (n)=>{\n    output.writeSync(CLR);\n    output.writeSync(encoder.encode(`${message}${mask.repeat(n)}`));\n  };\n  output.writeSync(encoder.encode(message));\n  Deno.stdin.setRaw(true, setRawOptions);\n  try {\n    return readLineFromStdinSync(callback);\n  } finally{\n    if (clear) {\n      output.writeSync(CLR);\n    } else {\n      output.writeSync(encoder.encode(\"\\n\"));\n    }\n    Deno.stdin.setRaw(false);\n  }\n}",
      "unicodeWidth": "function unicodeWidth(str) {\n  return [\n    ...str\n  ].map((ch)=>charWidth(ch) ?? 0).reduce((a, b)=>a + b, 0);\n}"
    }
  },
  {
    "jsr:@std/cache": {
      "LruCache": "class LruCache extends Map {\n  /**\n   * The maximum number of entries to store in the cache.\n   *\n   * @example Max size\n   * ```ts no-assert\n   * import { LruCache } from \"@std/cache\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const cache = new LruCache<string, number>(100);\n   * assertEquals(cache.maxSize, 100);\n   * ```\n   */ maxSize;\n  /**\n   * Constructs a new `LruCache`.\n   *\n   * @param maxSize The maximum number of entries to store in the cache.\n   */ constructor(maxSize){\n    super();\n    this.maxSize = maxSize;\n  }\n  #setMostRecentlyUsed(key, value) {\n    // delete then re-add to ensure most recently accessed elements are last\n    super.delete(key);\n    super.set(key, value);\n  }\n  #pruneToMaxSize() {\n    if (this.size > this.maxSize) {\n      this.delete(this.keys().next().value);\n    }\n  }\n  /**\n   * Checks whether an element with the specified key exists or not.\n   *\n   * @param key The key to check.\n   * @returns `true` if the cache contains the specified key, otherwise `false`.\n   *\n   * @example Checking for the existence of a key\n   * ```ts\n   * import { LruCache } from \"@std/cache\";\n   * import { assert } from \"@std/assert\";\n   *\n   * const cache = new LruCache<string, number>(100);\n   *\n   * cache.set(\"a\", 1);\n   * assert(cache.has(\"a\"));\n   * ```\n   */ has(key) {\n    const exists = super.has(key);\n    if (exists) {\n      this.#setMostRecentlyUsed(key, super.get(key));\n    }\n    return exists;\n  }\n  /**\n   * Gets the element with the specified key.\n   *\n   * @param key The key to get the value for.\n   * @returns The value associated with the specified key, or `undefined` if the key is not present in the cache.\n   *\n   * @example Getting a value from the cache\n   * ```ts\n   * import { LruCache } from \"@std/cache\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * const cache = new LruCache<string, number>(100);\n   *\n   * cache.set(\"a\", 1);\n   * assertEquals(cache.get(\"a\"), 1);\n   * ```\n   */ get(key) {\n    if (super.has(key)) {\n      const value = super.get(key);\n      this.#setMostRecentlyUsed(key, value);\n      return value;\n    }\n    return undefined;\n  }\n  /**\n   * Sets the specified key to the specified value.\n   *\n   * @param key The key to set the value for.\n   * @param value The value to set.\n   * @returns `this` for chaining.\n   *\n   * @example Setting a value in the cache\n   * ```ts no-assert\n   * import { LruCache } from \"@std/cache\";\n   *\n   * const cache = new LruCache<string, number>(100);\n   * cache.set(\"a\", 1);\n   * ```\n   */ set(key, value) {\n    this.#setMostRecentlyUsed(key, value);\n    this.#pruneToMaxSize();\n    return this;\n  }\n}",
      "TtlCache": "class TtlCache extends Map {\n  #defaultTtl;\n  #timeouts = new Map();\n  /**\n   * Constructs a new instance.\n   *\n   * @experimental **UNSTABLE**: New API, yet to be vetted.\n   *\n   * @param defaultTtl The default time-to-live in milliseconds. This value must\n   * be equal to or greater than 0. Its limit is determined by the current\n   * runtime's {@linkcode setTimeout} implementation.\n   */ constructor(defaultTtl){\n    super();\n    this.#defaultTtl = defaultTtl;\n  }\n  /**\n   * Set a value in the cache.\n   *\n   * @experimental **UNSTABLE**: New API, yet to be vetted.\n   *\n   * @param key The cache key\n   * @param value The value to set\n   * @param ttl A custom time-to-live. If supplied, overrides the cache's\n   * default TTL for this entry. This value must\n   * be equal to or greater than 0. Its limit is determined by the current\n   * runtime's {@linkcode setTimeout} implementation.\n   * @returns `this` for chaining.\n   *\n   * @example Usage\n   * ```ts\n   * import { TtlCache } from \"@std/cache/ttl-cache\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const cache = new TtlCache<string, number>(1000);\n   *\n   * cache.set(\"a\", 1);\n   * assertEquals(cache.get(\"a\"), 1);\n   * ```\n   */ set(key, value, ttl = this.#defaultTtl) {\n    clearTimeout(this.#timeouts.get(key));\n    super.set(key, value);\n    this.#timeouts.set(key, setTimeout(()=>this.delete(key), ttl));\n    return this;\n  }\n  /**\n   * Deletes the value associated with the given key.\n   *\n   * @experimental **UNSTABLE**: New API, yet to be vetted.\n   *\n   * @param key The key to delete.\n   * @returns `true` if the key was deleted, `false` otherwise.\n   *\n   * @example Usage\n   * ```ts\n   * import { TtlCache } from \"@std/cache\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const cache = new TtlCache<string, number>(1000);\n   *\n   * cache.set(\"a\", 1);\n   * cache.delete(\"a\");\n   * assertEquals(cache.has(\"a\"), false);\n   * ```\n   */ delete(key) {\n    clearTimeout(this.#timeouts.get(key));\n    this.#timeouts.delete(key);\n    return super.delete(key);\n  }\n  /**\n   * Clears the cache.\n   *\n   * @experimental **UNSTABLE**: New API, yet to be vetted.\n   *\n   * @example Usage\n   * ```ts\n   * import { TtlCache } from \"@std/cache\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * const cache = new TtlCache<string, number>(1000);\n   *\n   * cache.set(\"a\", 1);\n   * cache.set(\"b\", 2);\n   * cache.clear();\n   * assertEquals(cache.size, 0);\n   * ```\n   */ clear() {\n    for (const timeout of this.#timeouts.values()){\n      clearTimeout(timeout);\n    }\n    this.#timeouts.clear();\n    super.clear();\n  }\n  /**\n   * Automatically clears all remaining timeouts once the cache goes out of\n   * scope if the cache is declared with `using`.\n   *\n   * @experimental **UNSTABLE**: New API, yet to be vetted.\n   *\n   * @example Usage\n   * ```ts no-assert\n   * import { TtlCache } from \"@std/cache/ttl-cache\";\n   * import { assertEquals } from \"@std/assert/equals\";\n   *\n   * let c: TtlCache<string, number>;\n   * {\n   *  using cache = new TtlCache<string, number>(1000);\n   *  cache.set(\"a\", 1);\n   *  c = cache;\n   * }\n   * assertEquals(c.size, 0);\n   * ```\n   */ [_computedKey]() {\n    this.clear();\n  }\n}",
      "memoize": "function memoize(fn, options) {\n  const cache = options?.cache ?? new Map();\n  const getKey = options?.getKey ?? _serializeArgList(cache);\n  const memoized = function(...args) {\n    const key = getKey.apply(this, args);\n    if (cache.has(key)) {\n      return cache.get(key);\n    }\n    let val = fn.apply(this, args);\n    if (val instanceof Promise) {\n      val = val.catch((reason)=>{\n        cache.delete(key);\n        throw reason;\n      });\n    }\n    cache.set(key, val);\n    return val;\n  };\n  return Object.defineProperties(memoized, {\n    length: {\n      value: fn.length\n    },\n    name: {\n      value: fn.name\n    }\n  });\n}"
    }
  },
  {
    "jsr:@std/bytes": {
      "concat": "function concat(buffers) {\n  let length = 0;\n  for (const buffer of buffers){\n    length += buffer.length;\n  }\n  const output = new Uint8Array(length);\n  let index = 0;\n  for (const buffer of buffers){\n    output.set(buffer, index);\n    index += buffer.length;\n  }\n  return output;\n}",
      "copy": "function copy(src, dst, offset = 0) {\n  offset = Math.max(0, Math.min(offset, dst.byteLength));\n  const dstBytesAvailable = dst.byteLength - offset;\n  if (src.byteLength > dstBytesAvailable) {\n    src = src.subarray(0, dstBytesAvailable);\n  }\n  dst.set(src, offset);\n  return src.byteLength;\n}",
      "endsWith": "function endsWith(source, suffix) {\n  const diff = source.length - suffix.length;\n  if (diff < 0) {\n    return false;\n  }\n  for(let i = suffix.length - 1; i >= 0; i--){\n    if (source[diff + i] !== suffix[i]) {\n      return false;\n    }\n  }\n  return true;\n}",
      "equals": "function equals(a, b) {\n  if (a.length !== b.length) {\n    return false;\n  }\n  return a.length >= THRESHOLD_32_BIT && a.byteOffset % 4 === b.byteOffset % 4 ? equals32Bit(a, b) : equalsNaive(a, b);\n}",
      "includesNeedle": "function includesNeedle(source, needle, start = 0) {\n  return indexOfNeedle(source, needle, start) !== -1;\n}",
      "indexOfNeedle": "function indexOfNeedle(source, needle, start = 0) {\n  if (start < 0) {\n    start = Math.max(0, source.length + start);\n  }\n  if (needle.length > source.length - start) {\n    return -1;\n  }\n  const s = needle[0];\n  for(let i = start; i < source.length; i++){\n    if (source[i] !== s) continue;\n    let matched = 1;\n    let j = i + 1;\n    while(matched < needle.length && source[j] === needle[j - i]){\n      matched++;\n      j++;\n    }\n    if (matched === needle.length) {\n      return i;\n    }\n  }\n  return -1;\n}",
      "lastIndexOfNeedle": "function lastIndexOfNeedle(source, needle, start = source.length - 1) {\n  if (start < 0) {\n    return -1;\n  }\n  if (start >= source.length) {\n    start = source.length - 1;\n  }\n  const e = needle[needle.length - 1];\n  for(let i = start; i >= 0; i--){\n    if (source[i] !== e) continue;\n    let matched = 1;\n    let j = i;\n    while(matched < needle.length && source[--j] === needle[needle.length - 1 - (i - j)]){\n      matched++;\n    }\n    if (matched === needle.length) {\n      return i - needle.length + 1;\n    }\n  }\n  return -1;\n}",
      "repeat": "function repeat(source, count) {\n  if (count < 0 || !Number.isInteger(count)) {\n    throw new RangeError(\"Count must be a non-negative integer\");\n  }\n  const repeated = new Uint8Array(source.length * count);\n  let offset = 0;\n  while(offset < repeated.length){\n    offset += copy(source, repeated, offset);\n  }\n  return repeated;\n}",
      "startsWith": "function startsWith(source, prefix) {\n  if (prefix.length > source.length) {\n    return false;\n  }\n  for(let i = 0; i < prefix.length; i++){\n    if (source[i] !== prefix[i]) return false;\n  }\n  return true;\n}"
    }
  },
  {
    "jsr:@std/async": {
      "MuxAsyncIterator": "class MuxAsyncIterator {\n  #iteratorCount = 0;\n  #yields = [];\n  // deno-lint-ignore no-explicit-any\n  #throws = [];\n  #signal = Promise.withResolvers();\n  /**\n   * Add an async iterable to the stream.\n   *\n   * @param iterable The async iterable to add.\n   *\n   * @example Usage\n   * ```ts\n   * import { MuxAsyncIterator } from \"@std/async/mux-async-iterator\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * async function* gen123(): AsyncIterableIterator<number> {\n   *   yield 1;\n   *   yield 2;\n   *   yield 3;\n   * }\n   *\n   * const mux = new MuxAsyncIterator<number>();\n   * mux.add(gen123());\n   *\n   * const result = await Array.fromAsync(mux.iterate());\n   *\n   * assertEquals(result, [1, 2, 3]);\n   * ```\n   */ add(iterable) {\n    ++this.#iteratorCount;\n    this.#callIteratorNext(iterable[Symbol.asyncIterator]());\n  }\n  async #callIteratorNext(iterator) {\n    try {\n      const { value, done } = await iterator.next();\n      if (done) {\n        --this.#iteratorCount;\n      } else {\n        this.#yields.push({\n          iterator,\n          value\n        });\n      }\n    } catch (e) {\n      this.#throws.push(e);\n    }\n    this.#signal.resolve();\n  }\n  /**\n   * Returns an async iterator of the stream.\n   * @returns the async iterator for all the added async iterables.\n   *\n   * @example Usage\n   * ```ts\n   * import { MuxAsyncIterator } from \"@std/async/mux-async-iterator\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * async function* gen123(): AsyncIterableIterator<number> {\n   *   yield 1;\n   *   yield 2;\n   *   yield 3;\n   * }\n   *\n   * const mux = new MuxAsyncIterator<number>();\n   * mux.add(gen123());\n   *\n   * const result = await Array.fromAsync(mux.iterate());\n   *\n   * assertEquals(result, [1, 2, 3]);\n   * ```\n   */ async *iterate() {\n    while(this.#iteratorCount > 0){\n      // Sleep until any of the wrapped iterators yields.\n      await this.#signal.promise;\n      // Note that while we're looping over `yields`, new items may be added.\n      for (const { iterator, value } of this.#yields){\n        yield value;\n        this.#callIteratorNext(iterator);\n      }\n      if (this.#throws.length) {\n        for (const e of this.#throws){\n          throw e;\n        }\n      }\n      // Clear the `yields` list and reset the `signal` promise.\n      this.#yields.length = 0;\n      this.#signal = Promise.withResolvers();\n    }\n  }\n  /**\n   * Implements an async iterator for the stream.\n   * @returns the async iterator for all the added async iterables.\n   *\n   * @example Usage\n   * ```ts\n   * import { MuxAsyncIterator } from \"@std/async/mux-async-iterator\";\n   * import { assertEquals } from \"@std/assert\";\n   *\n   * async function* gen123(): AsyncIterableIterator<number> {\n   *   yield 1;\n   *   yield 2;\n   *   yield 3;\n   * }\n   *\n   * const mux = new MuxAsyncIterator<number>();\n   * mux.add(gen123());\n   *\n   * const result = await Array.fromAsync(mux);\n   *\n   * assertEquals(result, [1, 2, 3]);\n   * ```\n   */ [_computedKey]() {\n    return this.iterate();\n  }\n}",
      "RetryError": "class RetryError extends Error {\n  /**\n   * Constructs a new {@linkcode RetryError} instance.\n   *\n   * @param cause the cause for this error.\n   * @param attempts the number of retry attempts made.\n   */ constructor(cause, attempts){\n    super(`Retrying exceeded the maxAttempts (${attempts}).`);\n    this.name = \"RetryError\";\n    this.cause = cause;\n  }\n}",
      "abortable": "function abortable(p, signal) {\n  if (p instanceof Promise) {\n    return abortablePromise(p, signal);\n  } else {\n    return abortableAsyncIterable(p, signal);\n  }\n}",
      "deadline": "async function deadline(p, ms, options = {}) {\n  const signals = [\n    AbortSignal.timeout(ms)\n  ];\n  if (options.signal) signals.push(options.signal);\n  return await abortable(p, AbortSignal.any(signals));\n}",
      "debounce": "function debounce(fn, wait) {\n  let timeout = null;\n  let flush = null;\n  const debounced = (...args)=>{\n    debounced.clear();\n    flush = ()=>{\n      debounced.clear();\n      fn.call(debounced, ...args);\n    };\n    timeout = Number(setTimeout(flush, wait));\n  };\n  debounced.clear = ()=>{\n    if (typeof timeout === \"number\") {\n      clearTimeout(timeout);\n      timeout = null;\n      flush = null;\n    }\n  };\n  debounced.flush = ()=>{\n    flush?.();\n  };\n  Object.defineProperty(debounced, \"pending\", {\n    get: ()=>typeof timeout === \"number\"\n  });\n  return debounced;\n}",
      "delay": "function delay(ms, options = {}) {\n  const { signal, persistent = true } = options;\n  if (signal?.aborted) return Promise.reject(signal.reason);\n  return new Promise((resolve, reject)=>{\n    const abort = ()=>{\n      clearTimeout(i);\n      reject(signal?.reason);\n    };\n    const done = ()=>{\n      signal?.removeEventListener(\"abort\", abort);\n      resolve();\n    };\n    const i = setTimeout(done, ms);\n    signal?.addEventListener(\"abort\", abort, {\n      once: true\n    });\n    if (persistent === false) {\n      try {\n        // @ts-ignore For browser compatibility\n        Deno.unrefTimer(i);\n      } catch (error) {\n        if (!(error instanceof ReferenceError)) {\n          throw error;\n        }\n        console.error(\"`persistent` option is only available in Deno\");\n      }\n    }\n  });\n}",
      "pooledMap": "function pooledMap(poolLimit, array, iteratorFn) {\n  // Create the async iterable that is returned from this function.\n  const res = new TransformStream({\n    async transform (p, controller) {\n      try {\n        const s = await p;\n        controller.enqueue(s);\n      } catch (e) {\n        if (e instanceof AggregateError && e.message === ERROR_WHILE_MAPPING_MESSAGE) {\n          controller.error(e);\n        }\n      }\n    }\n  });\n  // Start processing items from the iterator\n  (async ()=>{\n    const writer = res.writable.getWriter();\n    const executing = [];\n    try {\n      for await (const item of array){\n        const p = Promise.resolve().then(()=>iteratorFn(item));\n        // Only write on success. If we `writer.write()` a rejected promise,\n        // that will end the iteration. We don't want that yet. Instead let it\n        // fail the race, taking us to the catch block where all currently\n        // executing jobs are allowed to finish and all rejections among them\n        // can be reported together.\n        writer.write(p);\n        const e = p.then(()=>executing.splice(executing.indexOf(e), 1));\n        executing.push(e);\n        if (executing.length >= poolLimit) {\n          await Promise.race(executing);\n        }\n      }\n      // Wait until all ongoing events have processed, then close the writer.\n      await Promise.all(executing);\n      writer.close();\n    } catch  {\n      const errors = [];\n      for (const result of (await Promise.allSettled(executing))){\n        if (result.status === \"rejected\") {\n          errors.push(result.reason);\n        }\n      }\n      writer.write(Promise.reject(new AggregateError(errors, ERROR_WHILE_MAPPING_MESSAGE))).catch(()=>{});\n    }\n  })();\n  // Feature test until browser coverage is adequate\n  return Symbol.asyncIterator in res.readable && typeof res.readable[Symbol.asyncIterator] === \"function\" ? res.readable[Symbol.asyncIterator]() : async function*() {\n    const reader = res.readable.getReader();\n    while(true){\n      const { done, value } = await reader.read();\n      if (done) break;\n      yield value;\n    }\n    reader.releaseLock();\n  }();\n}",
      "retry": "async function retry(fn, options) {\n  const { multiplier = 2, maxTimeout = 60000, maxAttempts = 5, minTimeout = 1000, jitter = 1 } = options ?? {};\n  if (maxTimeout <= 0) {\n    throw new TypeError(`Cannot retry as 'maxTimeout' must be positive: current value is ${maxTimeout}`);\n  }\n  if (minTimeout > maxTimeout) {\n    throw new TypeError(`Cannot retry as 'minTimeout' must be <= 'maxTimeout': current values 'minTimeout=${minTimeout}', 'maxTimeout=${maxTimeout}'`);\n  }\n  if (jitter > 1) {\n    throw new TypeError(`Cannot retry as 'jitter' must be <= 1: current value is ${jitter}`);\n  }\n  let attempt = 0;\n  while(true){\n    try {\n      return await fn();\n    } catch (error) {\n      if (attempt + 1 >= maxAttempts) {\n        throw new RetryError(error, maxAttempts);\n      }\n      const timeout = exponentialBackoffWithJitter(maxTimeout, minTimeout, attempt, multiplier, jitter);\n      await new Promise((r)=>setTimeout(r, timeout));\n    }\n    attempt++;\n  }\n}",
      "tee": "function tee(iterable, n = 2) {\n  const queue = new Queue(iterable);\n  async function* generator() {\n    let buffer = queue.head;\n    while(true){\n      if (buffer.next) {\n        buffer = buffer.next;\n        yield buffer.value;\n      } else if (queue.done) {\n        return;\n      } else {\n        await queue.next();\n      }\n    }\n  }\n  return Array.from({\n    length: n\n  }).map(()=>generator());\n}"
    }
  },
  {
    "jsr:@std/assert": {
      "AssertionError": "class AssertionError extends Error {\n  /** Constructs a new instance.\n   *\n   * @param message The error message.\n   * @param options Additional options. This argument is still unstable. It may change in the future release.\n   */ constructor(message, options){\n    super(message, options);\n    this.name = \"AssertionError\";\n  }\n}",
      "assert": "function assert(expr, msg = \"\") {\n  if (!expr) {\n    throw new AssertionError(msg);\n  }\n}",
      "assertAlmostEquals": "function assertAlmostEquals(actual, expected, tolerance, msg) {\n  if (Object.is(actual, expected)) {\n    return;\n  }\n  const delta = Math.abs(expected - actual);\n  if (tolerance === undefined) {\n    tolerance = isFinite(expected) ? Math.abs(expected * 1e-7) : 1e-7;\n  }\n  if (delta <= tolerance) {\n    return;\n  }\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  const f = (n)=>Number.isInteger(n) ? n : n.toExponential();\n  throw new AssertionError(`Expected actual: \"${f(actual)}\" to be close to \"${f(expected)}\": \\\ndelta \"${f(delta)}\" is greater than \"${f(tolerance)}\"${msgSuffix}`);\n}",
      "assertArrayIncludes": "function assertArrayIncludes(actual, expected, msg) {\n  const missing = [];\n  for(let i = 0; i < expected.length; i++){\n    let found = false;\n    for(let j = 0; j < actual.length; j++){\n      if (equal(expected[i], actual[j])) {\n        found = true;\n        break;\n      }\n    }\n    if (!found) {\n      missing.push(expected[i]);\n    }\n  }\n  if (missing.length === 0) {\n    return;\n  }\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  msg = `Expected actual: \"${format(actual)}\" to include: \"${format(expected)}\"${msgSuffix}\\nmissing: ${format(missing)}`;\n  throw new AssertionError(msg);\n}",
      "assertEquals": "function assertEquals(actual, expected, msg) {\n  if (equal(actual, expected)) {\n    return;\n  }\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  let message = `Values are not equal${msgSuffix}`;\n  const actualString = format(actual);\n  const expectedString = format(expected);\n  const stringDiff = typeof actual === \"string\" && typeof expected === \"string\";\n  const diffResult = stringDiff ? diffStr(actual, expected) : diff(actualString.split(\"\\n\"), expectedString.split(\"\\n\"));\n  const diffMsg = buildMessage(diffResult, {\n    stringDiff\n  }).join(\"\\n\");\n  message = `${message}\\n${diffMsg}`;\n  throw new AssertionError(message);\n}",
      "assertExists": "function assertExists(actual, msg) {\n  if (actual === undefined || actual === null) {\n    const msgSuffix = msg ? `: ${msg}` : \".\";\n    msg = `Expected actual: \"${actual}\" to not be null or undefined${msgSuffix}`;\n    throw new AssertionError(msg);\n  }\n}",
      "assertFalse": "function assertFalse(expr, msg = \"\") {\n  if (expr) {\n    throw new AssertionError(msg);\n  }\n}",
      "assertGreater": "function assertGreater(actual, expected, msg) {\n  if (actual > expected) return;\n  const actualString = format(actual);\n  const expectedString = format(expected);\n  throw new AssertionError(msg ?? `Expect ${actualString} > ${expectedString}`);\n}",
      "assertGreaterOrEqual": "function assertGreaterOrEqual(actual, expected, msg) {\n  if (actual >= expected) return;\n  const actualString = format(actual);\n  const expectedString = format(expected);\n  throw new AssertionError(msg ?? `Expect ${actualString} >= ${expectedString}`);\n}",
      "assertInstanceOf": "function assertInstanceOf(actual, expectedType, msg = \"\") {\n  if (actual instanceof expectedType) return;\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  const expectedTypeStr = expectedType.name;\n  let actualTypeStr = \"\";\n  if (actual === null) {\n    actualTypeStr = \"null\";\n  } else if (actual === undefined) {\n    actualTypeStr = \"undefined\";\n  } else if (typeof actual === \"object\") {\n    actualTypeStr = actual.constructor?.name ?? \"Object\";\n  } else {\n    actualTypeStr = typeof actual;\n  }\n  if (expectedTypeStr === actualTypeStr) {\n    msg = `Expected object to be an instance of \"${expectedTypeStr}\"${msgSuffix}`;\n  } else if (actualTypeStr === \"function\") {\n    msg = `Expected object to be an instance of \"${expectedTypeStr}\" but was not an instanced object${msgSuffix}`;\n  } else {\n    msg = `Expected object to be an instance of \"${expectedTypeStr}\" but was \"${actualTypeStr}\"${msgSuffix}`;\n  }\n  throw new AssertionError(msg);\n}",
      "assertIsError": "function assertIsError(error, // deno-lint-ignore no-explicit-any\nErrorClass, msgMatches, msg) {\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  if (!(error instanceof Error)) {\n    throw new AssertionError(`Expected \"error\" to be an Error object${msgSuffix}}`);\n  }\n  if (ErrorClass && !(error instanceof ErrorClass)) {\n    msg = `Expected error to be instance of \"${ErrorClass.name}\", but was \"${error?.constructor?.name}\"${msgSuffix}`;\n    throw new AssertionError(msg);\n  }\n  let msgCheck;\n  if (typeof msgMatches === \"string\") {\n    msgCheck = stripAnsiCode(error.message).includes(stripAnsiCode(msgMatches));\n  }\n  if (msgMatches instanceof RegExp) {\n    msgCheck = msgMatches.test(stripAnsiCode(error.message));\n  }\n  if (msgMatches && !msgCheck) {\n    msg = `Expected error message to include ${msgMatches instanceof RegExp ? msgMatches.toString() : JSON.stringify(msgMatches)}, but got ${JSON.stringify(error?.message)}${msgSuffix}`;\n    throw new AssertionError(msg);\n  }\n}",
      "assertLess": "function assertLess(actual, expected, msg) {\n  if (actual < expected) return;\n  const actualString = format(actual);\n  const expectedString = format(expected);\n  throw new AssertionError(msg ?? `Expect ${actualString} < ${expectedString}`);\n}",
      "assertLessOrEqual": "function assertLessOrEqual(actual, expected, msg) {\n  if (actual <= expected) return;\n  const actualString = format(actual);\n  const expectedString = format(expected);\n  throw new AssertionError(msg ?? `Expect ${actualString} <= ${expectedString}`);\n}",
      "assertMatch": "function assertMatch(actual, expected, msg) {\n  if (expected.test(actual)) return;\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  msg = `Expected actual: \"${actual}\" to match: \"${expected}\"${msgSuffix}`;\n  throw new AssertionError(msg);\n}",
      "assertNotEquals": "function assertNotEquals(actual, expected, msg) {\n  if (!equal(actual, expected)) {\n    return;\n  }\n  const actualString = String(actual);\n  const expectedString = String(expected);\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  throw new AssertionError(`Expected actual: ${actualString} not to be: ${expectedString}${msgSuffix}`);\n}",
      "assertNotInstanceOf": "function assertNotInstanceOf(actual, // deno-lint-ignore no-explicit-any\nunexpectedType, msg) {\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  msg = `Expected object to not be an instance of \"${typeof unexpectedType}\"${msgSuffix}`;\n  assertFalse(actual instanceof unexpectedType, msg);\n}",
      "assertNotMatch": "function assertNotMatch(actual, expected, msg) {\n  if (!expected.test(actual)) return;\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  msg = `Expected actual: \"${actual}\" to not match: \"${expected}\"${msgSuffix}`;\n  throw new AssertionError(msg);\n}",
      "assertNotStrictEquals": "function assertNotStrictEquals(actual, expected, msg) {\n  if (!Object.is(actual, expected)) {\n    return;\n  }\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  throw new AssertionError(`Expected \"actual\" to not be strictly equal to: ${format(actual)}${msgSuffix}\\n`);\n}",
      "assertObjectMatch": "function assertObjectMatch(// deno-lint-ignore no-explicit-any\nactual, expected, msg) {\n  return assertEquals(// get the intersection of \"actual\" and \"expected\"\n  // side effect: all the instances' constructor field is \"Object\" now.\n  filter(actual, expected), // set (nested) instances' constructor field to be \"Object\" without changing expected value.\n  // see https://github.com/denoland/deno_std/pull/1419\n  filter(expected, expected), msg);\n}",
      "assertRejects": "async function assertRejects(fn, errorClassOrMsg, msgIncludesOrMsg, msg) {\n  // deno-lint-ignore no-explicit-any\n  let ErrorClass;\n  let msgIncludes;\n  let err;\n  if (typeof errorClassOrMsg !== \"string\") {\n    if (errorClassOrMsg === undefined || errorClassOrMsg.prototype instanceof Error || errorClassOrMsg.prototype === Error.prototype) {\n      ErrorClass = errorClassOrMsg;\n      msgIncludes = msgIncludesOrMsg;\n    }\n  } else {\n    msg = errorClassOrMsg;\n  }\n  let doesThrow = false;\n  let isPromiseReturned = false;\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  try {\n    const possiblePromise = fn();\n    if (possiblePromise && typeof possiblePromise === \"object\" && typeof possiblePromise.then === \"function\") {\n      isPromiseReturned = true;\n      await possiblePromise;\n    } else {\n      throw new Error();\n    }\n  } catch (error) {\n    if (!isPromiseReturned) {\n      throw new AssertionError(`Function throws when expected to reject${msgSuffix}`);\n    }\n    if (ErrorClass) {\n      if (!(error instanceof Error)) {\n        throw new AssertionError(`A non-Error object was rejected${msgSuffix}`);\n      }\n      assertIsError(error, ErrorClass, msgIncludes, msg);\n    }\n    err = error;\n    doesThrow = true;\n  }\n  if (!doesThrow) {\n    throw new AssertionError(`Expected function to reject${msgSuffix}`);\n  }\n  return err;\n}",
      "assertStrictEquals": "function assertStrictEquals(actual, expected, msg) {\n  if (Object.is(actual, expected)) {\n    return;\n  }\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  let message;\n  const actualString = format(actual);\n  const expectedString = format(expected);\n  if (actualString === expectedString) {\n    const withOffset = actualString.split(\"\\n\").map((l)=>`    ${l}`).join(\"\\n\");\n    message = `Values have the same structure but are not reference-equal${msgSuffix}\\n\\n${red(withOffset)}\\n`;\n  } else {\n    const stringDiff = typeof actual === \"string\" && typeof expected === \"string\";\n    const diffResult = stringDiff ? diffStr(actual, expected) : diff(actualString.split(\"\\n\"), expectedString.split(\"\\n\"));\n    const diffMsg = buildMessage(diffResult, {\n      stringDiff\n    }).join(\"\\n\");\n    message = `Values are not strictly equal${msgSuffix}\\n${diffMsg}`;\n  }\n  throw new AssertionError(message);\n}",
      "assertStringIncludes": "function assertStringIncludes(actual, expected, msg) {\n  if (actual.includes(expected)) return;\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  msg = `Expected actual: \"${actual}\" to contain: \"${expected}\"${msgSuffix}`;\n  throw new AssertionError(msg);\n}",
      "assertThrows": "function assertThrows(fn, errorClassOrMsg, msgIncludesOrMsg, msg) {\n  // deno-lint-ignore no-explicit-any\n  let ErrorClass;\n  let msgIncludes;\n  let err;\n  if (typeof errorClassOrMsg !== \"string\") {\n    if (errorClassOrMsg === undefined || errorClassOrMsg?.prototype instanceof Error || errorClassOrMsg?.prototype === Error.prototype) {\n      ErrorClass = errorClassOrMsg;\n      msgIncludes = msgIncludesOrMsg;\n    } else {\n      msg = msgIncludesOrMsg;\n    }\n  } else {\n    msg = errorClassOrMsg;\n  }\n  let doesThrow = false;\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  try {\n    fn();\n  } catch (error) {\n    if (ErrorClass) {\n      if (error instanceof Error === false) {\n        throw new AssertionError(`A non-Error object was thrown${msgSuffix}`);\n      }\n      assertIsError(error, ErrorClass, msgIncludes, msg);\n    }\n    err = error;\n    doesThrow = true;\n  }\n  if (!doesThrow) {\n    msg = `Expected function to throw${msgSuffix}`;\n    throw new AssertionError(msg);\n  }\n  return err;\n}",
      "equal": "function equal(c, d) {\n  const seen = new Map();\n  return function compare(a, b) {\n    // Have to render RegExp & Date for string comparison\n    // unless it's mistreated as object\n    if (a && b && (a instanceof RegExp && b instanceof RegExp || a instanceof URL && b instanceof URL)) {\n      return String(a) === String(b);\n    }\n    if (a instanceof Date && b instanceof Date) {\n      const aTime = a.getTime();\n      const bTime = b.getTime();\n      // Check for NaN equality manually since NaN is not\n      // equal to itself.\n      if (Number.isNaN(aTime) && Number.isNaN(bTime)) {\n        return true;\n      }\n      return aTime === bTime;\n    }\n    if (typeof a === \"number\" && typeof b === \"number\") {\n      return Number.isNaN(a) && Number.isNaN(b) || a === b;\n    }\n    if (Object.is(a, b)) {\n      return true;\n    }\n    if (a && typeof a === \"object\" && b && typeof b === \"object\") {\n      if (a && b && !constructorsEqual(a, b)) {\n        return false;\n      }\n      if (a instanceof WeakMap || b instanceof WeakMap) {\n        if (!(a instanceof WeakMap && b instanceof WeakMap)) return false;\n        throw new TypeError(\"cannot compare WeakMap instances\");\n      }\n      if (a instanceof WeakSet || b instanceof WeakSet) {\n        if (!(a instanceof WeakSet && b instanceof WeakSet)) return false;\n        throw new TypeError(\"cannot compare WeakSet instances\");\n      }\n      if (a instanceof WeakRef || b instanceof WeakRef) {\n        if (!(a instanceof WeakRef && b instanceof WeakRef)) return false;\n        return compare(a.deref(), b.deref());\n      }\n      if (seen.get(a) === b) {\n        return true;\n      }\n      if (Object.keys(a).length !== Object.keys(b).length) {\n        return false;\n      }\n      seen.set(a, b);\n      if (isKeyedCollection(a) && isKeyedCollection(b)) {\n        if (a.size !== b.size) {\n          return false;\n        }\n        const aKeys = [\n          ...a.keys()\n        ];\n        const primitiveKeysFastPath = aKeys.every((k)=>{\n          return typeof k === \"string\" || typeof k === \"number\" || typeof k === \"boolean\" || typeof k === \"bigint\" || typeof k === \"symbol\" || k == null;\n        });\n        if (primitiveKeysFastPath) {\n          if (a instanceof Set) {\n            return a.symmetricDifference(b).size === 0;\n          }\n          for (const key of aKeys){\n            if (!b.has(key) || !compare(a.get(key), b.get(key))) {\n              return false;\n            }\n          }\n          return true;\n        }\n        let unmatchedEntries = a.size;\n        for (const [aKey, aValue] of a.entries()){\n          for (const [bKey, bValue] of b.entries()){\n            /* Given that Map keys can be references, we need\n             * to ensure that they are also deeply equal */ if (!compare(aKey, bKey)) continue;\n            if (aKey === aValue && bKey === bValue || compare(aValue, bValue)) {\n              unmatchedEntries--;\n              break;\n            }\n          }\n        }\n        return unmatchedEntries === 0;\n      }\n      const merged = {\n        ...a,\n        ...b\n      };\n      for (const key of [\n        ...Object.getOwnPropertyNames(merged),\n        ...Object.getOwnPropertySymbols(merged)\n      ]){\n        if (!compare(a && a[key], b && b[key])) {\n          return false;\n        }\n        if (key in a && !(key in b) || key in b && !(key in a)) {\n          return false;\n        }\n      }\n      return true;\n    }\n    return false;\n  }(c, d);\n}",
      "fail": "function fail(msg) {\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  throw new AssertionError(`Failed assertion${msgSuffix}`);\n}",
      "unimplemented": "function unimplemented(msg) {\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  throw new AssertionError(`Unimplemented${msgSuffix}`);\n}",
      "unreachable": "function unreachable(msg) {\n  const msgSuffix = msg ? `: ${msg}` : \".\";\n  throw new AssertionError(`Unreachable${msgSuffix}`);\n}"
    }
  }
}
